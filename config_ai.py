#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¯‰æœªç§‘æŠ€å¤§è…¦ - AI é…ç½®æ–‡ä»¶
æ”¯æŒ OpenAI å’Œ Ollama å…©ç¨®æ¨¡å‹
"""

import os
from typing import Optional
from enum import Enum

class AIModelType(Enum):
    """AI æ¨¡å‹é¡å‹"""
    OPENAI = "openai"
    OLLAMA = "ollama"
    GEMINI = "gemini"
    QWEN = "qwen"
    DEMO = "demo"

class AIConfig:
    """AI æ¨¡å‹é…ç½®é¡"""
    
    # AI æ¨¡å‹é¡å‹é…ç½®
    MODEL_TYPE: AIModelType = AIModelType.DEMO  # é»˜èªä½¿ç”¨æ¼”ç¤ºæ¨¡å¼
    
    # OpenAI é…ç½®
    OPENAI_API_KEY: Optional[str] = None
    OPENAI_API_BASE: str = "https://api.openai.com/v1"
    OPENAI_MODEL: str = "gpt-4o-mini"
    
    # Ollama é…ç½®
    OLLAMA_API_BASE: str = "http://localhost:11461/v1"
    OLLAMA_MODEL: str = "llama3.1"  # é»˜èªä½¿ç”¨ llama3.1 æ¨¡å‹
    
    # Gemini é…ç½®
    GEMINI_API_KEY: Optional[str] = None
    GEMINI_MODEL: str = "gemini-pro"
    
    # é€šç¾©åƒå•é…ç½®
    DASHSCOPE_API_KEY: Optional[str] = None
    QWEN_MODEL: str = "qwen-plus"
    
    # é€šç”¨æ¨¡å‹åƒæ•¸
    MAX_TOKENS: int = 1000
    TEMPERATURE: float = 0.7
    TOP_P: float = 0.9
    
    # ä¸Šä¸‹æ–‡é…ç½®
    CONTEXT_MESSAGES: int = 10  # ä¿ç•™æœ€è¿‘å¹¾æ¢å°è©±è¨˜éŒ„
    
    # æˆæœ¬æ§åˆ¶ï¼ˆåƒ…é©ç”¨æ–¼ OpenAIï¼‰
    ENABLE_COST_TRACKING: bool = True
    
    def __init__(self, **kwargs):
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
    
    @classmethod
    def load_from_env(cls):
        """å¾ç’°å¢ƒè®Šé‡åŠ è¼‰é…ç½®"""
        # æª¢æ¸¬æ¨¡å‹é¡å‹
        model_type_str = os.getenv("AI_MODEL_TYPE", "demo").lower()
        if model_type_str == "openai" and os.getenv("OPENAI_API_KEY"):
            model_type = AIModelType.OPENAI
        elif model_type_str == "ollama":
            model_type = AIModelType.OLLAMA
        elif model_type_str == "gemini" and os.getenv("GEMINI_API_KEY"):
            model_type = AIModelType.GEMINI
        elif model_type_str == "qwen" and os.getenv("DASHSCOPE_API_KEY"):
            model_type = AIModelType.QWEN
        else:
            model_type = AIModelType.DEMO
        
        return cls(
            MODEL_TYPE=model_type,
            OPENAI_API_KEY=os.getenv("OPENAI_API_KEY"),
            OPENAI_MODEL=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            OLLAMA_API_BASE=os.getenv("OLLAMA_API_BASE", "http://localhost:11461/v1"),
            OLLAMA_MODEL=os.getenv("OLLAMA_MODEL", "llama3.1"),
            GEMINI_API_KEY=os.getenv("GEMINI_API_KEY"),
            GEMINI_MODEL=os.getenv("GEMINI_MODEL", "gemini-pro"),
            DASHSCOPE_API_KEY=os.getenv("DASHSCOPE_API_KEY"),
            QWEN_MODEL=os.getenv("QWEN_MODEL", "qwen-plus"),
            MAX_TOKENS=int(os.getenv("AI_MAX_TOKENS", "1000")),
            TEMPERATURE=float(os.getenv("AI_TEMPERATURE", "0.7"))
        )
    
    @classmethod
    def validate(cls, config: 'AIConfig') -> bool:
        """é©—è­‰é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        if config.MODEL_TYPE == AIModelType.OPENAI:
            if not config.OPENAI_API_KEY:
                print("âš ï¸  è­¦å‘Šï¼šæœªè¨­ç½® OPENAI_API_KEY")
                print("ğŸ’¡ æç¤ºï¼šæ‚¨éœ€è¦è¨­ç½® API å¯†é‘°æ‰èƒ½ä½¿ç”¨ OpenAI åŠŸèƒ½")
                print("ğŸ“‹ ç²å–æ–¹å¼ï¼šhttps://platform.openai.com/api-keys")
                return False
            print("[AI] ä½¿ç”¨ OpenAI æ¨¡å‹")
            print(f"  æ¨¡å‹: {config.OPENAI_MODEL}")
        elif config.MODEL_TYPE == AIModelType.OLLAMA:
            print("[AI] ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å‹")
            print(f"  æ¨¡å‹: {config.OLLAMA_MODEL}")
            print(f"  API åœ°å€: {config.OLLAMA_API_BASE}")
            print("[æç¤º] è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œ")
        elif config.MODEL_TYPE == AIModelType.GEMINI:
            if not config.GEMINI_API_KEY:
                print("âš ï¸  è­¦å‘Šï¼šæœªè¨­ç½® GEMINI_API_KEY")
                print("ğŸ’¡ æç¤ºï¼šæ‚¨éœ€è¦è¨­ç½® API å¯†é‘°æ‰èƒ½ä½¿ç”¨ Gemini åŠŸèƒ½")
                print("ğŸ“‹ ç²å–æ–¹å¼ï¼šhttps://aistudio.google.com/app/apikey")
                return False
            print("[AI] ä½¿ç”¨ Google Gemini æ¨¡å‹")
            print(f"  æ¨¡å‹: {config.GEMINI_MODEL}")
        elif config.MODEL_TYPE == AIModelType.QWEN:
            if not config.DASHSCOPE_API_KEY:
                print("âš ï¸  è­¦å‘Šï¼šæœªè¨­ç½® DASHSCOPE_API_KEY")
                print("ğŸ’¡ æç¤ºï¼šæ‚¨éœ€è¦è¨­ç½® API å¯†é‘°æ‰èƒ½ä½¿ç”¨é€šç¾©åƒå•åŠŸèƒ½")
                print("ğŸ“‹ ç²å–æ–¹å¼ï¼šhttps://dashscope.aliyun.com/")
                return False
            print("[AI] ä½¿ç”¨é€šç¾©åƒå•æ¨¡å‹")
            print(f"  æ¨¡å‹: {config.QWEN_MODEL}")
        else:
            print("[æ¨¡å¼] ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼")
            print("[æç¤º] å¯ä»¥è¨­ç½®ç’°å¢ƒè®Šé‡åˆ‡æ›åˆ° OpenAIã€Ollamaã€Gemini æˆ– Qwen")
        
        return True
    
    def get_api_base(self) -> str:
        """ç²å–ç•¶å‰ API åŸºç¤åœ°å€"""
        if self.MODEL_TYPE == AIModelType.OPENAI:
            return self.OPENAI_API_BASE
        elif self.MODEL_TYPE == AIModelType.OLLAMA:
            return self.OLLAMA_API_BASE
        elif self.MODEL_TYPE == AIModelType.GEMINI:
            return "https://generativelanguage.googleapis.com/v1"
        elif self.MODEL_TYPE == AIModelType.QWEN:
            return "https://dashscope.aliyuncs.com/api/v1"
        return ""
    
    def get_api_key(self) -> Optional[str]:
        """ç²å–ç•¶å‰ API å¯†é‘°"""
        if self.MODEL_TYPE == AIModelType.OPENAI:
            return self.OPENAI_API_KEY
        elif self.MODEL_TYPE == AIModelType.GEMINI:
            return self.GEMINI_API_KEY
        elif self.MODEL_TYPE == AIModelType.QWEN:
            return self.DASHSCOPE_API_KEY
        return "not-needed"  # Ollama ä¸éœ€è¦ API å¯†é‘°
    
    def get_model_name(self) -> str:
        """ç²å–ç•¶å‰æ¨¡å‹åç¨±"""
        if self.MODEL_TYPE == AIModelType.OPENAI:
            return self.OPENAI_MODEL
        elif self.MODEL_TYPE == AIModelType.OLLAMA:
            return self.OLLAMA_MODEL
        elif self.MODEL_TYPE == AIModelType.GEMINI:
            return self.GEMINI_MODEL
        elif self.MODEL_TYPE == AIModelType.QWEN:
            return self.QWEN_MODEL
        return "demo"

# å…¨å±€é…ç½®å¯¦ä¾‹
ai_config = AIConfig.load_from_env()
