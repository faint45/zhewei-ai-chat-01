# -*- coding: utf-8 -*-
"""
ç¯‰æœªç§‘æŠ€ â€” MCP å·¥ä½œæµå¼•æ“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
7 æ­¥é©Ÿè‡ªå‹•åŒ–å·¥ä½œæµï¼š
  1. æƒ³æ³•ç”¢å‡ºï¼ˆç”¨æˆ¶è¼¸å…¥éœ€æ±‚ï¼‰
  2. æœ¬åœ° AI åˆ†æåŠæå‡ºå»ºè­°ï¼ˆè§’è‰²çŸ¥è­˜åº« + Ollamaï¼‰
  3. ç”¨æˆ¶ç¢ºèªæ˜¯å¦ç‚ºæƒ³è¦çš„æ•ˆæœ
  4. MCP é–‹å§‹å‹•æ‰‹åšï¼ˆç”¨æœ€å°‘æµé‡ç”šè‡³å…è²»ï¼‰
  5. ç¢ºèªæˆæœ
  6. AI æå‡ºå„ªåŒ–å»ºè­°
  7. åŸ·è¡Œå„ªåŒ– â†’ çµæ¡ˆ

æ¯å€‹å·¥ä½œæµå¯¦ä¾‹ä»¥ JSON æŒä¹…åŒ–ï¼Œæ”¯æ´æš«åœ/æ¢å¾©ã€‚
"""
import json
import os
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any

ROOT = Path(__file__).resolve().parent
WORKFLOW_DIR = ROOT / "brain_workspace" / "workflows"
WORKFLOW_DIR.mkdir(parents=True, exist_ok=True)


def _is_ollama_healthy() -> bool:
    """è¼•é‡ç´š Ollama å¥åº·æ¢é‡ï¼ˆåŒæ­¥ç‰ˆï¼‰ï¼Œ2s è¶…æ™‚ï¼Œå¿«å– 30sã€‚"""
    import time as _time
    now = _time.time()
    # å¿«å–ï¼šé¿å…æ¯æ¬¡éƒ½æ¢æ¸¬
    if hasattr(_is_ollama_healthy, "_cache"):
        ok, ts = _is_ollama_healthy._cache
        if now - ts < 30:
            return ok
    try:
        import requests
        from ai_service import OLLAMA_BASE_URL
        r = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=2)
        healthy = r.status_code == 200
    except Exception:
        healthy = False
    _is_ollama_healthy._cache = (healthy, now)
    if not healthy:
        print("âš ï¸ [mcp_workflow] Ollama æœ¬åœ°ç•°å¸¸ï¼Œè‡ªå‹•åˆ‡æ›é›²ç«¯")
    return healthy


def smart_generate(prompt: str) -> str:
    """è»å¸«ç”Ÿæˆï¼šOllama æœ¬åœ°å„ªå…ˆï¼Œé›²ç«¯åƒ… non-local_only æ¨¡å¼å‚™æ´ã€‚"""
    # æœ¬åœ° Ollama è»å¸«å„ªå…ˆ
    if _is_ollama_healthy():
        try:
            from local_learning_system import ollama_generate
            result = ollama_generate(prompt)
            if result and result.strip():
                return result
        except Exception:
            pass
    # é local_only æ¨¡å¼æ‰å˜—è©¦é›²ç«¯å‚™æ´
    from ai_service import AI_COST_MODE
    if AI_COST_MODE != "local_only":
        try:
            from ai_service import _gemini_chat_sync, GEMINI_API_KEY
            if GEMINI_API_KEY:
                messages = [{"role": "user", "content": prompt}]
                result = _gemini_chat_sync(messages)
                if result and "API éŒ¯èª¤" not in result and "done" not in result[:20]:
                    return result
        except Exception:
            pass
    return "AI æœå‹™æš«æ™‚ä¸å¯ç”¨ã€‚"


def exec_generate(prompt: str) -> str:
    """å£«å…µç”Ÿæˆï¼šOllama æœ¬åœ°åŸ·è¡Œï¼Œé›²ç«¯åƒ… non-local_only æ¨¡å¼æ•‘æ´ã€‚"""
    # Ollama å£«å…µä¸Šå ´
    if _is_ollama_healthy():
        try:
            from local_learning_system import ollama_generate
            result = ollama_generate(prompt)
            if result and result.strip():
                return result
        except Exception:
            pass
    # é local_only æ¨¡å¼æ‰å˜—è©¦é›²ç«¯æ•‘æ´
    from ai_service import AI_COST_MODE
    if AI_COST_MODE != "local_only":
        try:
            from ai_service import _gemini_chat_sync, GEMINI_API_KEY
            if GEMINI_API_KEY:
                messages = [{"role": "user", "content": prompt}]
                return _gemini_chat_sync(messages)
        except Exception:
            pass
    return "AI æœå‹™æš«æ™‚ä¸å¯ç”¨ã€‚"

# å·¥ä½œæµæ­¥é©Ÿå®šç¾©
STEPS = [
    {"id": "idea",     "name": "æƒ³æ³•ç”¢å‡º",       "icon": "ğŸ’¡", "auto": False},
    {"id": "analyze",  "name": "AI åˆ†æå»ºè­°",    "icon": "ğŸ§ ", "auto": True},
    {"id": "confirm",  "name": "ç”¨æˆ¶ç¢ºèªæ–¹æ¡ˆ",   "icon": "âœ…", "auto": False},
    {"id": "execute",  "name": "MCP åŸ·è¡Œ",       "icon": "âš¡", "auto": True},
    {"id": "review",   "name": "ç¢ºèªæˆæœ",       "icon": "ğŸ”", "auto": False},
    {"id": "optimize", "name": "AI å„ªåŒ–å»ºè­°",    "icon": "ğŸ”§", "auto": True},
    {"id": "finalize", "name": "åŸ·è¡Œå„ªåŒ–/çµæ¡ˆ",  "icon": "ğŸ", "auto": False},
]

STEP_IDS = [s["id"] for s in STEPS]


def _wf_path(wf_id: str) -> Path:
    return WORKFLOW_DIR / f"{wf_id}.json"


def _save_wf(wf: dict):
    _wf_path(wf["id"]).write_text(json.dumps(wf, ensure_ascii=False, indent=2), encoding="utf-8")


def _load_wf(wf_id: str) -> dict | None:
    p = _wf_path(wf_id)
    if p.exists():
        return json.loads(p.read_text(encoding="utf-8"))
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å·¥ä½œæµ CRUD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_workflow(role_id: str, idea: str, title: str = "") -> dict[str, Any]:
    """å»ºç«‹æ–°å·¥ä½œæµã€‚"""
    import role_manager
    role = role_manager.get_role(role_id)
    if not role:
        return {"ok": False, "error": f"è§’è‰² '{role_id}' ä¸å­˜åœ¨"}

    wf_id = f"wf_{int(time.time())}_{uuid.uuid4().hex[:8]}"
    wf = {
        "id": wf_id,
        "title": title or idea[:50],
        "role_id": role_id,
        "role_name": role["name"],
        "role_icon": role["icon"],
        "idea": idea,
        "current_step": "idea",
        "status": "active",
        "created_at": datetime.now().isoformat(timespec="seconds"),
        "updated_at": datetime.now().isoformat(timespec="seconds"),
        "steps": {
            "idea":     {"status": "done", "input": idea, "output": "", "ts": datetime.now().isoformat(timespec="seconds")},
            "analyze":  {"status": "pending", "input": "", "output": "", "ts": ""},
            "confirm":  {"status": "pending", "input": "", "output": "", "ts": ""},
            "execute":  {"status": "pending", "input": "", "output": "", "ts": ""},
            "review":   {"status": "pending", "input": "", "output": "", "ts": ""},
            "optimize": {"status": "pending", "input": "", "output": "", "ts": ""},
            "finalize": {"status": "pending", "input": "", "output": "", "ts": ""},
        },
        "mcp_actions": [],
        "history": [{"step": "idea", "action": "created", "ts": datetime.now().isoformat(timespec="seconds")}],
    }
    _save_wf(wf)
    return {"ok": True, "workflow": wf}


def list_workflows(status: str = "") -> list[dict]:
    """åˆ—å‡ºæ‰€æœ‰å·¥ä½œæµï¼ˆå¯ä¾ç‹€æ…‹ç¯©é¸ï¼‰ã€‚"""
    results = []
    for p in sorted(WORKFLOW_DIR.glob("wf_*.json"), reverse=True):
        try:
            wf = json.loads(p.read_text(encoding="utf-8"))
            if status and wf.get("status") != status:
                continue
            results.append({
                "id": wf["id"],
                "title": wf.get("title", ""),
                "role_id": wf.get("role_id", ""),
                "role_name": wf.get("role_name", ""),
                "role_icon": wf.get("role_icon", ""),
                "current_step": wf.get("current_step", ""),
                "status": wf.get("status", ""),
                "created_at": wf.get("created_at", ""),
                "updated_at": wf.get("updated_at", ""),
            })
        except Exception:
            continue
    return results


def get_workflow(wf_id: str) -> dict[str, Any]:
    """å–å¾—å·¥ä½œæµè©³æƒ…ã€‚"""
    wf = _load_wf(wf_id)
    if not wf:
        return {"ok": False, "error": "å·¥ä½œæµä¸å­˜åœ¨"}
    return {"ok": True, "workflow": wf}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ­¥é©ŸåŸ·è¡Œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def advance_step(wf_id: str, user_input: str = "", user_approved: bool = True) -> dict[str, Any]:
    """æ¨é€²å·¥ä½œæµåˆ°ä¸‹ä¸€æ­¥ã€‚

    - è‡ªå‹•æ­¥é©Ÿï¼ˆanalyze/execute/optimizeï¼‰ç”± AI åŸ·è¡Œ
    - æ‰‹å‹•æ­¥é©Ÿï¼ˆconfirm/review/finalizeï¼‰éœ€ç”¨æˆ¶ç¢ºèª
    """
    wf = _load_wf(wf_id)
    if not wf:
        return {"ok": False, "error": "å·¥ä½œæµä¸å­˜åœ¨"}
    if wf["status"] != "active":
        return {"ok": False, "error": f"å·¥ä½œæµç‹€æ…‹ç‚º {wf['status']}ï¼Œç„¡æ³•æ¨é€²"}

    current = wf["current_step"]
    current_idx = STEP_IDS.index(current) if current in STEP_IDS else -1

    # æ±ºå®šä¸‹ä¸€æ­¥
    if current == "idea":
        next_step = "analyze"
    elif current == "analyze":
        next_step = "confirm"
    elif current == "confirm":
        if not user_approved:
            # ç”¨æˆ¶ä¸æ»¿æ„ï¼Œå›åˆ° analyze é‡æ–°åˆ†æ
            wf["steps"]["analyze"]["status"] = "pending"
            wf["steps"]["analyze"]["output"] = ""
            wf["current_step"] = "analyze"
            wf["steps"]["confirm"]["input"] = user_input or "ç”¨æˆ¶è¦æ±‚é‡æ–°åˆ†æ"
            wf["history"].append({"step": "confirm", "action": "rejected", "ts": datetime.now().isoformat(timespec="seconds")})
            wf["updated_at"] = datetime.now().isoformat(timespec="seconds")
            _save_wf(wf)
            return _run_auto_step(wf, "analyze", user_input)
        next_step = "execute"
    elif current == "execute":
        next_step = "review"
    elif current == "review":
        if not user_approved:
            # æˆæœä¸æ»¿æ„ï¼Œå›åˆ° execute é‡åš
            wf["steps"]["execute"]["status"] = "pending"
            wf["current_step"] = "execute"
            wf["history"].append({"step": "review", "action": "rejected", "ts": datetime.now().isoformat(timespec="seconds")})
            wf["updated_at"] = datetime.now().isoformat(timespec="seconds")
            _save_wf(wf)
            return _run_auto_step(wf, "execute", user_input)
        next_step = "optimize"
    elif current == "optimize":
        next_step = "finalize"
    elif current == "finalize":
        if user_approved:
            wf["status"] = "completed"
            wf["steps"]["finalize"]["status"] = "done"
            wf["steps"]["finalize"]["output"] = "çµæ¡ˆ"
            wf["steps"]["finalize"]["ts"] = datetime.now().isoformat(timespec="seconds")
            wf["history"].append({"step": "finalize", "action": "completed", "ts": datetime.now().isoformat(timespec="seconds")})
            wf["updated_at"] = datetime.now().isoformat(timespec="seconds")
            _save_wf(wf)
            return {"ok": True, "workflow": wf, "message": "å·¥ä½œæµå·²çµæ¡ˆ"}
        else:
            # å›åˆ° optimize
            wf["steps"]["optimize"]["status"] = "pending"
            wf["current_step"] = "optimize"
            wf["history"].append({"step": "finalize", "action": "rejected", "ts": datetime.now().isoformat(timespec="seconds")})
            wf["updated_at"] = datetime.now().isoformat(timespec="seconds")
            _save_wf(wf)
            return _run_auto_step(wf, "optimize", user_input)
    else:
        return {"ok": False, "error": f"æœªçŸ¥æ­¥é©Ÿ: {current}"}

    # æ¨™è¨˜ç•¶å‰æ­¥é©Ÿå®Œæˆ
    wf["steps"][current]["status"] = "done"
    if user_input:
        wf["steps"][current]["input"] = user_input
    wf["steps"][current]["ts"] = datetime.now().isoformat(timespec="seconds")
    wf["current_step"] = next_step
    wf["updated_at"] = datetime.now().isoformat(timespec="seconds")
    wf["history"].append({"step": current, "action": "done", "ts": datetime.now().isoformat(timespec="seconds")})
    _save_wf(wf)

    # å¦‚æœä¸‹ä¸€æ­¥æ˜¯è‡ªå‹•æ­¥é©Ÿï¼Œç«‹å³åŸ·è¡Œ
    step_def = next((s for s in STEPS if s["id"] == next_step), None)
    if step_def and step_def.get("auto"):
        return _run_auto_step(wf, next_step, user_input)

    return {"ok": True, "workflow": wf, "message": f"é€²å…¥æ­¥é©Ÿ: {step_def['name'] if step_def else next_step}"}


def _run_auto_step(wf: dict, step_id: str, context: str = "") -> dict[str, Any]:
    """åŸ·è¡Œè‡ªå‹•æ­¥é©Ÿï¼ˆAI åˆ†æ / MCP åŸ·è¡Œ / AI å„ªåŒ–ï¼‰ã€‚"""
    import sys
    sys.path.insert(0, str(ROOT / "Jarvis_Training"))

    role_id = wf["role_id"]
    idea = wf["idea"]

    import role_manager

    if step_id == "analyze":
        return _step_analyze(wf, role_id, idea, context)
    elif step_id == "execute":
        return _step_execute(wf, role_id, idea, context)
    elif step_id == "optimize":
        return _step_optimize(wf, role_id, idea, context)
    else:
        return {"ok": False, "error": f"ç„¡æ³•è‡ªå‹•åŸ·è¡Œæ­¥é©Ÿ: {step_id}"}


def _step_analyze(wf: dict, role_id: str, idea: str, extra: str = "") -> dict[str, Any]:
    """æ­¥é©Ÿ 2ï¼šAI åˆ†æåŠæå‡ºå»ºè­°ï¼ˆGemini Pro å„ªå…ˆï¼ŒOllama å‚™æ´ï¼‰ã€‚"""
    import role_manager

    role = role_manager.get_role(role_id) or {}
    system_prompt = role.get("system_prompt", "")
    mcp_tools = role.get("mcp_tools", {})

    # æœå°‹è§’è‰²çŸ¥è­˜åº«å–å¾—ä¸Šä¸‹æ–‡
    hits = role_manager.role_search(role_id, idea, top_k=3)
    context_parts = []
    for i, h in enumerate(hits, 1):
        src = "å°ˆæ¥­åº«" if h.get("from", "").startswith("role:") else "é€šè­˜åº«"
        context_parts.append(f"[{src}] {h.get('question', '')[:60]}: {h.get('answer', '')[:200]}")
    kb_context = "\n".join(context_parts) if context_parts else "ï¼ˆç„¡ç›¸é—œçŸ¥è­˜ï¼‰"

    # å¯ç”¨ MCP å·¥å…·æè¿°
    tool_desc = ""
    if mcp_tools:
        tool_lines = []
        for phase, tools in mcp_tools.items():
            tool_lines.append(f"  {phase}: {', '.join(tools)}")
        tool_desc = "å¯ç”¨ MCP å·¥å…·ï¼š\n" + "\n".join(tool_lines)

    prompt = (
        f"{system_prompt}\n\n"
        f"ç”¨æˆ¶çš„æƒ³æ³•ï¼š{idea}\n"
        f"{'ç”¨æˆ¶è£œå……ï¼š' + extra if extra else ''}\n\n"
        f"ç›¸é—œçŸ¥è­˜ï¼š\n{kb_context}\n\n"
        f"{tool_desc}\n\n"
        "è«‹ä»¥æ­¤è§’è‰²çš„å°ˆæ¥­è¦–è§’ï¼Œæä¾›ï¼š\n"
        "1. ã€éœ€æ±‚åˆ†æã€‘ç†è§£ç”¨æˆ¶æƒ³è¦ä»€éº¼\n"
        "2. ã€åŸ·è¡Œæ–¹æ¡ˆã€‘å…·é«”æ­¥é©Ÿï¼ˆå„ªå…ˆä½¿ç”¨å…è²»/æœ¬åœ°æ–¹æ¡ˆï¼‰\n"
        "3. ã€æ‰€éœ€å·¥å…·ã€‘åˆ—å‡ºæœƒç”¨åˆ°çš„ MCP å·¥å…·å’ŒåŸå› \n"
        "4. ã€é ä¼°æˆæœ¬ã€‘æ™‚é–“å’Œè²»ç”¨ï¼ˆç›¡é‡å…è²»ï¼‰\n"
        "5. ã€é¢¨éšªæé†’ã€‘å¯èƒ½çš„å•é¡Œå’Œå‚™æ¡ˆ"
    )
    try:
        analysis = smart_generate(prompt)
    except Exception as e:
        analysis = f"AI åˆ†ææš«æ™‚ä¸å¯ç”¨ï¼š{e}\n\nè«‹æ‰‹å‹•æä¾›åŸ·è¡Œæ–¹æ¡ˆã€‚"

    wf["steps"]["analyze"]["status"] = "done"
    wf["steps"]["analyze"]["output"] = analysis
    wf["steps"]["analyze"]["ts"] = datetime.now().isoformat(timespec="seconds")
    wf["current_step"] = "confirm"
    wf["updated_at"] = datetime.now().isoformat(timespec="seconds")
    wf["history"].append({"step": "analyze", "action": "done", "ts": datetime.now().isoformat(timespec="seconds")})
    _save_wf(wf)

    return {"ok": True, "workflow": wf, "message": "AI åˆ†æå®Œæˆï¼Œè«‹ç¢ºèªæ–¹æ¡ˆ"}


def _step_execute(wf: dict, role_id: str, idea: str, extra: str = "") -> dict[str, Any]:
    """æ­¥é©Ÿ 4ï¼šMCP åŸ·è¡Œã€‚

    ç”¢ç”Ÿ MCP å‹•ä½œè¨ˆç•«ï¼ˆå¯¦éš› MCP å‘¼å«ç”±å‰ç«¯/Agent åŸ·è¡Œï¼‰ã€‚
    """
    import role_manager

    role = role_manager.get_role(role_id) or {}
    mcp_tools = role.get("mcp_tools", {})
    analysis = wf["steps"]["analyze"].get("output", "")

    # ç”¢ç”Ÿ MCP åŸ·è¡Œè¨ˆç•«
    exec_tools = mcp_tools.get("execute", [])
    research_tools = mcp_tools.get("research", [])

    prompt = (
        f"ä½ æ˜¯ MCP å·¥ä½œæµåŸ·è¡Œè¦åŠƒå™¨ã€‚æ ¹æ“šä»¥ä¸‹åˆ†æçµæœï¼Œç”¢ç”Ÿå…·é«”çš„ MCP å·¥å…·å‘¼å«è¨ˆç•«ã€‚\n\n"
        f"ç”¨æˆ¶éœ€æ±‚ï¼š{idea}\n"
        f"åˆ†æçµæœï¼š{analysis[:1500]}\n"
        f"{'ç”¨æˆ¶è£œå……ï¼š' + extra if extra else ''}\n\n"
        f"å¯ç”¨åŸ·è¡Œå·¥å…·ï¼š{', '.join(exec_tools)}\n"
        f"å¯ç”¨ç ”ç©¶å·¥å…·ï¼š{', '.join(research_tools)}\n\n"
        "è«‹ç”¢ç”Ÿ JSON æ ¼å¼çš„åŸ·è¡Œè¨ˆç•«ï¼Œæ¯å€‹å‹•ä½œåŒ…å«ï¼š\n"
        '[ {{"tool": "å·¥å…·å", "action": "å‹•ä½œæè¿°", "params": "åƒæ•¸èªªæ˜", "cost": "å…è²»/ä½æˆæœ¬"}} ]\n'
        "å„ªå…ˆä½¿ç”¨å…è²»æ–¹æ¡ˆï¼Œæœ€å°åŒ–å¤–éƒ¨ API å‘¼å«ã€‚åªè¼¸å‡º JSON é™£åˆ—ã€‚"
    )
    try:
        raw = exec_generate(prompt)
        # å˜—è©¦è§£æ JSON
        import re
        json_match = re.search(r'\[.*\]', raw, re.DOTALL)
        if json_match:
            actions = json.loads(json_match.group())
        else:
            actions = [{"tool": "manual", "action": raw[:500], "params": "", "cost": "å…è²»"}]
    except Exception:
        actions = [{"tool": "manual", "action": "AI è¦åŠƒå¤±æ•—ï¼Œè«‹æ‰‹å‹•åŸ·è¡Œ", "params": "", "cost": "å…è²»"}]

    wf["mcp_actions"] = actions
    wf["steps"]["execute"]["status"] = "done"
    wf["steps"]["execute"]["output"] = json.dumps(actions, ensure_ascii=False)
    wf["steps"]["execute"]["ts"] = datetime.now().isoformat(timespec="seconds")
    wf["current_step"] = "review"
    wf["updated_at"] = datetime.now().isoformat(timespec="seconds")
    wf["history"].append({"step": "execute", "action": "done", "ts": datetime.now().isoformat(timespec="seconds")})
    _save_wf(wf)

    return {"ok": True, "workflow": wf, "message": "MCP åŸ·è¡Œè¨ˆç•«å·²ç”¢ç”Ÿï¼Œè«‹ç¢ºèªæˆæœ"}


def _step_optimize(wf: dict, role_id: str, idea: str, extra: str = "") -> dict[str, Any]:
    """æ­¥é©Ÿ 6ï¼šAI æå‡ºå„ªåŒ–å»ºè­°ï¼ˆGemini Pro å„ªå…ˆï¼ŒOllama å‚™æ´ï¼‰ã€‚"""
    import role_manager

    role = role_manager.get_role(role_id) or {}
    analysis = wf["steps"]["analyze"].get("output", "")
    execute_output = wf["steps"]["execute"].get("output", "")

    prompt = (
        f"{role.get('system_prompt', '')}\n\n"
        f"ç”¨æˆ¶åŸå§‹éœ€æ±‚ï¼š{idea}\n"
        f"åŸ·è¡Œæ–¹æ¡ˆï¼š{analysis[:800]}\n"
        f"åŸ·è¡Œçµæœï¼š{execute_output[:800]}\n"
        f"{'ç”¨æˆ¶å›é¥‹ï¼š' + extra if extra else ''}\n\n"
        "è«‹æå‡ºå„ªåŒ–å»ºè­°ï¼š\n"
        "1. ã€æˆæœè©•ä¼°ã€‘ç›®å‰æˆæœçš„å„ªç¼ºé»\n"
        "2. ã€å„ªåŒ–æ–¹å‘ã€‘å¯ä»¥æ”¹é€²çš„åœ°æ–¹\n"
        "3. ã€å…·é«”å‹•ä½œã€‘å„ªåŒ–çš„å…·é«”æ­¥é©Ÿ\n"
        "4. ã€é æœŸæ•ˆæœã€‘å„ªåŒ–å¾Œçš„é æœŸæ”¹å–„"
    )
    try:
        optimization = smart_generate(prompt)
    except Exception as e:
        optimization = f"AI å„ªåŒ–åˆ†ææš«æ™‚ä¸å¯ç”¨ï¼š{e}"

    wf["steps"]["optimize"]["status"] = "done"
    wf["steps"]["optimize"]["output"] = optimization
    wf["steps"]["optimize"]["ts"] = datetime.now().isoformat(timespec="seconds")
    wf["current_step"] = "finalize"
    wf["updated_at"] = datetime.now().isoformat(timespec="seconds")
    wf["history"].append({"step": "optimize", "action": "done", "ts": datetime.now().isoformat(timespec="seconds")})
    _save_wf(wf)

    return {"ok": True, "workflow": wf, "message": "AI å„ªåŒ–å»ºè­°å·²ç”¢ç”Ÿï¼Œè«‹æ±ºå®šæ˜¯å¦çµæ¡ˆ"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# çµ±è¨ˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def workflow_stats() -> dict[str, Any]:
    """å·¥ä½œæµçµ±è¨ˆã€‚"""
    all_wf = list_workflows()
    active = sum(1 for w in all_wf if w["status"] == "active")
    completed = sum(1 for w in all_wf if w["status"] == "completed")
    by_role: dict[str, int] = {}
    for w in all_wf:
        rn = w.get("role_name", "æœªçŸ¥")
        by_role[rn] = by_role.get(rn, 0) + 1
    return {
        "ok": True,
        "total": len(all_wf),
        "active": active,
        "completed": completed,
        "by_role": by_role,
        "steps": STEPS,
    }
