#!/usr/bin/env python3
"""
ç¯‰æœªç§‘æŠ€ â€” æœ¬åœ°ç¨ç«‹é‹è¡Œæ¨¡çµ„
æ¼¸é€²å¼è„«é›¢é›²ç«¯ AI è¨‚é–±ï¼Œé”åˆ°çœŸæ­£çš„æœ¬åœ°é‹è¡Œ

GitHub ä¸Šå¯ç”¨çš„é–‹æºæ›¿ä»£æ–¹æ¡ˆæ•´åˆï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é›²ç«¯è¨‚é–±åŠŸèƒ½          â”‚  æœ¬åœ°æ›¿ä»£æ–¹æ¡ˆ              â”‚  ç‹€æ…‹     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ChatGPT / Claude      â”‚  Ollama + Open WebUI       â”‚  âœ… å·²æœ‰  â”‚
â”‚  GPT-4 æ¨ç†            â”‚  Qwen3:8b / 70b            â”‚  âœ… å·²æœ‰  â”‚
â”‚  Copilot å¯«ç¨‹å¼        â”‚  Aider + Qwen3-Coder       â”‚  ğŸ”§ å¯è£  â”‚
â”‚  RAG çŸ¥è­˜åº«            â”‚  ChromaDB + nomic-embed     â”‚  âœ… å·²æœ‰  â”‚
â”‚  å¤š Agent å”ä½œ         â”‚  multi_agent.py v2          â”‚  âœ… å·²æœ‰  â”‚
â”‚  åœ–ç‰‡ç”Ÿæˆ              â”‚  Forge + ComfyUI            â”‚  âœ… å·²æœ‰  â”‚
â”‚  è¦–è¦ºè¾¨è­˜              â”‚  YOLOv8 + moondream         â”‚  âœ… å·²æœ‰  â”‚
â”‚  OCR æ–‡å­—è¾¨è­˜          â”‚  EasyOCR                    â”‚  âœ… å·²æœ‰  â”‚
â”‚  èªéŸ³è½‰æ–‡å­—            â”‚  Whisper.cpp                â”‚  ğŸ”§ å¯è£  â”‚
â”‚  Fine-tuning å¾®èª¿      â”‚  Unsloth + LoRA             â”‚  ğŸ”§ å¯è£  â”‚
â”‚  Prompt è‡ªå‹•å„ªåŒ–       â”‚  DSPy + Ollama              â”‚  ğŸ”§ å¯è£  â”‚
â”‚  é›»è…¦è‡ªå‹•æ“ä½œ          â”‚  Open Interpreter           â”‚  ğŸ”§ å¯è£  â”‚
â”‚  Embedding             â”‚  nomic-embed-text           â”‚  âœ… å·²æœ‰  â”‚
â”‚  çµæ§‹åŒ–è¼¸å‡º            â”‚  guidance + instructor      â”‚  âœ… å·²æœ‰  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç¡¬é«”ï¼šRTX 4060 Ti 8GB + 64GB RAM + i7-14700
"""

import os
import time
import json
import requests
from typing import Dict, List, Optional
from pathlib import Path

OLLAMA_BASE = (os.environ.get("OLLAMA_BASE_URL") or "http://localhost:11460").rstrip("/")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ç¨ç«‹æ€§è©•ä¼°å¼•æ“
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ä½ çš„ç³»çµ±éœ€è¦çš„æ‰€æœ‰ AI èƒ½åŠ›
CAPABILITIES = {
    # â”€â”€ å·²å®Œæˆï¼ˆæœ¬åœ°é‹è¡Œä¸­ï¼‰â”€â”€
    "chat": {
        "name": "å°è©± / å•ç­”",
        "cloud": "ChatGPT $20/æœˆ, Claude $20/æœˆ",
        "local": "Ollama qwen3:8b",
        "status": "local",  # local / partial / cloud / available
        "monthly_saving": 40,
        "tools": ["ollama"],
    },
    "reasoning": {
        "name": "æ·±åº¦æ¨ç†",
        "cloud": "GPT-4o $20/æœˆ, Claude Opus $20/æœˆ",
        "local": "Qwen3:8b (24 tok/s) æˆ– Qwen3:70b Q2 (3-5 tok/s)",
        "status": "local",
        "monthly_saving": 40,
        "tools": ["ollama"],
    },
    "code_generation": {
        "name": "ç¨‹å¼ç¢¼ç”Ÿæˆ",
        "cloud": "GitHub Copilot $10/æœˆ, Cursor $20/æœˆ",
        "local": "Qwen3:8b + CodeSim æ¨¡æ“¬å™¨",
        "status": "local",
        "monthly_saving": 30,
        "tools": ["ollama", "code_simulator"],
    },
    "rag": {
        "name": "çŸ¥è­˜åº« RAG",
        "cloud": "OpenAI Assistants API, Pinecone",
        "local": "ChromaDB + nomic-embed-text + rag_fusion",
        "status": "local",
        "monthly_saving": 30,
        "tools": ["chromadb", "nomic-embed-text"],
    },
    "multi_agent": {
        "name": "å¤š Agent å”ä½œ",
        "cloud": "CrewAI Cloud, AutoGen Studio",
        "local": "multi_agent.py v2 (Tool/Task/Crew)",
        "status": "local",
        "monthly_saving": 0,
        "tools": ["multi_agent"],
    },
    "image_gen": {
        "name": "åœ–ç‰‡ç”Ÿæˆ",
        "cloud": "Midjourney $10/æœˆ, DALL-E API",
        "local": "Forge (SD WebUI) + ComfyUI",
        "status": "local",
        "monthly_saving": 10,
        "tools": ["forge", "comfyui"],
    },
    "vision": {
        "name": "è¦–è¦ºè¾¨è­˜",
        "cloud": "GPT-4V API, Google Vision API",
        "local": "YOLOv8 + moondream VLM + EasyOCR",
        "status": "local",
        "monthly_saving": 20,
        "tools": ["yolov8", "moondream", "easyocr"],
    },
    "embedding": {
        "name": "æ–‡å­—å‘é‡åŒ–",
        "cloud": "OpenAI Embeddings API $0.13/1M tokens",
        "local": "nomic-embed-text (768ç¶­, æœ¬åœ°å…è²»)",
        "status": "local",
        "monthly_saving": 10,
        "tools": ["nomic-embed-text"],
    },
    "structured_output": {
        "name": "çµæ§‹åŒ–è¼¸å‡º",
        "cloud": "OpenAI JSON Mode, Claude Tool Use",
        "local": "guidance + instructor + Ollama",
        "status": "local",
        "monthly_saving": 0,
        "tools": ["guidance", "instructor"],
    },

    # â”€â”€ å¯å®‰è£ï¼ˆGitHub ä¸Šæœ‰æˆç†Ÿæ–¹æ¡ˆï¼‰â”€â”€
    "code_assistant": {
        "name": "AI å¯«ç¨‹å¼åŠ©æ‰‹ï¼ˆIDE æ•´åˆï¼‰",
        "cloud": "GitHub Copilot $10/æœˆ, Cursor $20/æœˆ, Windsurf",
        "local": "Aider + Ollama æˆ– Continue.dev + Ollama",
        "status": "available",
        "monthly_saving": 20,
        "tools": ["aider", "continue.dev"],
        "install": {
            "aider": "pip install aider-chat && aider --model ollama/qwen3:8b",
            "continue": "VS Code å®‰è£ Continue æ“´å±• â†’ è¨­å®š Ollama provider",
        },
        "github": "https://github.com/Aider-AI/aider",
    },
    "speech_to_text": {
        "name": "èªéŸ³è½‰æ–‡å­—",
        "cloud": "OpenAI Whisper API $0.006/åˆ†é˜",
        "local": "faster-whisper 1.2.1 (å·²å®‰è£, GPU åŠ é€Ÿ)",
        "status": "local",
        "monthly_saving": 5,
        "tools": ["faster-whisper"],
    },
    "fine_tuning": {
        "name": "æ¨¡å‹å¾®èª¿ï¼ˆè®“æ¨¡å‹å­¸ä½ çš„é ˜åŸŸï¼‰",
        "cloud": "OpenAI Fine-tuning $25/1M tokens",
        "local": "Unsloth + QLoRA (éœ€ WSL/Dockerï¼ŒWindows Py3.14 ä¸ç›¸å®¹)",
        "status": "available",
        "monthly_saving": 25,
        "tools": ["unsloth"],
        "install": {
            "unsloth": "éœ€åœ¨ WSL2 Ubuntu æˆ– Docker ä¸­åŸ·è¡Œ",
        },
        "github": "https://github.com/unslothai/unsloth",
        "note": "Windows Py3.14 triton/torchvision è¡çªï¼Œéœ€ç”¨ WSL2 æˆ– Docker",
    },
    "prompt_optimization": {
        "name": "Prompt è‡ªå‹•å„ªåŒ–",
        "cloud": "æ‰‹å‹•èª¿ prompt / PromptLayer è¨‚é–±",
        "local": "DSPy 3.1.3 + Ollama (å·²å®‰è£, è‡ªå‹•æ‰¾æœ€ä½³ prompt)",
        "status": "local",
        "monthly_saving": 0,
        "tools": ["dspy"],
    },
    "computer_use": {
        "name": "é›»è…¦è‡ªå‹•æ“ä½œï¼ˆAgent æ§åˆ¶é›»è…¦ï¼‰",
        "cloud": "Claude Computer Use API",
        "local": "Open Interpreter + Ollama (é›¢ç·šæ¨¡å¼)",
        "status": "available",
        "monthly_saving": 20,
        "tools": ["open-interpreter"],
        "install": {
            "open-interpreter": (
                "pip install open-interpreter\n"
                "interpreter.offline = True\n"
                "interpreter.llm.model = 'ollama/qwen3:8b'\n"
                "interpreter.llm.api_base = 'http://localhost:11460'"
            ),
        },
        "github": "https://github.com/openinterpreter/open-interpreter",
    },
    "text_to_speech": {
        "name": "æ–‡å­—è½‰èªéŸ³",
        "cloud": "ElevenLabs $5/æœˆ, OpenAI TTS API",
        "local": "Coqui TTS / Piper TTS (é›¢ç·š, å¤šèªè¨€)",
        "status": "available",
        "monthly_saving": 5,
        "tools": ["piper-tts"],
        "install": {
            "piper": "pip install piper-tts && ä¸‹è¼‰ä¸­æ–‡èªéŸ³æ¨¡å‹",
        },
        "github": "https://github.com/rhasspy/piper",
    },
}


def assess_independence() -> Dict:
    """
    è©•ä¼°ç›®å‰çš„æœ¬åœ°ç¨ç«‹ç¨‹åº¦

    Returns:
        {"score": int, "local_count": int, "total": int,
         "monthly_saving": float, "capabilities": dict,
         "next_steps": list}
    """
    local_count = 0
    available_count = 0
    cloud_count = 0
    total_saving = 0
    potential_saving = 0
    next_steps = []

    for key, cap in CAPABILITIES.items():
        if cap["status"] == "local":
            local_count += 1
            total_saving += cap["monthly_saving"]
        elif cap["status"] == "available":
            available_count += 1
            potential_saving += cap["monthly_saving"]
            if cap.get("github"):
                next_steps.append({
                    "capability": cap["name"],
                    "tool": list(cap.get("install", {}).keys())[0] if cap.get("install") else "",
                    "github": cap.get("github", ""),
                    "saving": cap["monthly_saving"],
                    "note": cap.get("note", ""),
                })
        else:
            cloud_count += 1

    total = len(CAPABILITIES)
    score = int(local_count / total * 100)

    # æ’åºï¼šçœæœ€å¤šéŒ¢çš„å„ªå…ˆ
    next_steps.sort(key=lambda x: x["saving"], reverse=True)

    return {
        "score": score,
        "local_count": local_count,
        "available_count": available_count,
        "cloud_count": cloud_count,
        "total": total,
        "monthly_saving_current": total_saving,
        "monthly_saving_potential": potential_saving,
        "monthly_saving_total": total_saving + potential_saving,
        "next_steps": next_steps,
    }


def check_ollama_models() -> Dict:
    """æª¢æŸ¥ Ollama æœ¬åœ°æ¨¡å‹ç‹€æ…‹"""
    try:
        r = requests.get(f"{OLLAMA_BASE}/api/tags", timeout=5)
        if r.status_code == 200:
            models = r.json().get("models", [])
            total_size = sum(m.get("size", 0) for m in models)
            names = [m["name"] for m in models]

            # æª¢æŸ¥é—œéµæ¨¡å‹
            has_chat = any("qwen3" in n or "zhewei" in n for n in names)
            has_embed = any("nomic" in n or "embed" in n for n in names)
            has_vision = any("moondream" in n or "llava" in n for n in names)
            has_coder = any("coder" in n for n in names)

            return {
                "ok": True,
                "models": names,
                "count": len(models),
                "total_gb": round(total_size / 1e9, 1),
                "has_chat": has_chat,
                "has_embed": has_embed,
                "has_vision": has_vision,
                "has_coder": has_coder,
                "missing": [
                    m for m in ["qwen3-coder:latest"]
                    if not has_coder
                ],
            }
    except Exception as e:
        return {"ok": False, "error": str(e)}
    return {"ok": False, "error": "unknown"}


def get_roadmap() -> Dict:
    """
    å–å¾—å®Œæ•´çš„è„«é›¢è¨‚é–±è·¯ç·šåœ–

    Returns:
        åˆ†éšæ®µçš„è¡Œå‹•è¨ˆç•«
    """
    assessment = assess_independence()

    return {
        "current_score": assessment["score"],
        "phases": [
            {
                "phase": 1,
                "name": "åŸºç¤æœ¬åœ°åŒ–ï¼ˆå·²å®Œæˆï¼‰",
                "status": "done",
                "items": [
                    "âœ… Ollama æœ¬åœ°æ¨ç† (qwen3:8b, 24 tok/s)",
                    "âœ… ChromaDB çŸ¥è­˜åº« + nomic-embed-text",
                    "âœ… Forge/ComfyUI æœ¬åœ°ç”Ÿåœ–",
                    "âœ… YOLOv8 è¦–è¦ºè¾¨è­˜ + EasyOCR",
                    "âœ… multi_agent v2 å¤š Agent å”ä½œ",
                    "âœ… AI SOP ç®¡ç·š (åˆ†é¡/å¿«å–/å“è³ªé–€æª»)",
                ],
                "saving": "~NT$180/æœˆï¼ˆå·²çœä¸‹ï¼‰",
            },
            {
                "phase": 2,
                "name": "é€²éšæœ¬åœ°åŒ–ï¼ˆæ¨è–¦å®‰è£ï¼‰",
                "status": "ready",
                "items": [
                    {
                        "name": "Aider â€” æœ¬åœ° AI å¯«ç¨‹å¼ï¼ˆå–ä»£ Copilot/Cursorï¼‰",
                        "command": "pip install aider-chat",
                        "usage": "aider --model ollama_chat/qwen3:8b --ollama-base-url http://localhost:11460",
                        "github": "https://github.com/Aider-AI/aider",
                        "saving": "NT$600/æœˆ",
                        "priority": "HIGH",
                    },
                    {
                        "name": "Unsloth â€” æœ¬åœ°å¾®èª¿æ¨¡å‹ï¼ˆè®“ AI å­¸ä½ çš„é ˜åŸŸï¼‰",
                        "command": "pip install unsloth",
                        "usage": "ç”¨ä½ çš„ç‡Ÿå»ºçŸ¥è­˜ JSONL å¾®èª¿ qwen3:8b â†’ å°ˆå±¬ç‡Ÿå»º AI",
                        "github": "https://github.com/unslothai/unsloth",
                        "saving": "NT$750/æœˆ",
                        "priority": "HIGH",
                        "note": "RTX 4060 Ti 8GB ç”¨ QLoRA 4-bit å¯èª¿ 8B æ¨¡å‹",
                    },
                    {
                        "name": "DSPy â€” è‡ªå‹•å„ªåŒ– Promptï¼ˆä¸ç”¨æ‰‹èª¿ï¼‰",
                        "command": "pip install dspy",
                        "usage": "è‡ªå‹•æ‰¾åˆ°æœ€ä½³ promptï¼Œå“è³ªæå‡ 20-40%",
                        "github": "https://github.com/stanfordnlp/dspy",
                        "saving": "å“è³ªæå‡ï¼ˆé–“æ¥çœéŒ¢ï¼‰",
                        "priority": "MEDIUM",
                    },
                    {
                        "name": "faster-whisper â€” æœ¬åœ°èªéŸ³è½‰æ–‡å­—",
                        "command": "pip install faster-whisper",
                        "usage": "å·¥åœ°èªéŸ³è¨˜éŒ„ â†’ æ–‡å­—ï¼Œå®Œå…¨é›¢ç·š",
                        "github": "https://github.com/SYSTRAN/faster-whisper",
                        "saving": "NT$150/æœˆ",
                        "priority": "MEDIUM",
                    },
                ],
                "saving": "é¡å¤– ~NT$1,500/æœˆ",
            },
            {
                "phase": 3,
                "name": "å®Œå…¨ç¨ç«‹ï¼ˆçµ‚æ¥µç›®æ¨™ï¼‰",
                "status": "future",
                "items": [
                    {
                        "name": "Qwen3:70b Q2 â€” æœ¬åœ°è·‘ 70B å¤§æ¨¡å‹",
                        "command": "ollama pull qwen3:70b",
                        "usage": "64GB RAM å¯è·‘ï¼Œ3-5 tok/sï¼Œå“è³ªæ¥è¿‘ GPT-4",
                        "note": "ä¸‹è¼‰ç´„ 26GBï¼Œé¦–æ¬¡è¼‰å…¥ 30-60 ç§’",
                        "priority": "HIGH",
                    },
                    {
                        "name": "Open Interpreter â€” AI è‡ªå‹•æ“ä½œé›»è…¦",
                        "command": "pip install open-interpreter",
                        "usage": "ç”¨è‡ªç„¶èªè¨€è®“ AI æ“ä½œä½ çš„é›»è…¦",
                        "github": "https://github.com/openinterpreter/open-interpreter",
                        "priority": "MEDIUM",
                    },
                    {
                        "name": "Piper TTS â€” æœ¬åœ°æ–‡å­—è½‰èªéŸ³",
                        "command": "pip install piper-tts",
                        "usage": "ä¸­æ–‡èªéŸ³åˆæˆï¼Œå®Œå…¨é›¢ç·š",
                        "github": "https://github.com/rhasspy/piper",
                        "priority": "LOW",
                    },
                    {
                        "name": "æŒçºŒå¾®èª¿ â€” ç”¨ Unsloth è®“æ¨¡å‹è¶Šä¾†è¶Šè°æ˜",
                        "usage": "æ¯æœˆæ”¶é›†å°è©±è³‡æ–™ â†’ å¾®èª¿ â†’ æ¨¡å‹æŒçºŒé€²æ­¥",
                        "note": "é€™æ˜¯çœŸæ­£è„«é›¢é›²ç«¯çš„é—œéµï¼šæ¨¡å‹æœƒè¶Šç”¨è¶Šå¥½",
                        "priority": "ONGOING",
                    },
                ],
                "saving": "å®Œå…¨è„«é›¢æ‰€æœ‰è¨‚é–±",
            },
        ],
        "key_insight": (
            "é—œéµæ´å¯Ÿï¼šçœŸæ­£è„«é›¢è¨‚é–±çš„æ ¸å¿ƒä¸æ˜¯ã€Œè·‘æ¨¡å‹ã€ï¼ˆä½ å·²ç¶“åšåˆ°äº†ï¼‰ï¼Œ"
            "è€Œæ˜¯ã€Œè®“æ¨¡å‹æŒçºŒé€²æ­¥ã€ã€‚Unsloth å¾®èª¿ + DSPy è‡ªå‹•å„ªåŒ– prompt "
            "= ä½ çš„æœ¬åœ° AI æœƒè¶Šä¾†è¶Šè°æ˜ï¼Œä¸å†éœ€è¦ä¾è³´é›²ç«¯æ›´æ–°ã€‚"
        ),
        "hardware_status": {
            "gpu": "RTX 4060 Ti 8GB â€” å¯è·‘ â‰¤8B å…¨ GPUï¼Œ14B éƒ¨åˆ† GPUï¼Œ70B æ··åˆ",
            "ram": "64GB DDR4 â€” è¶³å¤ è·‘ 70B Q2 é‡åŒ–æ¨¡å‹",
            "cpu": "i7-14700 20æ ¸28ç·šç¨‹ â€” CPU offload æ•ˆèƒ½å„ªç§€",
            "verdict": "ä½ çš„ç¡¬é«”å·²ç¶“è¶³å¤ é”åˆ° 95% æœ¬åœ°ç¨ç«‹",
        },
    }


def get_cloud_vs_local_comparison() -> List[Dict]:
    """
    é›²ç«¯è¨‚é–± vs æœ¬åœ°æ–¹æ¡ˆçš„è©³ç´°å°æ¯”

    Returns:
        [{"service": str, "monthly_cost": float, "local_alternative": str,
          "quality_ratio": str, "status": str}]
    """
    return [
        {
            "service": "ChatGPT Plus",
            "monthly_cost": 620,  # NT$
            "local_alternative": "Ollama qwen3:8b (å·²å®‰è£)",
            "quality_ratio": "85-90%",
            "status": "å·²æ›¿ä»£",
            "note": "æ—¥å¸¸å°è©±å“è³ªç›¸ç•¶ï¼Œè¤‡é›œæ¨ç†ç¨å¼±",
        },
        {
            "service": "Claude Pro",
            "monthly_cost": 620,
            "local_alternative": "Ollama qwen3:8b + multi_agent v2",
            "quality_ratio": "80-85%",
            "status": "å·²æ›¿ä»£",
            "note": "é•·æ–‡åˆ†æç”¨ multi_agent å¤šæ­¥é©Ÿè£œå„Ÿ",
        },
        {
            "service": "GitHub Copilot",
            "monthly_cost": 310,
            "local_alternative": "Aider + qwen3:8b æˆ– Continue.dev",
            "quality_ratio": "75-85%",
            "status": "å¯å®‰è£",
            "note": "Qwen3-Coder åœ¨ SWE-Bench è¡¨ç¾å„ªç§€",
        },
        {
            "service": "Cursor Pro",
            "monthly_cost": 620,
            "local_alternative": "Aider + qwen3:8b (çµ‚ç«¯) æˆ– Continue.dev (VS Code)",
            "quality_ratio": "70-80%",
            "status": "å¯å®‰è£",
            "note": "è¤‡é›œé‡æ§‹ç”¨ 70B æ¨¡å‹è£œå¼·",
        },
        {
            "service": "Midjourney",
            "monthly_cost": 310,
            "local_alternative": "Forge + NoobAI-XL (å·²å®‰è£)",
            "quality_ratio": "80-90%",
            "status": "å·²æ›¿ä»£",
            "note": "SDXL å“è³ªæ¥è¿‘ï¼Œå¯è‡ªè¨‚æ¨¡å‹",
        },
        {
            "service": "OpenAI API (Embedding)",
            "monthly_cost": 150,
            "local_alternative": "nomic-embed-text (å·²å®‰è£, å…è²»)",
            "quality_ratio": "90-95%",
            "status": "å·²æ›¿ä»£",
            "note": "768ç¶­ï¼Œå“è³ªæ¥è¿‘ text-embedding-3-small",
        },
        {
            "service": "OpenAI API (GPT-4)",
            "monthly_cost": 1000,
            "local_alternative": "Qwen3:70b Q2 (å¯å®‰è£, å…è²»)",
            "quality_ratio": "85-90%",
            "status": "å¯å®‰è£",
            "note": "éœ€ ollama pull qwen3:70b (~26GB)",
        },
        {
            "service": "OpenAI Fine-tuning",
            "monthly_cost": 750,
            "local_alternative": "Unsloth QLoRA (å¯å®‰è£, å…è²»)",
            "quality_ratio": "90-95%",
            "status": "å¯å®‰è£",
            "note": "8GB VRAM å¯èª¿ 8B æ¨¡å‹ï¼Œæ•ˆæœæ›´å¥½å› ç‚ºå®Œå…¨æ§åˆ¶",
        },
    ]


def print_independence_report():
    """å°å‡ºå®Œæ•´çš„ç¨ç«‹æ€§å ±å‘Š"""
    assessment = assess_independence()
    roadmap = get_roadmap()

    print("=" * 60)
    print("  ç¯‰æœªç§‘æŠ€ â€” æœ¬åœ° AI ç¨ç«‹æ€§å ±å‘Š")
    print("=" * 60)
    print()
    print(f"  ç¨ç«‹æ€§åˆ†æ•¸: {assessment['score']}%")
    print(f"  æœ¬åœ°é‹è¡Œ: {assessment['local_count']}/{assessment['total']} é …èƒ½åŠ›")
    print(f"  å¯å®‰è£:   {assessment['available_count']} é …")
    print(f"  å·²çœä¸‹:   NT${assessment['monthly_saving_current']}/æœˆ")
    print(f"  æ½›åœ¨ç¯€çœ: NT${assessment['monthly_saving_potential']}/æœˆ")
    print(f"  å®Œå…¨ç¨ç«‹å¾Œ: NT${assessment['monthly_saving_total']}/æœˆ")
    print()

    for phase in roadmap["phases"]:
        status_icon = {"done": "âœ…", "ready": "ğŸ”§", "future": "ğŸ¯"}
        print(f"  {status_icon.get(phase['status'], '?')} Phase {phase['phase']}: {phase['name']}")
        print(f"     ç¯€çœ: {phase['saving']}")
        print()

    print(f"  ğŸ’¡ {roadmap['key_insight']}")
    print()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å…¨åŸŸä¾¿æ·å‡½æ•¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def independence_score() -> int:
    """å–å¾—ç¨ç«‹æ€§åˆ†æ•¸ (0-100)"""
    return assess_independence()["score"]


def next_steps() -> List[Dict]:
    """å–å¾—ä¸‹ä¸€æ­¥å»ºè­°"""
    return assess_independence()["next_steps"]


if __name__ == "__main__":
    print_independence_report()
