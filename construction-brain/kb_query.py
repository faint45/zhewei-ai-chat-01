# -*- coding: utf-8 -*-
"""
ç¯‰æœªç§‘æŠ€ Construction Brain
kb_query.py

åŠŸèƒ½ï¼š
  å¾æ–½å·¥çŸ¥è­˜åº«ï¼ˆChromaDBï¼‰åšèªæ„æœå°‹ï¼Œ
  çµåˆ Ollama æœ¬åœ°æ¨¡å‹ï¼Œå›ç­”æ–°æ¡ˆå­äººå“¡çš„å•é¡Œ
  ï¼ˆRAGï¼šRetrieval-Augmented Generationï¼‰

ç”¨æ³•ï¼š
    # äº’å‹•å•ç­”æ¨¡å¼
    python kb_query.py --interactive

    # å–®æ¬¡æŸ¥è©¢
    python kb_query.py --question "é‹¼ç­‹æ··å‡åœŸæ©‹å¢©æ–½å·¥æ™‚é¤Šè­·éœ€è¦å¹¾å¤©ï¼Ÿ"

    # é‡å°ç‰¹å®šé¡åˆ¥æŸ¥è©¢
    python kb_query.py --question "æ··å‡åœŸæ¾†ç½®è¦ç¯„" --category æ–½å·¥è¦ç¯„
"""

import argparse
import os
from pathlib import Path

import httpx

BASE_DIR = Path(os.environ.get("ZHEWEI_BASE", r"C:\ZheweiConstruction"))
OLLAMA_BASE_URL = os.environ.get("OLLAMA_BASE_URL", "http://localhost:11434").rstrip("/")
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "zhewei-brain")
OLLAMA_TIMEOUT = float(os.environ.get("OLLAMA_TIMEOUT", "120"))

KB_DIR = BASE_DIR / "db" / "kb_chroma"

RAG_SYSTEM_PROMPT = """ä½ æ˜¯ã€Œç¯‰æœªç§‘æŠ€ã€çš„å·¥åœ°çŸ¥è­˜åº«åŠ©ç†ã€‚

ä½ çš„è§’è‰²æ˜¯å”åŠ©å·¥åœ°ä¸»ä»»ã€ç›£é€ äººå“¡ã€æ–°é€²å·¥ç¨‹å¸«ï¼Œ
å¿«é€Ÿäº†è§£å·¥ç¨‹æ–½å·¥æ–¹æ³•ã€è¦ç¯„è¦æ±‚ã€æ–½å·¥ç¨‹åºã€‚

ã€å›ç­”åŸå‰‡ã€‘
1. å„ªå…ˆå¼•ç”¨æä¾›çš„ã€Œåƒè€ƒè³‡æ–™ã€æ®µè½ï¼Œä¸¦æ¨™æ˜å‡ºè™•ï¼ˆæ–‡ä»¶åç¨±ï¼‰
2. å›ç­”è¦å…·é«”ã€å¯æ“ä½œï¼Œé¿å…æ¨¡ç³Šæ•˜è¿°
3. æ¶‰åŠå®‰å…¨çš„äº‹é …è¦ç‰¹åˆ¥å¼·èª¿
4. æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™æ™‚ï¼Œæ˜ç¢ºèªªã€ŒçŸ¥è­˜åº«ä¸­æœªæ‰¾åˆ°ç›¸é—œè³‡æ–™ï¼Œå»ºè­°æŸ¥é–±åŸå§‹æ–‡ä»¶ã€
5. å›ç­”èªè¨€ï¼šç¹é«”ä¸­æ–‡ï¼Œå°ˆæ¥­è¡“èª
6. æ ¼å¼ï¼šæ¢åˆ—å¼æˆ–è¡¨æ ¼ï¼Œæ–¹ä¾¿å¿«é€Ÿé–±è®€

ã€ç¦æ­¢ã€‘
- ä¸å¾—æé€ å·¥ç¨‹æ•¸æ“šï¼ˆå¦‚æ··å‡åœŸå¼·åº¦ã€é¤Šè­·å¤©æ•¸ç­‰ï¼‰
- æœªåœ¨çŸ¥è­˜åº«ä¸­æ‰¾åˆ°ä¾æ“šæ™‚ï¼Œä¸å¾—è‡†æ¸¬è¦ç¯„è¦æ±‚"""


def _get_collection():
    try:
        import chromadb
        from chromadb.utils import embedding_functions
        client = chromadb.PersistentClient(path=str(KB_DIR))
        ef = embedding_functions.DefaultEmbeddingFunction()
        return client.get_or_create_collection(
            name="construction_kb",
            embedding_function=ef,
        )
    except ImportError:
        print("[kb_query] âš ï¸ chromadb æœªå®‰è£ï¼špip install chromadb")
        return None
    except Exception as e:
        print(f"[kb_query] âš ï¸ ChromaDB é€£ç·šå¤±æ•—ï¼š{e}")
        return None


def retrieve(question: str, top_k: int = 5, category: str = None) -> list[dict]:
    """
    å¾å‘é‡ç´¢å¼•æœå°‹æœ€ç›¸é—œçš„æ®µè½

    Returns:
        list of {text, filename, category, score}
    """
    collection = _get_collection()
    if collection is None:
        return []

    where = {"category": category} if category else None
    try:
        results = collection.query(
            query_texts=[question],
            n_results=min(top_k, collection.count()),
            where=where,
            include=["documents", "metadatas", "distances"],
        )
    except Exception as e:
        print(f"[kb_query] æœå°‹å¤±æ•—ï¼š{e}")
        return []

    chunks = []
    for doc, meta, dist in zip(
        results["documents"][0],
        results["metadatas"][0],
        results["distances"][0],
    ):
        chunks.append({
            "text": doc,
            "filename": meta.get("filename", ""),
            "category": meta.get("category", ""),
            "score": round(1 - dist, 3),
        })
    return chunks


def _build_context(chunks: list[dict]) -> str:
    if not chunks:
        return "ï¼ˆçŸ¥è­˜åº«ä¸­æœªæ‰¾åˆ°ç›¸é—œæ®µè½ï¼‰"
    parts = []
    for i, chunk in enumerate(chunks, 1):
        parts.append(
            f"ã€åƒè€ƒè³‡æ–™ {i}ã€‘ä¾†æºï¼š{chunk['filename']}ï¼ˆ{chunk['category']}ï¼‰\n"
            f"{chunk['text']}"
        )
    return "\n\n".join(parts)


def answer(question: str, top_k: int = 5, category: str = None) -> str:
    """
    RAG å•ç­”ï¼šæœå°‹ + Ollama ç”Ÿæˆå›ç­”

    Args:
        question: å•é¡Œæ–‡å­—
        top_k: å–æœ€ç›¸é—œçš„ K å€‹æ®µè½
        category: é™å®šé¡åˆ¥ï¼ˆé¸å¡«ï¼‰

    Returns:
        AI å›ç­”æ–‡å­—
    """
    print(f"[kb_query] æœå°‹ï¼šã€Œ{question[:50]}ã€")
    chunks = retrieve(question, top_k=top_k, category=category)

    if chunks:
        print(f"[kb_query] æ‰¾åˆ° {len(chunks)} å€‹ç›¸é—œæ®µè½")
        for i, chunk in enumerate(chunks, 1):
            print(f"  [{i}] {chunk['filename']} (ç›¸ä¼¼åº¦: {chunk['score']:.3f})")
    else:
        print("[kb_query] âš ï¸ çŸ¥è­˜åº«ç„¡ç›¸é—œè³‡æ–™ï¼Œä»¥æ¨¡å‹æœ¬èº«çŸ¥è­˜å›ç­”")

    context = _build_context(chunks)
    user_prompt = f"""ä»¥ä¸‹æ˜¯å¾çŸ¥è­˜åº«æ‰¾åˆ°çš„ç›¸é—œåƒè€ƒè³‡æ–™ï¼š

{context}

---

è«‹æ ¹æ“šä¸Šè¿°åƒè€ƒè³‡æ–™ï¼Œå›ç­”ä»¥ä¸‹å•é¡Œï¼š
{question}"""

    payload = {
        "model": OLLAMA_MODEL,
        "messages": [
            {"role": "system", "content": RAG_SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ],
        "stream": False,
        "options": {"temperature": 0.2, "num_ctx": 8192},
    }

    try:
        with httpx.Client(timeout=OLLAMA_TIMEOUT) as client:
            r = client.post(f"{OLLAMA_BASE_URL}/api/chat", json=payload)
            r.raise_for_status()
            return r.json()["message"]["content"].strip()
    except Exception as e:
        return f"[kb_query] âŒ Ollama å‘¼å«å¤±æ•—ï¼š{e}"


def interactive_mode(category: str = None):
    """äº’å‹•å•ç­”æ¨¡å¼"""
    print(f"\n{'='*55}")
    print(f"  ç¯‰æœªç§‘æŠ€ æ–½å·¥çŸ¥è­˜åº« å•ç­”æ¨¡å¼")
    print(f"  çŸ¥è­˜åº«ä½ç½®ï¼š{KB_DIR}")
    if category:
        print(f"  æœå°‹é¡åˆ¥ï¼š{category}")
    print(f"  è¼¸å…¥ 'exit' æˆ– 'quit' é›¢é–‹")
    print(f"{'='*55}\n")

    collection = _get_collection()
    if collection:
        print(f"  çŸ¥è­˜åº«æ®µè½æ•¸ï¼š{collection.count():,}\n")
    else:
        print("  âš ï¸ çŸ¥è­˜åº«å°šæœªå»ºç«‹ï¼Œè«‹å…ˆåŸ·è¡Œ kb_ingest.py\n")

    while True:
        try:
            question = input("ğŸ” ä½ çš„å•é¡Œï¼š").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nå†è¦‹ï¼")
            break

        if not question:
            continue
        if question.lower() in ("exit", "quit", "é›¢é–‹", "é€€å‡º"):
            print("å†è¦‹ï¼")
            break

        print()
        resp = answer(question, category=category)
        print(f"\n{'â”€'*55}")
        print(resp)
        print(f"{'â”€'*55}\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ç¯‰æœªç§‘æŠ€ â€” æ–½å·¥çŸ¥è­˜åº«å•ç­”ï¼ˆRAGï¼‰")
    parser.add_argument("--question", help="å–®æ¬¡æŸ¥è©¢å•é¡Œ")
    parser.add_argument("--category", default=None,
                        choices=["æ–½å·¥æ³•", "åˆ†é …è¨ˆç•«æ›¸", "æ–½å·¥è¦ç¯„", "ç›£é€ è¨ˆç•«", "è¨­è¨ˆåœ–èªª", "å¥‘ç´„", "æ¨™æº–åœ–", "å…¶ä»–"],
                        help="é™å®šæœå°‹é¡åˆ¥")
    parser.add_argument("--interactive", action="store_true", help="äº’å‹•å•ç­”æ¨¡å¼")
    parser.add_argument("--top_k", type=int, default=5, help="å–æœ€ç›¸é—œçš„ K å€‹æ®µè½")
    args = parser.parse_args()

    if args.interactive or not args.question:
        interactive_mode(category=args.category)
    else:
        resp = answer(args.question, top_k=args.top_k, category=args.category)
        print(f"\n{'â”€'*55}")
        print(resp)
        print(f"{'â”€'*55}")
