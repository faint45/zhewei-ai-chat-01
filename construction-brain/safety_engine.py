# -*- coding: utf-8 -*-
"""
ç¯‰æœªç§‘æŠ€ Construction Brain
safety_engine.py

åŠŸèƒ½ï¼š
  æ•´åˆä¾†è‡ª work_eventsï¼ˆèªéŸ³/æ–‡å­—æŠ½å–ï¼‰èˆ‡ photosï¼ˆç…§ç‰‡è¾¨è­˜ï¼‰çš„å·¥å®‰ç¼ºå¤±ï¼Œ
  è¼¸å‡ºï¼š
    - SafetyIssues.csvï¼ˆç¼ºå¤±è¿½è¹¤è¡¨ï¼Œå¯ç”¨ Excel é–‹ï¼‰
    - RectifyPlan.mdï¼ˆæ•´æ”¹è¨ˆç•«æ›¸ï¼‰

ç”¨æ³•ï¼š
    python safety_engine.py --project_id PRJ-001 --date 2026-02-24
    python safety_engine.py --project_id PRJ-001  # ä½¿ç”¨ä»Šå¤©
"""

import argparse
import csv
import json
import os
import sqlite3
import uuid
from datetime import date, datetime, timedelta
from pathlib import Path

BASE_DIR = Path(os.environ.get("ZHEWEI_BASE", r"C:\ZheweiConstruction"))
DB_PATH = BASE_DIR / "db" / "index.db"

SEVERITY_LABEL = {"high": "ğŸ”´ é«˜", "medium": "ğŸŸ¡ ä¸­", "low": "ğŸŸ¢ ä½"}
SEVERITY_DUE_DAYS = {"high": 0, "medium": 1, "low": 3}
SEVERITY_SUGGESTION = {
    "high": "ç«‹å³åœå·¥æ”¹å–„ï¼Œç¢ºèªå®‰å…¨å¾Œæ–¹å¯å¾©å·¥",
    "medium": "æ‡‰æ–¼æœ¬æ—¥å·¥ä½œçµæŸå‰å®Œæˆæ”¹å–„",
    "low": "æ‡‰æ–¼ 3 æ—¥å…§å®Œæˆæ”¹å–„",
}

CSV_FIELDS = [
    "issue_id", "project_id", "date", "location", "issue_type",
    "severity", "description", "suggestion", "owner", "due_date",
    "status", "photo_path", "photo_hash", "source", "verified_by", "verified_at",
]


def _ensure_db():
    if not DB_PATH.exists():
        return
    conn = sqlite3.connect(DB_PATH)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS safety_issues (
            id TEXT PRIMARY KEY,
            project_id TEXT,
            date TEXT,
            location TEXT,
            issue_type TEXT,
            severity TEXT,
            description TEXT,
            suggestion TEXT,
            owner TEXT,
            due_date TEXT,
            status TEXT,
            photo_path TEXT,
            photo_hash TEXT,
            source TEXT,
            verified_by TEXT,
            verified_at TEXT,
            created_at TEXT
        )
    """)
    conn.commit()
    conn.close()


def _load_from_work_events(project_id: str, event_date: str) -> list[dict]:
    if not DB_PATH.exists():
        return []
    conn = sqlite3.connect(DB_PATH)
    rows = conn.execute(
        "SELECT json_data FROM work_events WHERE project_id=? AND date=? AND parse_status='ok'",
        (project_id, event_date),
    ).fetchall()
    conn.close()
    issues = []
    for row in rows:
        data = json.loads(row[0])
        for si in data.get("safety_issues", []):
            issues.append({
                "description": si.get("description", ""),
                "location": si.get("location", ""),
                "severity": si.get("severity", "medium"),
                "source": "line_text_or_voice",
                "photo_path": "",
                "photo_hash": "",
            })
    return issues


def _load_from_photos(project_id: str, event_date: str) -> list[dict]:
    if not DB_PATH.exists():
        return []
    conn = sqlite3.connect(DB_PATH)
    rows = conn.execute(
        """SELECT classified_path, hash, safety_json, location_hint
           FROM photos WHERE project_id=? AND date=? AND photo_type='å·¥å®‰ç¼ºå¤±' AND status='ok'""",
        (project_id, event_date),
    ).fetchall()
    conn.close()
    issues = []
    for row in rows:
        photo_path, photo_hash, safety_json_str, location_hint = row
        try:
            safety_list = json.loads(safety_json_str or "[]")
        except Exception:
            safety_list = []
        if safety_list:
            for si in safety_list:
                issues.append({
                    "description": si.get("description", ""),
                    "location": si.get("location") or location_hint or "",
                    "severity": si.get("severity", "medium"),
                    "source": "line_photo",
                    "photo_path": photo_path,
                    "photo_hash": photo_hash,
                })
        else:
            issues.append({
                "description": "ç…§ç‰‡é¡¯ç¤ºå·¥å®‰ç¼ºå¤±ï¼ˆå¾…äººå·¥ç¢ºèªï¼‰",
                "location": location_hint or "",
                "severity": "medium",
                "source": "line_photo",
                "photo_path": photo_path,
                "photo_hash": photo_hash,
            })
    return issues


def _classify_issue_type(description: str) -> str:
    desc = description.lower()
    mapping = [
        (["å®‰å…¨å¸½", "é ­ç›”"], "æœªæˆ´å®‰å…¨å¸½"),
        (["åå…‰èƒŒå¿ƒ", "èƒŒå¿ƒ"], "æœªç©¿åå…‰èƒŒå¿ƒ"),
        (["å®‰å…¨å¸¶", "ç¹«æ›"], "æœªç¹«å®‰å…¨å¸¶"),
        (["å®‰å…¨é‹", "é‹¼é ­é‹"], "æœªç©¿å®‰å…¨é‹"),
        (["é˜²å¡µ", "å£ç½©"], "æœªæˆ´é˜²å¡µå£ç½©"),
        (["é–‹å£", "è­·æ¬„", "æ´å£", "è­·è“‹"], "é–‹å£æœªè¨­è­·æ¬„"),
        (["é‚Šç·£", "å®‰å…¨ç¶²", "é˜²å¢œç¶²"], "é‚Šç·£æœªè¨­å®‰å…¨ç¶²"),
        (["å‘æ´", "è­¦ç¤º", "è­¦æˆ’"], "å‘æ´æœªè¨­è­¦ç¤º"),
        (["é›»ç·š", "è£¸éœ²", "é›»æ°£"], "é›»ç·šè£¸éœ²æˆ–äº‚æ‹‰"),
        (["æ¼é›»", "æ–·è·¯å™¨", "æ„Ÿé›»"], "è‡¨æ™‚ç”¨é›»ç„¡æ¼é›»æ–·è·¯å™¨"),
        (["é€šé“", "å †æ”¾", "é›œç‰©"], "é€šé“å †æ”¾é›œç‰©"),
        (["åœç±¬", "æ–½å·¥åœ"], "æœªè¨­æ–½å·¥åœç±¬"),
        (["å‹•ç«", "ç„Šæ¥", "åˆ‡å‰²"], "æœªè¾¦ç†å‹•ç«è¨±å¯"),
    ]
    for keywords, issue_type in mapping:
        if any(k in desc for k in keywords):
            return issue_type
    return "å…¶ä»–å·¥å®‰ç¼ºå¤±"


def _deduplicate(issues: list[dict]) -> list[dict]:
    seen = set()
    result = []
    for iss in issues:
        key = (iss["description"][:30], iss["location"][:20])
        if key not in seen:
            seen.add(key)
            result.append(iss)
    return result


def _build_issue_rows(issues: list[dict], project_id: str, event_date: str) -> list[dict]:
    rows = []
    counter = 1
    for iss in issues:
        severity = iss.get("severity", "medium")
        due_days = SEVERITY_DUE_DAYS.get(severity, 1)
        due_date = (date.fromisoformat(event_date) + timedelta(days=due_days)).isoformat()
        issue_type = _classify_issue_type(iss.get("description", ""))
        row = {
            "issue_id": f"SAF-{event_date.replace('-','')}-{counter:03d}",
            "project_id": project_id,
            "date": event_date,
            "location": iss.get("location", ""),
            "issue_type": issue_type,
            "severity": severity,
            "description": iss.get("description", ""),
            "suggestion": SEVERITY_SUGGESTION.get(severity, ""),
            "owner": "",
            "due_date": due_date,
            "status": "open",
            "photo_path": iss.get("photo_path", ""),
            "photo_hash": iss.get("photo_hash", ""),
            "source": iss.get("source", ""),
            "verified_by": "",
            "verified_at": "",
        }
        rows.append(row)
        counter += 1
    return rows


def _save_to_db(rows: list[dict]):
    _ensure_db()
    if not rows:
        return
    conn = sqlite3.connect(DB_PATH)
    for row in rows:
        conn.execute(
            """INSERT OR IGNORE INTO safety_issues
               (id,project_id,date,location,issue_type,severity,description,
                suggestion,owner,due_date,status,photo_path,photo_hash,source,
                verified_by,verified_at,created_at)
               VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)""",
            (row["issue_id"], row["project_id"], row["date"], row["location"],
             row["issue_type"], row["severity"], row["description"], row["suggestion"],
             row["owner"], row["due_date"], row["status"], row["photo_path"],
             row["photo_hash"], row["source"], row["verified_by"], row["verified_at"],
             datetime.now().isoformat()),
        )
    conn.commit()
    conn.close()


def generate_safety_csv(project_id: str, event_date: str) -> Path:
    issues_from_events = _load_from_work_events(project_id, event_date)
    issues_from_photos = _load_from_photos(project_id, event_date)
    all_issues = _deduplicate(issues_from_events + issues_from_photos)
    rows = _build_issue_rows(all_issues, project_id, event_date)
    _save_to_db(rows)

    out_dir = BASE_DIR / "projects" / project_id / "02_Output" / "Reports" / event_date
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "SafetyIssues.csv"

    with open(out_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=CSV_FIELDS)
        writer.writeheader()
        writer.writerows(rows)

    high_count = sum(1 for r in rows if r["severity"] == "high")
    med_count = sum(1 for r in rows if r["severity"] == "medium")
    print(f"[safety] âœ… SafetyIssues.csv â†’ {out_path}")
    print(f"[safety]    é«˜é¢¨éšª:{high_count} ä»¶ï½œä¸­é¢¨éšª:{med_count} ä»¶ï½œåˆè¨ˆ:{len(rows)} ä»¶")
    return out_path


def generate_rectify_plan(project_id: str, event_date: str) -> Path:
    if not DB_PATH.exists():
        return None

    conn = sqlite3.connect(DB_PATH)
    rows = conn.execute(
        """SELECT issue_id,location,issue_type,severity,description,suggestion,due_date,photo_path
           FROM safety_issues WHERE project_id=? AND date=? AND status='open'
           ORDER BY CASE severity WHEN 'high' THEN 1 WHEN 'medium' THEN 2 ELSE 3 END""",
        (project_id, event_date),
    ).fetchall()
    conn.close()

    cfg_path = BASE_DIR / "config" / f"{project_id}.json"
    cfg = json.loads(cfg_path.read_text(encoding="utf-8")) if cfg_path.exists() else {}

    lines = []
    lines.append("# å·¥å®‰ç¼ºå¤±æ•´æ”¹è¨ˆç•«æ›¸")
    lines.append("")
    lines.append(f"**å·¥ç¨‹åç¨±ï¼š** {cfg.get('project_name', project_id)}")
    lines.append(f"**ç™¼ç¾æ—¥æœŸï¼š** {event_date}")
    lines.append(f"**å·¥åœ°ä¸»ä»»ï¼š** {cfg.get('supervisor', '')}")
    lines.append(f"**ç”¢ç”Ÿæ™‚é–“ï¼š** {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    lines.append("")
    lines.append("---")
    lines.append("")

    if not rows:
        lines.append("æœ¬æ—¥ç„¡å·¥å®‰ç¼ºå¤±è¨˜éŒ„ã€‚")
    else:
        high_rows = [r for r in rows if r[3] == "high"]
        med_rows = [r for r in rows if r[3] == "medium"]
        low_rows = [r for r in rows if r[3] == "low"]

        lines.append(f"## ç¼ºå¤±æ‘˜è¦ï¼šå…± {len(rows)} é …")
        lines.append("")
        lines.append(f"| åš´é‡åº¦ | ä»¶æ•¸ |")
        lines.append(f"|-------|------|")
        lines.append(f"| ğŸ”´ é«˜é¢¨éšªï¼ˆç«‹å³æ”¹å–„ï¼‰ | {len(high_rows)} ä»¶ |")
        lines.append(f"| ğŸŸ¡ ä¸­é¢¨éšªï¼ˆæœ¬æ—¥æ”¹å–„ï¼‰ | {len(med_rows)} ä»¶ |")
        lines.append(f"| ğŸŸ¢ ä½é¢¨éšªï¼ˆ3æ—¥å…§æ”¹å–„ï¼‰| {len(low_rows)} ä»¶ |")
        lines.append("")
        lines.append("---")
        lines.append("")

        for i, row in enumerate(rows, 1):
            issue_id, location, issue_type, severity, description, suggestion, due_date, photo_path = row
            sev_label = SEVERITY_LABEL.get(severity, severity)
            lines.append(f"## ç¼ºå¤± {i}ï¼š{issue_type}ã€€{sev_label}")
            lines.append("")
            lines.append(f"| é …ç›® | å…§å®¹ |")
            lines.append(f"|------|------|")
            lines.append(f"| ç¼ºå¤±ç·¨è™Ÿ | {issue_id} |")
            lines.append(f"| ä½ç½® | {location} |")
            lines.append(f"| æè¿° | {description} |")
            lines.append(f"| æ•´æ”¹å»ºè­° | {suggestion} |")
            lines.append(f"| æ‡‰æ”¹å–„æœŸé™ | {due_date} |")
            lines.append(f"| è²¬ä»»å–®ä½ | ï¼ˆå¡«å¯«ï¼‰ |")
            lines.append(f"| ç¢ºèªç‹€æ…‹ | â¬œ å¾…ç¢ºèª |")
            if photo_path:
                lines.append(f"| ç…§ç‰‡ | `{Path(photo_path).name}` |")
            lines.append("")
            lines.append("**æ•´æ”¹ç¢ºèªç°½ç« ï¼šï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ã€€æ—¥æœŸï¼šï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿**")
            lines.append("")
            lines.append("---")
            lines.append("")

    lines.append("")
    lines.append("> æœ¬æ•´æ”¹è¨ˆç•«ç”±ã€Œç¯‰æœªç§‘æŠ€ Construction Brainã€è‡ªå‹•ç”¢ç”Ÿï½œè«‹å·¥åœ°ä¸»ä»»ç¢ºèªå¾Œç°½ç½²")

    out_dir = BASE_DIR / "projects" / project_id / "02_Output" / "Reports" / event_date
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "RectifyPlan.md"
    out_path.write_text("\n".join(lines), encoding="utf-8")
    print(f"[safety] âœ… RectifyPlan.md â†’ {out_path}")
    return out_path


def run(project_id: str, event_date: str):
    print(f"\n{'='*50}")
    print(f"  ç¯‰æœªç§‘æŠ€ å·¥å®‰ç¼ºå¤±å¼•æ“")
    print(f"  å°ˆæ¡ˆï¼š{project_id}ã€€æ—¥æœŸï¼š{event_date}")
    print(f"{'='*50}\n")
    csv_path = generate_safety_csv(project_id, event_date)
    rectify_path = generate_rectify_plan(project_id, event_date)
    if rectify_path:
        print(f"\nå®Œæˆï¼è«‹æŸ¥çœ‹ï¼š\n  {csv_path}\n  {rectify_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ç¯‰æœªç§‘æŠ€ â€” å·¥å®‰ç¼ºå¤±æ•´åˆå¼•æ“")
    parser.add_argument("--project_id", required=True)
    parser.add_argument("--date", default="")
    args = parser.parse_args()
    run(args.project_id, args.date or date.today().isoformat())
