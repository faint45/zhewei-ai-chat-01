# -*- coding: utf-8 -*-
"""
ç¯‰æœªç§‘æŠ€ Construction Brain
daily_report_writer.py

åŠŸèƒ½ï¼šè®€å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰ work_eventsï¼Œå½™ç¸½è¼¸å‡ºï¼š
  - DailyReport.mdï¼ˆå…¬å…±å·¥ç¨‹æ–½å·¥æ—¥èªŒæ ¼å¼ï¼‰
  - Progress.csvï¼ˆé€²åº¦è¿½è¹¤è¡¨ï¼‰

ç”¨æ³•ï¼š
    python daily_report_writer.py --project_id PRJ-001 --date 2026-02-24
    python daily_report_writer.py --project_id PRJ-001  # ä½¿ç”¨ä»Šå¤©æ—¥æœŸ
"""

import argparse
import csv
import json
import os
import sqlite3
import uuid
from datetime import date, datetime
from pathlib import Path

BASE_DIR = Path(os.environ.get("ZHEWEI_BASE", r"C:\ZheweiConstruction"))
DB_PATH = BASE_DIR / "db" / "index.db"


def _load_project_config(project_id: str) -> dict:
    config_path = BASE_DIR / "config" / f"{project_id}.json"
    if config_path.exists():
        return json.loads(config_path.read_text(encoding="utf-8"))
    return {
        "project_name": project_id,
        "contractor": "",
        "contract_period": "",
        "start_date": "",
        "end_date": "",
        "supervisor": "",
    }


def _load_events(project_id: str, event_date: str) -> list[dict]:
    if not DB_PATH.exists():
        return []
    conn = sqlite3.connect(DB_PATH)
    rows = conn.execute(
        "SELECT json_data FROM work_events WHERE project_id=? AND date=? AND parse_status='ok'",
        (project_id, event_date),
    ).fetchall()
    conn.close()
    return [json.loads(r[0]) for r in rows]


def _load_photos_index(project_id: str, event_date: str) -> list[dict]:
    if not DB_PATH.exists():
        return []
    conn = sqlite3.connect(DB_PATH)
    rows = conn.execute(
        """SELECT photo_type, sub_type, location_hint, classified_path, description
           FROM photos WHERE project_id=? AND date=? AND status='ok'""",
        (project_id, event_date),
    ).fetchall()
    conn.close()
    return [
        {"type": r[0], "sub_type": r[1], "location": r[2], "path": r[3], "desc": r[4]}
        for r in rows
    ]


def _calc_elapsed_days(start_date_str: str, event_date_str: str) -> int:
    try:
        start = date.fromisoformat(start_date_str)
        target = date.fromisoformat(event_date_str)
        return (target - start).days + 1
    except Exception:
        return 0


def _merge_lists(events: list[dict], key: str) -> list[dict]:
    result = []
    for ev in events:
        result.extend(ev.get(key, []))
    return result


def _first_non_null(events: list[dict], key: str):
    for ev in events:
        val = ev.get(key)
        if val and val != "null":
            return val
    return None


def generate_daily_report(project_id: str, event_date: str) -> Path:
    """
    å½™ç¸½ç•¶æ—¥æ‰€æœ‰ work_eventsï¼Œè¼¸å‡º DailyReport.md
    å›å‚³è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    """
    cfg = _load_project_config(project_id)
    events = _load_events(project_id, event_date)
    photos = _load_photos_index(project_id, event_date)

    elapsed = _calc_elapsed_days(cfg.get("start_date", ""), event_date)
    weather_am = _first_non_null(events, "weather_am") or "â€”"
    weather_pm = _first_non_null(events, "weather_pm") or "â€”"

    work_items = _merge_lists(events, "work_items")
    materials = _merge_lists(events, "materials")
    labor = _merge_lists(events, "labor")
    equipment = _merge_lists(events, "equipment")
    safety_issues = _merge_lists(events, "safety_issues")
    problems = list({p for ev in events for p in ev.get("problems", [])})
    plan_tomorrow = list({p for ev in events for p in ev.get("plan_tomorrow", [])})
    notices = list({n for ev in events for n in ev.get("notices", [])})
    important_notes = list({n for ev in events for n in ev.get("important_notes", [])})

    lines = []
    lines.append("# å…¬å…±å·¥ç¨‹æ–½å·¥æ—¥èªŒ")
    lines.append("")
    lines.append(f"**è¡¨æ ¼ç·¨è™Ÿï¼š** {event_date.replace('-','')}_{project_id}")
    lines.append(f"**æœ¬æ—¥å¤©æ°£ï¼š** ä¸Šåˆ {weather_am}ã€€ä¸‹åˆ {weather_pm}")
    lines.append(f"**å¡«è¡¨æ—¥æœŸï¼š** {event_date}")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("## å·¥ç¨‹åŸºæœ¬è³‡æ–™")
    lines.append("")
    lines.append(f"| é …ç›® | å…§å®¹ |")
    lines.append(f"|------|------|")
    lines.append(f"| å·¥ç¨‹åç¨± | {cfg.get('project_name','')} |")
    lines.append(f"| æ‰¿æ”¬å» å•† | {cfg.get('contractor','')} |")
    lines.append(f"| é–‹å·¥æ—¥æœŸ | {cfg.get('start_date','')} |")
    lines.append(f"| ç«£å·¥æ—¥æœŸ | {cfg.get('end_date','')} |")
    lines.append(f"| ç´¯è¨ˆå·¥æœŸ | {elapsed} å¤© |")
    lines.append(f"| é å®šé€²åº¦ | {cfg.get('planned_progress_pct','')}% |")
    lines.append(f"| å·¥åœ°ä¸»ä»» | {cfg.get('supervisor','')} |")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("## ä¸€ã€ä¾æ–½å·¥è¨ˆç•«è¡Œç¨‹ä¹‹æ–½å·¥æ¦‚æ³")
    lines.append("")
    if work_items:
        lines.append("| å·¥å€/é‡Œç¨‹ | å·¥é … | å–®ä½ | æœ¬æ—¥å®Œæˆé‡ | ç´¯è¨ˆå®Œæˆé‡ | é€²åº¦% | å‚™è¨» |")
        lines.append("|----------|------|------|-----------|-----------|-------|------|")
        for wi in work_items:
            loc = wi.get("location") or ""
            item = wi.get("item") or ""
            unit = wi.get("unit") or ""
            qty = wi.get("qty_today") if wi.get("qty_today") is not None else "â€”"
            pct = wi.get("progress_pct") if wi.get("progress_pct") is not None else "â€”"
            note = wi.get("notes") or ""
            lines.append(f"| {loc} | {item} | {unit} | {qty} | â€” | {pct} | {note} |")
    else:
        lines.append("ï¼ˆæœ¬æ—¥ç„¡æ–½å·¥è¨˜éŒ„ï¼‰")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("## äºŒã€å·¥åœ°ææ–™ç®¡ç†æ¦‚æ³")
    lines.append("")
    if materials:
        lines.append("| ææ–™åç¨± | å–®ä½ | æœ¬æ—¥ä½¿ç”¨é‡ | å» å•† | å‚™è¨» |")
        lines.append("|---------|------|-----------|------|------|")
        for m in materials:
            name = m.get("name") or ""
            unit = m.get("unit") or ""
            qty = m.get("qty_today") if m.get("qty_today") is not None else "â€”"
            supplier = m.get("supplier") or ""
            note = m.get("notes") or ""
            lines.append(f"| {name} | {unit} | {qty} | {supplier} | {note} |")
    else:
        lines.append("ï¼ˆæœ¬æ—¥ç„¡ææ–™è¨˜éŒ„ï¼‰")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("## ä¸‰ã€å·¥åœ°äººå“¡åŠæ©Ÿå…·ç®¡ç†")
    lines.append("")
    lines.append("### äººåŠ›")
    if labor:
        lines.append("| å·¥åˆ¥ | æœ¬æ—¥äººæ•¸ |")
        lines.append("|------|---------|")
        for lb in labor:
            trade = lb.get("trade") or ""
            cnt = lb.get("count_today") if lb.get("count_today") is not None else "â€”"
            lines.append(f"| {trade} | {cnt} |")
    else:
        lines.append("ï¼ˆæœ¬æ—¥ç„¡äººåŠ›è¨˜éŒ„ï¼‰")
    lines.append("")
    lines.append("### æ©Ÿå…·")
    if equipment:
        lines.append("| æ©Ÿå…·åç¨± | æœ¬æ—¥ä½¿ç”¨æ•¸é‡ |")
        lines.append("|---------|------------|")
        for eq in equipment:
            name = eq.get("name") or ""
            cnt = eq.get("count_today") if eq.get("count_today") is not None else "â€”"
            lines.append(f"| {name} | {cnt} |")
    else:
        lines.append("ï¼ˆæœ¬æ—¥ç„¡æ©Ÿå…·è¨˜éŒ„ï¼‰")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("## å››ã€æœ¬æ—¥æ–½å·¥é …ç›®ä¹‹æŠ€è¡“å£«ï¼ˆäººå·¥ç¢ºèªï¼‰")
    lines.append("")
    lines.append("- [ ] æ–½å·¥é …ç›®éœ€è¦æŠ€è¡“å£«è³‡æ ¼ã€€â–¡æœ‰ã€€â–¡ç„¡ï¼ˆæ­¤é …å¦‚å‹¾é¸ã€Œæœ‰ã€ï¼Œæ‡‰é™„è¡¨ï¼‰")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("## äº”ã€å…¬å…±å ´æ‰€å®‰å…¨è¡›ç”Ÿäº‹é …")
    lines.append("")
    lines.append("### (ä¸€) æ–½å·¥å‰æª¢æŸ¥äº‹é …")
    lines.append("")
    lines.append("- [ ] 1. æ–½å·¥å‹¤å‰æ•™è‚²ï¼ˆå«å·¥åœ°é é˜²ç½å®³åŠå±å®¢å‘ŠçŸ¥ï¼‰ã€€â–¡æœ‰ã€€â–¡ç„¡")
    lines.append("- [ ] 2. ç¢ºèªæ–°é€²å‹å·¥æ˜¯å¦æŠ•ä¿å‹å·¥ä¿éšªã€€â–¡æœ‰ã€€â–¡ç„¡ã€€â–¡æ–°é€²å‹å·¥")
    lines.append("- [ ] 3. æª¢æŸ¥å‹å·¥å€‹äººé˜²è­·å…·ã€€â–¡æœ‰ã€€â–¡ç„¡")
    lines.append("")
    lines.append("### (äºŒ) å·¥å®‰ç¼ºå¤±è¨˜éŒ„")
    lines.append("")
    if safety_issues:
        lines.append("| ç¼ºå¤±æè¿° | ä½ç½® | åš´é‡åº¦ | å»ºè­°æ”¹å–„ |")
        lines.append("|---------|------|-------|---------|")
        severity_map = {"high": "ğŸ”´ é«˜", "medium": "ğŸŸ¡ ä¸­", "low": "ğŸŸ¢ ä½"}
        for si in safety_issues:
            desc = si.get("description") or ""
            loc = si.get("location") or ""
            sev = severity_map.get(si.get("severity", ""), si.get("severity", ""))
            suggestion = "è«‹ç«‹å³æ”¹å–„" if si.get("severity") == "high" else "æ‡‰æ–¼æœ¬æ—¥å…§æ”¹å–„"
            lines.append(f"| {desc} | {loc} | {sev} | {suggestion} |")
    else:
        lines.append("ï¼ˆæœ¬æ—¥ç„¡å·¥å®‰ç¼ºå¤±è¨˜éŒ„ï¼‰")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("## å…­ã€æ–½å·¥å–æ¨£è©¦é©—ç´€éŒ„")
    lines.append("")
    lines.append("ï¼ˆäººå·¥å¡«å¯«ï¼‰")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("## ä¸ƒã€é€šçŸ¥å”åŠ›å» å•†è¾¦ç†äº‹é …")
    lines.append("")
    if notices:
        for i, n in enumerate(notices, 1):
            lines.append(f"{i}. {n}")
    else:
        lines.append("ï¼ˆç„¡ï¼‰")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("## å…«ã€é‡è¦äº‹é …è¨˜éŒ„")
    lines.append("")
    all_important = problems + important_notes
    if all_important:
        for i, n in enumerate(all_important, 1):
            lines.append(f"{i}. {n}")
    else:
        lines.append("ï¼ˆç„¡ï¼‰")
    lines.append("")

    if plan_tomorrow:
        lines.append("---")
        lines.append("")
        lines.append("## ä¹ã€æ˜æ—¥æ–½å·¥è¨ˆç•«")
        lines.append("")
        for i, p in enumerate(plan_tomorrow, 1):
            lines.append(f"{i}. {p}")
        lines.append("")

    if photos:
        lines.append("---")
        lines.append("")
        lines.append("## ä»Šæ—¥é™„ä»¶ç´¢å¼•")
        lines.append("")
        lines.append("| é¡åˆ¥ | å­é¡å‹ | ä½ç½® | èªªæ˜ | æª”å |")
        lines.append("|------|-------|------|------|------|")
        for ph in photos:
            fname = Path(ph["path"]).name if ph.get("path") else ""
            lines.append(
                f"| {ph.get('type','')} | {ph.get('sub_type','')} | "
                f"{ph.get('location','')} | {ph.get('desc','')} | {fname} |"
            )
        lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("**ç°½ç« ï¼šå·¥åœ°ä¸»ä»» ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿**")
    lines.append("")
    lines.append(f"> æœ¬æ—¥èªŒç”±ã€Œç¯‰æœªç§‘æŠ€ Construction Brainã€è‡ªå‹•å½™æ•´ç”¢ç”Ÿï½œ{datetime.now().strftime('%Y-%m-%d %H:%M')}")

    out_dir = BASE_DIR / "projects" / project_id / "02_Output" / "Reports" / event_date
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "DailyReport.md"
    out_path.write_text("\n".join(lines), encoding="utf-8")
    print(f"[daily_report] âœ… DailyReport.md â†’ {out_path}")
    return out_path


def generate_progress_csv(project_id: str, event_date: str) -> Path:
    """
    å½™ç¸½ç•¶æ—¥æ‰€æœ‰ work_events çš„ work_itemsï¼Œè¼¸å‡º Progress.csv
    åŒä¸€å¤©é‡è·‘ï¼šè¦†è“‹åŒ event_date çš„åˆ—
    """
    events = _load_events(project_id, event_date)
    work_items = _merge_lists(events, "work_items")

    out_dir = BASE_DIR / "projects" / project_id / "02_Output" / "Reports" / event_date
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "Progress.csv"

    cumulative_path = BASE_DIR / "projects" / project_id / "02_Output" / "Progress_cumulative.csv"

    fieldnames = [
        "project_id", "date", "section", "trade", "work_item",
        "unit", "qty_today", "qty_cumulative", "qty_contract",
        "progress_pct", "status", "notes", "source", "event_id",
    ]

    existing_rows = []
    if cumulative_path.exists():
        with open(cumulative_path, newline="", encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            existing_rows = [r for r in reader if r.get("date") != event_date]

    new_rows = []
    for wi in work_items:
        qty_today = wi.get("qty_today")
        qty_prev = sum(
            float(r.get("qty_today") or 0)
            for r in existing_rows
            if r.get("work_item") == wi.get("item") and r.get("section") == wi.get("location")
        )
        qty_cumulative = (qty_prev + float(qty_today)) if qty_today is not None else qty_prev

        row = {
            "project_id": project_id,
            "date": event_date,
            "section": wi.get("location") or "",
            "trade": "",
            "work_item": wi.get("item") or "",
            "unit": wi.get("unit") or "",
            "qty_today": qty_today if qty_today is not None else "",
            "qty_cumulative": round(qty_cumulative, 3),
            "qty_contract": "",
            "progress_pct": wi.get("progress_pct") if wi.get("progress_pct") is not None else "",
            "status": "in_progress",
            "notes": wi.get("notes") or "",
            "source": "auto",
            "event_id": "",
        }
        new_rows.append(row)

    with open(out_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(new_rows)

    all_rows = existing_rows + new_rows
    with open(cumulative_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(all_rows)

    print(f"[daily_report] âœ… Progress.csv â†’ {out_path}")
    print(f"[daily_report] âœ… ç´¯è¨ˆé€²åº¦è¡¨æ›´æ–° â†’ {cumulative_path}")
    return out_path


def run(project_id: str, event_date: str):
    print(f"\n{'='*50}")
    print(f"  ç¯‰æœªç§‘æŠ€ æ—¥å ±ç”¢ç”Ÿå™¨")
    print(f"  å°ˆæ¡ˆï¼š{project_id}ã€€æ—¥æœŸï¼š{event_date}")
    print(f"{'='*50}\n")
    events = _load_events(project_id, event_date)
    if not events:
        print("[daily_report] âš ï¸ æ‰¾ä¸åˆ°ä»Šæ—¥å·¥é …è³‡æ–™ï¼Œæ—¥å ±å°‡ä»¥ç©ºç™½æ ¼å¼è¼¸å‡º")

    report_path = generate_daily_report(project_id, event_date)
    csv_path = generate_progress_csv(project_id, event_date)
    print(f"\nå®Œæˆï¼è«‹æŸ¥çœ‹ï¼š\n  {report_path}\n  {csv_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ç¯‰æœªç§‘æŠ€ â€” æ–½å·¥æ—¥èªŒ + é€²åº¦ CSV ç”¢ç”Ÿå™¨")
    parser.add_argument("--project_id", required=True, help="å°ˆæ¡ˆä»£ç¢¼")
    parser.add_argument("--date", default="", help="æ—¥æœŸ YYYY-MM-DDï¼ˆç©º=ä»Šå¤©ï¼‰")
    args = parser.parse_args()
    run(args.project_id, args.date or date.today().isoformat())
