# -*- coding: utf-8 -*-
"""
ç¯‰æœªç§‘æŠ€ â€” Ollama å­¸ç¿’æ§åˆ¶æ¨¡çµ„
è®“ AI å”åŠ©æ§åˆ¶æœ¬åœ° Ollama æ¨¡å‹é€²è¡Œå­¸ç¿’

åŠŸèƒ½ï¼š
- æ¨¡å‹è¨“ç·´ç‹€æ…‹ç›£æ§
- è‡ªå‹•åŒ–å­¸ç¿’æµç¨‹
- å­¸ç¿’å…§å®¹èƒå–èˆ‡å„²å­˜
"""

import asyncio
import json
import os
import subprocess
import time
from pathlib import Path
from typing import Optional, Callable
import urllib.request
import urllib.error

ROOT = Path(__file__).resolve().parent
OLLAMA_BASE_URL = os.environ.get("OLLAMA_BASE_URL", "http://localhost:11434")

class OllamaLearningController:
    """
    Ollama å­¸ç¿’æ§åˆ¶å™¨
    å”åŠ©ç”¨æˆ¶æ§åˆ¶æœ¬åœ°æ¨¡å‹é€²è¡Œå­¸ç¿’
    """
    
    def __init__(self, stream_callback: Optional[Callable] = None):
        self.base_url = OLLAMA_BASE_URL
        self.stream_callback = stream_callback
        self.active_learnings: dict[str, dict] = {}  # é€²è¡Œä¸­çš„å­¸ç¿’ä»»å‹™
        
    async def check_status(self) -> dict:
        """æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹"""
        try:
            req = urllib.request.Request(f"{self.base_url}/api/tags", method="GET")
            with urllib.request.urlopen(req, timeout=5) as r:
                data = json.loads(r.read())
                return {
                    "status": "online",
                    "models": data.get("models", []),
                    "count": len(data.get("models", [])),
                }
        except urllib.error.URLError as e:
            return {
                "status": "offline",
                "error": f"ç„¡æ³•é€£æ¥ Ollama: {str(e)}",
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
            }
    
    async def learn_topic(
        self,
        topic: str,
        session_id: str,
        depth: str = "standard",  # quick, standard, deep
        sources: list[str] = None
    ) -> dict:
        """
        å­¸ç¿’æ–°ä¸»é¡Œ
        
        æµç¨‹ï¼š
        1. åˆ†æä¸»é¡Œç¯„åœ
        2. æŸ¥è©¢ç¾æœ‰çŸ¥è­˜åº«
        3. ç”¢ç”Ÿå­¸ç¿’è¨ˆåŠƒ
        4. åŸ·è¡Œå¤šè¼ªå­¸ç¿’
        5. èƒå–ç²¾è¯å„²å­˜
        """
        learning_id = f"learn_{session_id}_{int(time.time())}"
        
        self.active_learnings[learning_id] = {
            "id": learning_id,
            "topic": topic,
            "status": "started",
            "progress": 0,
            "started_at": time.time(),
            "results": [],
        }
        
        await self._emit({
            "stage": "learning_init",
            "message": f"ğŸ“š åˆå§‹åŒ–å­¸ç¿’ä»»å‹™: {topic}",
            "learning_id": learning_id,
        })
        
        try:
            # Step 1: åˆ†æä¸»é¡Œ
            await self._emit({
                "stage": "analysis",
                "message": "ğŸ” åˆ†æä¸»é¡Œç¯„åœèˆ‡é—œéµæ¦‚å¿µ...",
                "progress": 10,
            })
            
            topic_analysis = await self._analyze_topic(topic)
            
            # Step 2: æŸ¥è©¢çŸ¥è­˜åº«
            await self._emit({
                "stage": "knowledge_check",
                "message": "ğŸ“– æª¢æŸ¥ç¾æœ‰çŸ¥è­˜åº«...",
                "progress": 20,
            })
            
            existing_knowledge = await self._check_existing_knowledge(topic)
            
            # Step 3: ç”¢ç”Ÿå­¸ç¿’è¨ˆåŠƒ
            await self._emit({
                "stage": "planning",
                "message": "ğŸ“‹ ç”¢ç”Ÿå€‹æ€§åŒ–å­¸ç¿’è¨ˆåŠƒ...",
                "progress": 30,
            })
            
            learning_plan = await self._generate_learning_plan(
                topic, topic_analysis, existing_knowledge, depth
            )
            
            # Step 4: åŸ·è¡Œå­¸ç¿’
            total_subtopics = len(learning_plan.get("subtopics", []))
            
            for idx, subtopic in enumerate(learning_plan.get("subtopics", [])):
                progress = 30 + (idx / max(total_subtopics, 1)) * 50
                
                await self._emit({
                    "stage": "learning_subtopic",
                    "message": f"ğŸ§  å­¸ç¿’ [{idx+1}/{total_subtopics}]: {subtopic['title']}",
                    "progress": int(progress),
                    "subtopic": subtopic,
                })
                
                # ä½¿ç”¨æœ¬åœ° Ollama é€²è¡Œå­¸ç¿’
                learning_result = await self._learn_with_ollama(subtopic)
                
                # ç²¾ä¿®èƒå–
                await self._emit({
                    "stage": "extracting",
                    "message": f"âœ¨ èƒå–çŸ¥è­˜ç²¾è¯...",
                    "progress": int(progress + 5),
                })
                
                essence = await self._extract_essence(learning_result, subtopic)
                
                self.active_learnings[learning_id]["results"].append({
                    "subtopic": subtopic,
                    "essence": essence,
                })
                
                # å„²å­˜åˆ°çŸ¥è­˜åº«
                await self._store_knowledge(topic, subtopic, essence)
            
            # Step 5: å®Œæˆ
            self.active_learnings[learning_id]["status"] = "completed"
            self.active_learnings[learning_id]["completed_at"] = time.time()
            
            await self._emit({
                "stage": "completed",
                "message": f"ğŸ‰ å­¸ç¿’å®Œæˆï¼å·²å­¸ç¿’ {total_subtopics} å€‹å­ä¸»é¡Œ",
                "progress": 100,
                "summary": {
                    "topic": topic,
                    "subtopics_learned": total_subtopics,
                    "duration_seconds": int(time.time() - self.active_learnings[learning_id]["started_at"]),
                },
            })
            
            return {
                "ok": True,
                "learning_id": learning_id,
                "topic": topic,
                "subtopics": total_subtopics,
                "results": self.active_learnings[learning_id]["results"],
            }
            
        except Exception as e:
            self.active_learnings[learning_id]["status"] = "failed"
            self.active_learnings[learning_id]["error"] = str(e)
            
            await self._emit({
                "stage": "failed",
                "message": f"âŒ å­¸ç¿’å¤±æ•—: {str(e)}",
                "error": str(e),
            })
            
            return {
                "ok": False,
                "error": str(e),
                "learning_id": learning_id,
            }
    
    async def _analyze_topic(self, topic: str) -> dict:
        """åˆ†æä¸»é¡Œç¯„åœ"""
        # é€™è£¡å¯ä»¥æ•´åˆå¤–éƒ¨ AI é€²è¡Œä¸»é¡Œåˆ†æ
        # æš«æ™‚ä½¿ç”¨ç°¡å–®çš„çµæ§‹åŒ–è¼¸å‡º
        return {
            "topic": topic,
            "domain": self._detect_domain(topic),
            "complexity": "medium",
            "estimated_subtopics": 3,
        }
    
    def _detect_domain(self, topic: str) -> str:
        """æª¢æ¸¬ä¸»é¡Œé ˜åŸŸ"""
        topic_lower = topic.lower()
        domains = {
            "programming": ["code", "ç¨‹å¼", "python", "javascript", "é–‹ç™¼", "api"],
            "construction": ["ç‡Ÿå»º", "å·¥ç¨‹", "å»ºç¯‰", "æ–½å·¥", "åœŸæœ¨", "çµæ§‹"],
            "business": ["å•†æ¥­", "ç®¡ç†", "è¡ŒéŠ·", "ç‡Ÿé‹", "ç­–ç•¥"],
            "science": ["ç§‘å­¸", "ç‰©ç†", "åŒ–å­¸", "ç”Ÿç‰©", "ç ”ç©¶"],
            "technology": ["ç§‘æŠ€", "ai", "æ©Ÿå™¨å­¸ç¿’", "å€å¡Šéˆ", "é›²ç«¯"],
        }
        
        for domain, keywords in domains.items():
            if any(kw in topic_lower for kw in keywords):
                return domain
        return "general"
    
    async def _check_existing_knowledge(self, topic: str) -> list:
        """æª¢æŸ¥çŸ¥è­˜åº«ä¸­æ˜¯å¦å·²æœ‰ç›¸é—œçŸ¥è­˜"""
        try:
            # å˜—è©¦å°å…¥ä¸¦æŸ¥è©¢çŸ¥è­˜åº«
            import sys
            sys.path.insert(0, str(ROOT))
            from jarvis_brain import search_knowledge
            
            results = search_knowledge(topic, top_k=3)
            return results
        except Exception:
            return []
    
    async def _generate_learning_plan(
        self,
        topic: str,
        analysis: dict,
        existing: list,
        depth: str
    ) -> dict:
        """ç”¢ç”Ÿå­¸ç¿’è¨ˆåŠƒ"""
        # ä½¿ç”¨ Ollama ç”Ÿæˆå­¸ç¿’è¨ˆåŠƒ
        prompt = f"""è«‹ç‚ºä¸»é¡Œã€Œ{topic}ã€ç”¢ç”Ÿä¸€å€‹å­¸ç¿’è¨ˆåŠƒã€‚

é ˜åŸŸ: {analysis['domain']}
æ·±åº¦: {depth}
å·²æœ‰çŸ¥è­˜: {len(existing)} æ¢ç›¸é—œè¨˜éŒ„

è«‹è¼¸å‡º JSON æ ¼å¼:
{{
    "overview": "ä¸»é¡Œæ¦‚è¿°",
    "subtopics": [
        {{"title": "å­ä¸»é¡Œ1", "key_points": ["è¦é»1", "è¦é»2"]}},
        {{"title": "å­ä¸»é¡Œ2", "key_points": ["è¦é»1", "è¦é»2"]}}
    ]
}}

å­ä¸»é¡Œæ•¸é‡: {3 if depth == 'quick' else 5 if depth == 'standard' else 8}"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å­¸ç¿’è¦åŠƒå°ˆå®¶ã€‚è«‹ç”¢ç”Ÿçµæ§‹åŒ–çš„å­¸ç¿’è¨ˆåŠƒã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        try:
            from ai_service import OllamaService
            ollama = OllamaService()
            response = await ollama.chat(messages)
            
            # å˜—è©¦è§£æ JSON
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except Exception:
            pass
        
        # å›é€€åˆ°é è¨­è¨ˆåŠƒ
        return {
            "overview": f"å­¸ç¿’ {topic} çš„åŸºç¤çŸ¥è­˜",
            "subtopics": [
                {"title": f"{topic} åŸºç¤æ¦‚å¿µ", "key_points": ["å®šç¾©", "èƒŒæ™¯"]},
                {"title": f"{topic} æ ¸å¿ƒåŸç†", "key_points": ["åŸç†1", "åŸç†2"]},
                {"title": f"{topic} å¯¦éš›æ‡‰ç”¨", "key_points": ["æ‡‰ç”¨å ´æ™¯", "æ¡ˆä¾‹"]},
            ],
        }
    
    async def _learn_with_ollama(self, subtopic: dict) -> str:
        """ä½¿ç”¨ Ollama å­¸ç¿’å­ä¸»é¡Œ"""
        prompt = f"""è«‹è©³ç´°è§£é‡‹ã€Œ{subtopic['title']}ã€ã€‚

é—œéµè¦é»:
{chr(10).join('- ' + kp for kp in subtopic.get('key_points', []))}

è«‹æä¾›:
1. æ ¸å¿ƒæ¦‚å¿µè§£é‡‹
2. è©³ç´°èªªæ˜
3. å¯¦éš›ä¾‹å­
4. ç›¸é—œçŸ¥è­˜é€£çµ"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜è¬›å¸«ï¼Œè«‹è©³ç´°ä¸”æ¸…æ™°åœ°è§£é‡‹çŸ¥è­˜é»ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        from ai_service import OllamaService
        ollama = OllamaService()
        return await ollama.chat(messages)
    
    async def _extract_essence(self, content: str, subtopic: dict) -> str:
        """èƒå–çŸ¥è­˜ç²¾è¯"""
        prompt = f"""è«‹å°‡ä»¥ä¸‹å…§å®¹èƒå–æˆçŸ¥è­˜ç²¾è¯ï¼ˆ3-5 å€‹é‡é»ï¼‰ã€‚

ä¸»é¡Œ: {subtopic['title']}
å…§å®¹:
{content[:2000]}  # é™åˆ¶é•·åº¦

è«‹è¼¸å‡ºç°¡æ½”çš„ç²¾è¯æ‘˜è¦ï¼Œæ¯å€‹é‡é»ä¸€è¡Œã€‚"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹çŸ¥è­˜èƒå–å°ˆå®¶ã€‚è«‹æå–æ ¸å¿ƒé‡é»ï¼Œå»é™¤å†—é¤˜ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        try:
            from ai_service import OllamaService
            ollama = OllamaService()
            return await ollama.chat(messages)
        except Exception:
            # å¦‚æœèƒå–å¤±æ•—ï¼Œè¿”å›å‰ 500 å­—ä½œç‚ºç²¾è¯
            return content[:500] + "..."
    
    async def _store_knowledge(self, topic: str, subtopic: dict, essence: str):
        """å„²å­˜çŸ¥è­˜åˆ°çŸ¥è­˜åº«"""
        try:
            import sys
            sys.path.insert(0, str(ROOT))
            from local_learning_system import add_knowledge
            
            question = f"{topic} - {subtopic['title']} æ˜¯ä»€éº¼ï¼Ÿ"
            add_knowledge(question, essence, source="ollama_learning")
        except Exception as e:
            print(f"å„²å­˜çŸ¥è­˜å¤±æ•—: {e}")
    
    async def _emit(self, data: dict):
        """ç™¼é€é€²åº¦æ›´æ–°"""
        if self.stream_callback:
            await self.stream_callback(data)
    
    def get_learning_status(self, learning_id: str) -> dict:
        """å–å¾—å­¸ç¿’ä»»å‹™ç‹€æ…‹"""
        return self.active_learnings.get(learning_id, {"status": "not_found"})

# ä¾¿æ·å‡½æ•¸
async def quick_learn(topic: str, stream_callback: Optional[Callable] = None) -> dict:
    """å¿«é€Ÿå­¸ç¿’ä¸€å€‹ä¸»é¡Œ"""
    controller = OllamaLearningController(stream_callback)
    return await controller.learn_topic(topic, "quick_session", depth="quick")

# æ¸¬è©¦
if __name__ == "__main__":
    async def test():
        async def print_progress(data):
            print(f"[{data.get('stage')}] {data.get('message')}")
        
        controller = OllamaLearningController(print_progress)
        
        # æª¢æŸ¥ç‹€æ…‹
        status = await controller.check_status()
        print(f"Ollama ç‹€æ…‹: {status}")
        
        # å­¸ç¿’æ¸¬è©¦
        if status['status'] == 'online':
            result = await controller.learn_topic(
                "FastAPI WebSocket å³æ™‚é€šè¨Š",
                "test_session",
                depth="quick"
            )
            print(f"\nå­¸ç¿’çµæœ: {result}")
    
    asyncio.run(test())
