<<<<<<< HEAD
# 築未科技大腦 — Docker Compose
# 啟動：docker compose up -d
# 需 .env 內 CLOUDFLARE_TOKEN（tunnel 用）

services:
  # 築未大腦核心服務
  brain_server:
    build: .
    container_name: zhewei_brain
    environment:
      BRAIN_WORKSPACE: /app
      ZHEWEI_MEMORY_ROOT: /memory
      BRAIN_WS_PORT: "8000"
    volumes:
      # 使用專案目錄為 /app（本機無 D 槽時相容）；有 D 槽且已複製專案到 D:\brain_workspace 時可改為：D:/brain_workspace:/app
      - .:/app
      # 本機無 Z 槽時使用專案內 zhewei_memory；有 Z 槽時可改為：Z:/Zhewei_Brain:/memory
      - ./zhewei_memory:/memory
    ports:
      - "8000:8000"
    restart: unless-stopped

  # Cloudflare 加密隧道通道
  tunnel:
    image: cloudflare/cloudflared:latest
    restart: always
    command: tunnel --no-autoupdate run --token ${CLOUDFLARE_TOKEN}
    depends_on:
      - brain_server

=======
# 築未科技七階段系統 - Docker Compose 配置

version: '3.8'

services:
  # 總指揮官 - Gemini Pro 服務
  commander:
    build:
      context: .
      dockerfile: Dockerfile.commander
    container_name: zhewei-commander
    volumes:
      - ./D:/brain_workspace:/workspace
      - ./logs:/logs
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - WORKSPACE=/workspace
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - zhewei-network
    restart: unless-stopped

  # 首席開發官 - Claude Pro 服務
  lead-dev:
    build:
      context: .
      dockerfile: Dockerfile.lead-dev
    container_name: zhewei-lead-dev
    volumes:
      - ./D:/brain_workspace:/workspace
      - ./logs:/logs
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - CLAUDE_MODEL=${CLAUDE_MODEL:-claude-3-5-sonnet-20241022}
      - WORKSPACE=/workspace
    networks:
      - zhewei-network
    depends_on:
      - commander
    restart: unless-stopped

  # 地端勤務兵 - Ollama 服務
  local-guard:
    image: ollama/ollama:latest
    container_name: zhewei-ollama
    volumes:
      - ollama_data:/root/.ollama
      - ./D:/brain_workspace:/workspace
    ports:
      - "11461:11434"
    environment:
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2.5:latest}
    networks:
      - zhewei-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # 基礎設施 - 統一API服務器
  api-server:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: zhewei-api
    volumes:
      - ./D:/brain_workspace:/workspace
      - ./logs:/logs
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8005:8005"
    environment:
      - WORKSPACE=/workspace
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - CORS_ORIGINS=${CORS_ORIGINS:-*}
    networks:
      - zhewei-network
    depends_on:
      - commander
      - lead-dev
      - local-guard
    restart: unless-stopped

  # 監控服務
  monitoring:
    build:
      context: .
      dockerfile: Dockerfile.monitoring
    container_name: zhewei-monitoring
    volumes:
      - ./logs:/logs
      - ./api_monitoring.db:/data/api_monitoring.db
    ports:
      - "8002:8001"
    environment:
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - zhewei-network
    depends_on:
      - api-server
    restart: unless-stopped

volumes:
  ollama_data:
    driver: local

networks:
  zhewei-network:
    driver: bridge
>>>>>>> bd6537def53debaba0c16f279817e4a317eed98c
