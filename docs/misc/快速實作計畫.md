# 築未科技大腦 - 快速實作計畫

**目標**：最快、最穩定的遠端對話系統  
**技術選型**：Web + WebSocket  
**預計時間**：1-3 小時完成基礎功能  
**日期**：2026/02/04

---

## 一、技術選型總結

### ✅ 推薦方案：Web + WebSocket

| 評估項目 | 評分 | 說明 |
|----------|------|------|
| 實現速度 | ⭐⭐⭐⭐⭐ | 現有代碼，1-2 小時完成 |
| 跨平台性 | ⭐⭐⭐⭐⭐ | PC、iOS、任何瀏覽器 |
| 用戶體驗 | ⭐⭐⭐⭐⭐ | 美觀界面，即時通訊 |
| 穩定性 | ⭐⭐⭐⭐⭐ | WebSocket 成熟技術 |
| 維護成本 | ⭐⭐⭐⭐⭐ | 單一服務，易於維護 |

---

## 二、實作步驟

### 階段 1：基礎功能（30 分鐘）

**目標：啟動服務並測試基本對話**

#### 步驟 1.1：檢查現有文件（5 分鐘）

```bash
# 檢查 brain_server.py
python brain_server.py --help 2>&1 | head

# 檢查 remote_brain.html
ls -la remote_brain.html

# 檢查 Ollama 狀態
ollama list
```

#### 步驟 1.2：啟動 brain_server（5 分鐘）

```bash
# 啟動服務
python brain_server.py

# 應該看到：
# 啟動築未科技大腦服務器...
# WebSocket 端點: ws://localhost:8000/ws/chat
# REST API: http://localhost:8000/api/chat
```

#### 步驟 1.3：測試本地訪問（5 分鐘）

```bash
# 方式 1：瀏覽器
# 打開瀏覽器訪問 http://localhost:8000

# 方式 2：curl 測試
curl http://localhost:8000/health

# 方式 3：Python 測試
import requests
response = requests.get("http://localhost:8000/health")
print(response.json())
```

#### 步驟 1.4：測試遠端訪問（5 分鐘）

```bash
# 從筆電或手機訪問
# http://100.116.133.23:8000

# 測試 Tailscale 連接
ping 100.116.133.23
```

#### 步驟 1.5：測試對話（10 分鐘）

```bash
# 在瀏覽器界面
1. 打開 http://localhost:8000
2. 發送消息："你好"
3. 查看回應
4. 發送複雜問題測試
```

---

### 階段 2：配置 Ollama（30 分鐘）

**目標：配置本地模型並測試**

#### 步驟 2.1：檢查 Ollama 安裝（5 分鐘）

```bash
# 檢查 Ollama 版本
ollama version

# 如果未安裝，訪問：https://ollama.ai/
```

#### 步驟 2.2：拉取模型（10 分鐘）

```bash
# 拉推薦模型
ollama pull llama3.2

# 可選：拉取代碼專用模型
ollama pull codellama:7b

# 查看已安裝模型
ollama list
```

#### 步驟 2.3：測試 Ollama（5 分鐘）

```bash
# 測試模型運行
ollama run llama3.2

# 發送測試消息
"你好，請自我介紹"
"請寫一個 Python Hello World 程序"
```

#### 步驟 2.4：配置環境變量（10 分鐘）

```bash
# 創建 .env 文件
echo "AI_MODEL_TYPE=ollama" > .env
echo "OLLAMA_BASE_URL=http://localhost:11434" >> .env

# 或者設置系統環境變量
# Windows PowerShell:
$env:AI_MODEL_TYPE="ollama"
$env:OLLAMA_BASE_URL="http://localhost:11434"

# 重啟 brain_server
```

---

### 階段 3：優化界面（1-2 小時）

**目標：創建美觀易用的對話界面**

#### 步驟 3.1：檢查現有界面（5 分鐘）

```bash
# 檢查 remote_brain.html
cat remote_brain.html

# 訪問並評估
# http://localhost:8000
```

#### 步驟 3.2：創建新版界面（1-1.5 小時）

**功能清單：**

- ✅ 美觀的聊天界面
- ✅ Markdown 渲染（使用 marked.js）
- ✅ 代碼高亮（使用 highlight.js）
- ✅ 響應式設計（適配 iOS）
- ✅ 深色模式切換
- ✅ 加載動畫

**技術棧：**
- HTML5
- CSS3（Flexbox + Grid）
- Vanilla JavaScript
- WebSocket API
- marked.js（Markdown）
- highlight.js（代碼高亮）

#### 步驟 3.3：測試界面（30 分鐘）

**測試場景：**

1. PC 瀏覽器（Chrome/Firefox/Edge）
2. iOS Safari（橫屏/豎屏）
3. 深色/淺色模式切換
4. 代碼顯示效果
5. Markdown 渲染效果

---

### 階段 4：進階功能（1-2 小時）

**目標：增強用戶體驗**

#### 步驟 4.1：對話歷史（30 分鐘）

```python
# 在 brain_server.py 中添加
- 保存對話歷史到 SQLite
- 按用戶 ID 管理歷史
- 支持歷史查詢和清除
```

#### 步驟 4.2：會話管理（30 分鐘）

```python
# 添加會話功能
- 支持多個對話會話
- 會話切換
- 會話重命名
- 會話刪除
```

#### 步驟 4.3：狀態顯示（30 分鐘）

```python
# 添加狀態面板
- 當前使用的模型
- Ollama 連接狀態
- 系統資源使用率
- 對話統計
```

#### 步驟 4.4：模型切換（30 分鐘）

```python
# 添加模型切換功能
- 手動切換模型（Llama 3 / Code Llama）
- 自動選擇模型（根據任務類型）
- 模型狀態顯示
```

---

### 階段 5：測試與優化（1-2 小時）

**目標：確保穩定可靠**

#### 步驟 5.1：多設備測試（30 分鐘）

| 設備 | 瀏覽器 | 測試項目 |
|------|--------|----------|
| PC 筆電 | Chrome | 對話、代碼、Markdown |
| PC 桌機 | Firefox | 深色模式、響應式 |
| iOS 手機 | Safari | 豎屏、橫屏、觸控 |
| Android 手機 | Chrome | 所有功能 |

#### 步驟 5.2：性能優化（30 分鐘）

| 優化項目 | 方法 | 預期效果 |
|----------|------|----------|
| 消息壓縮 | 減少傳輸數據量 | 快 20% |
| 流式輸出 | 逐步顯示回應 | 體驗提升 50% |
| 快取機制 | 快取常見問題 | 快 50% |
| 並發處理 | 支持多個會話 | 並發能力提升 |

#### 步驟 5.3：錯誤處理（30 分鐘）

```python
# 添加錯誤處理
- WebSocket 斷線重連
- API 調用失敗重試
- 友好的錯誤提示
- 日誌記錄
```

#### 步驟 5.4：文檔編寫（30 分鐘）

**文檔清單：**

- ✅ 快速開始指南
- ✅ iOS 使用指南
- ✅ 功能說明
- ✅ 故障排查
- ✅ API 文檔

---

## 三、今天的目標（30 分鐘完成）

### ✅ 最快啟動路徑

```bash
# 1. 啟動服務（1 分鐘）
python brain_server.py

# 2. 測試訪問（2 分鐘）
# 本地：http://localhost:8000
# 遠端：http://100.116.133.23:8000

# 3. 測試對話（5 分鐘）
# 發送 "你好"
# 發送 "請寫一個 Hello World 程序"

# 4. 配置 Ollama（10 分鐘）
# 拉取模型：ollama pull llama3.2
# 設置環境變量
# 重啟服務

# 5. 測試本地模型（10 分鐘）
# 測試對話響應速度
# 測試編碼能力
```

**總計：30 分鐘完成基礎功能！**

---

## 四、iOS 使用指南

### 4.1 瀏覽器訪問

```
1. 打開 Safari
2. 輸入：http://100.116.133.23:8000
3. 等待頁面加載
4. 開始對話
```

### 4.2 添加到主屏幕（PWA 體驗）

```
1. Safari > 分享按鈕（方框箭頭）
2. 向下滑動找到"添加到主屏幕"
3. 點擊"添加"
4. 確認名稱和圖標
5. 點擊"添加"
```

**效果：**
- ✅ 像原生 App 一樣
- ✅ 全屏運行
- ✅ 支持深色模式

### 4.3 Shortcuts 快捷指令

**創建一鍵對話快捷指令：**

```
1. 打開 Shortcuts App
2. 點擊 "+" 創建新快捷指令
3. 點擊搜索，搜索"打開 URL"
4. 輸入 URL：http://100.116.133.23:8000
5. 點擊"下一步"
6. 輸入名稱："築未科技大腦"
7. 點擊"完成"
8. 長按快捷指令 > 添加到主屏幕
```

---

## 五、進階功能實作（可選）

### 5.1 語音輸入（未來功能）

**技術方案：**
- Web Speech API（瀏覽器原生）
- 錄音 → 語音識別 → 文字 → AI → 回應
- 可選：語音合成（文字轉語音）

**實作時間：** 2-3 小時

### 5.2 文件上傳（未來功能）

**功能：**
- 上傳文件給 AI 分析
- 支持代碼文件
- 支持圖片文件（圖像識別）

**實作時間：** 2-3 小時

### 5.3 推送通知（未來功能）

**技術方案：**
- Pushover
- Telegram Bot
- iOS 推送

**實作時間：** 1-2 小時

---

## 六、故障排查

### 6.1 服務無法啟動

```bash
# 檢查端口是否被占用
netstat -ano | findstr :8000

# 檢查 Python 版本
python --version

# 檢查依賴
pip list | findstr fastapi
pip list | findstr uvicorn
```

### 6.2 WebSocket 連接失敗

```bash
# 檢查防火牆
# 允許端口 8000

# 檢查 Tailscale 連接
tailscale status

# 檢查瀏覽器控制台
# F12 > Console > 查看錯誤
```

### 6.3 Ollama 連接失敗

```bash
# 檢查 Ollama 服務
ollama list

# 檢查端口
netstat -ano | findstr :11434

# 重啟 Ollama
# Windows：服務管理器重啟
# macOS/Linux: brew services restart ollama
```

### 6.4 iOS Safari 問題

```bash
# 常見問題：
- CORS 錯誤：檢查 brain_server.py 的 CORS 配置
- WebSocket 連接失敗：檢查 Tailscale 連接
- 頁面空白：檢查 HTML 文件路徑
```

---

## 七、性能優化建議

### 7.1 模型選擇

| 任務類型 | 推薦模型 | 原因 |
|----------|----------|------|
| 對話 | Llama 3.2 | 回應自然，速度快 |
| 編碼 | Code Llama | 專門優化 |
| 創作 | Llama 3.2 | 創造力強 |
| 分析 | Llama 3.2 | 理解能力好 |

### 7.2 快取策略

```python
# 實現 LRU 快取
- 快存最近使用的問題和答案
- 快存時間：1 小時
- 快存大小：100 條記錄
```

### 7.3 流式輸出

```python
# 實現 SSE（Server-Sent Events）
- 逐步輸出回應
- 減少感知延遲
- 提升用戶體驗
```

---

## 八、總結

### ✅ 今天可以完成（30 分鐘）

1. 啟動 brain_server.py
2. 測試本地訪問
3. 測試遠端訪問
4. 配置 Ollama
5. 測試本地模型對話

### ✅ 本週可以完成（3-5 小時）

1. 優化界面
2. 添加 Markdown 支持和代碼高亮
3. 實現對話歷史
4. 添加會話管理
5. 完善文檔

### ✅ 未來可以擴展（5-10 小時）

1. 語音輸入
2. 文件上傳
3. 推送通知
4. 圖像識別
5. 多語言支持

---

## 九、立即開始

**最快啟動方式：**

```bash
# 1. 啟動服務
python brain_server.py

# 2. 訪問
http://100.116.133.23:8000

# 3. 開始對話！
```

**準備好了嗎？讓我們立即開始！** 🚀
