# ç¯‰æœªç§‘æŠ€ â€” æ··åˆéƒ¨ç½²æŒ‡å—ï¼ˆæ–¹æ¡ˆ Cï¼‰

## ğŸ¯ æ¶æ§‹æ¦‚è¦½

**æ··åˆéƒ¨ç½²**ï¼šé›²ç«¯ + æœ¬åœ°æœ€ä½³çµ„åˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é›²ç«¯ VPS (24/7)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Ollama   â”‚  â”‚ Brain  â”‚  â”‚ CMS â”‚  â”‚CodeSim â”‚         â”‚
â”‚  â”‚ (CPU)    â”‚  â”‚ Server â”‚  â”‚     â”‚  â”‚        â”‚         â”‚
â”‚  â”‚ è¼•é‡æ¨¡å‹  â”‚  â”‚        â”‚  â”‚     â”‚  â”‚        â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â”‚
â”‚       â”‚            â”‚           â”‚         â”‚              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                    â”‚                                     â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚            â”‚ Cloudflare     â”‚                           â”‚
â”‚            â”‚ Tunnel         â”‚                           â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Internet
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æœ¬åœ°ä¸»æ©Ÿï¼ˆéœ€è¦æ™‚é–‹æ©Ÿï¼‰                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Ollama   â”‚  â”‚ Vision â”‚  â”‚ ComfyUI â”‚  â”‚  Dify   â”‚  â”‚
â”‚  â”‚ (GPU)    â”‚  â”‚   AI   â”‚  â”‚  ç”Ÿåœ–   â”‚  â”‚         â”‚  â”‚
â”‚  â”‚ å¤§æ¨¡å‹    â”‚  â”‚ YOLOv8 â”‚  â”‚         â”‚  â”‚         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚            â”‚             â”‚            â”‚        â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                    â”‚                                    â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚            â”‚ Cloudflare     â”‚                          â”‚
â”‚            â”‚ Tunnel (Local) â”‚                          â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ æ–¹æ¡ˆå„ªå‹¢

### âœ… å„ªé»
1. **æˆæœ¬æœ€å„ª**ï¼šé›²ç«¯åƒ…éœ€ $12/æœˆï¼ˆ2GB VPSï¼‰
2. **æ€§èƒ½æœ€ä½³**ï¼šæœ¬åœ° GPU è™•ç†è¦–è¦ºèˆ‡å¤§æ¨¡å‹
3. **ç©©å®šå¯é **ï¼šæ ¸å¿ƒæœå‹™ 24/7 é›²ç«¯é‹è¡Œ
4. **å½ˆæ€§æ“´å±•**ï¼šæœ¬åœ°é—œæ©Ÿæ™‚é™ç´šç‚ºé›²ç«¯è¼•é‡æ¨¡å‹

### ğŸ“Š æœå‹™åˆ†é…

| æœå‹™ | ä½ç½® | åŸå›  | é–‹æ©Ÿéœ€æ±‚ |
|------|------|------|----------|
| Brain Server | é›²ç«¯ | æ ¸å¿ƒæœå‹™ï¼Œ24/7 éœ€æ±‚ | å¿…é ˆ |
| Portal | é›²ç«¯ | å…¥å£é é¢ï¼Œ24/7 éœ€æ±‚ | å¿…é ˆ |
| CMS | é›²ç«¯ | ç‡Ÿå»ºç®¡ç†ï¼Œ24/7 éœ€æ±‚ | å¿…é ˆ |
| CodeSim | é›²ç«¯ | ä»£ç¢¼æ¨¡æ“¬ï¼Œ24/7 éœ€æ±‚ | å¿…é ˆ |
| Prediction | é›²ç«¯ | é æ¸¬ç³»çµ±ï¼Œ24/7 éœ€æ±‚ | å¿…é ˆ |
| Ollama (CPU) | é›²ç«¯ | è¼•é‡æ¨¡å‹å‚™æ´ | å¿…é ˆ |
| Ollama (GPU) | æœ¬åœ° | å¤§æ¨¡å‹æ¨ç† | å¯é¸ |
| Vision AI | æœ¬åœ° | YOLOv8 éœ€ GPU | å¯é¸ |
| ComfyUI | æœ¬åœ° | ç”Ÿåœ–éœ€ GPU | å¯é¸ |
| Dify | æœ¬åœ° | AI å¹³å° | å¯é¸ |

---

## ğŸš€ éƒ¨ç½²æ­¥é©Ÿ

### éšæ®µ 1ï¼šé›²ç«¯ VPS éƒ¨ç½²

#### 1.1 å»ºç«‹ VPSï¼ˆLinode æ¨è–¦ï¼‰

```bash
# è¦æ ¼å»ºè­°
- CPU: 2 vCPU
- RAM: 2GB
- å„²å­˜: 50GB SSD
- æµé‡: 2TB/æœˆ
- æˆæœ¬: $12/æœˆ
```

#### 1.2 å®‰è£ Docker

```bash
ssh ubuntu@YOUR_VPS_IP

# å®‰è£ Docker
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# ç™»å‡ºå†ç™»å…¥
exit
ssh ubuntu@YOUR_VPS_IP
```

#### 1.3 éƒ¨ç½²é›²ç«¯æœå‹™

```bash
cd /opt
sudo mkdir zhewei && sudo chown $USER:$USER zhewei
cd zhewei

# Clone å°ˆæ¡ˆ
git clone YOUR_REPO .

# è¨­å®šç’°å¢ƒè®Šæ•¸
cat > .env << 'EOF'
# Cloudflare Tunnel Token
CLOUDFLARE_TOKEN=your_cloudflare_tunnel_token

# AI Provider Keys
GEMINI_API_KEY=your_gemini_api_key
GROQ_API_KEY=your_groq_api_key
DEEPSEEK_API_KEY=your_deepseek_api_key

# Ollama è¨­å®šï¼ˆé›²ç«¯ CPU ç‰ˆï¼‰
OLLAMA_BASE_URL=http://ollama:11434
AI_COST_MODE=smart_route

# æœ¬åœ° GPU Ollamaï¼ˆé€é Tunnelï¼‰
OLLAMA_GPU_URL=https://ollama-gpu.zhe-wei.net
EOF

# åŸ·è¡Œéƒ¨ç½²
chmod +x scripts/deploy_to_cloud.sh
./scripts/deploy_to_cloud.sh
```

---

### éšæ®µ 2ï¼šæœ¬åœ°ä¸»æ©Ÿè¨­å®š

#### 2.1 å®‰è£ Cloudflare Tunnelï¼ˆWindowsï¼‰

```powershell
# å®‰è£ cloudflared
winget install Cloudflare.cloudflared

# ç™»å…¥ Cloudflare
cloudflared tunnel login

# å»ºç«‹ Tunnelï¼ˆæœ¬åœ° GPU æœå‹™ï¼‰
cloudflared tunnel create zhewei-local-gpu

# è¨˜ä¸‹ Tunnel ID å’Œ Token
```

#### 2.2 è¨­å®šæœ¬åœ°æœå‹™ Tunnel

å»ºç«‹ `C:\Users\YOUR_USER\.cloudflared\config.yml`ï¼š

```yaml
tunnel: YOUR_TUNNEL_ID
credentials-file: C:\Users\YOUR_USER\.cloudflared\YOUR_TUNNEL_ID.json

ingress:
  # Ollama GPU
  - hostname: ollama-gpu.zhe-wei.net
    service: http://localhost:11460
  
  # Vision AI
  - hostname: vision-gpu.zhe-wei.net
    service: http://localhost:8030
  
  # ComfyUI
  - hostname: comfyui.zhe-wei.net
    service: http://localhost:9188
  
  # Dify
  - hostname: dify-local.zhe-wei.net
    service: http://localhost:8080
  
  # 404 fallback
  - service: http_status:404
```

#### 2.3 è¨­å®š DNSï¼ˆCloudflare Dashboardï¼‰

```
ollama-gpu.zhe-wei.net    â†’ CNAME â†’ YOUR_TUNNEL_ID.cfargotunnel.com
vision-gpu.zhe-wei.net    â†’ CNAME â†’ YOUR_TUNNEL_ID.cfargotunnel.com
comfyui.zhe-wei.net       â†’ CNAME â†’ YOUR_TUNNEL_ID.cfargotunnel.com
dify-local.zhe-wei.net    â†’ CNAME â†’ YOUR_TUNNEL_ID.cfargotunnel.com
```

#### 2.4 å•Ÿå‹•æœ¬åœ° Tunnelï¼ˆWindows æœå‹™ï¼‰

```powershell
# å®‰è£ç‚º Windows æœå‹™
cloudflared service install

# å•Ÿå‹•æœå‹™
Start-Service cloudflared

# è¨­å®šé–‹æ©Ÿè‡ªå‹•å•Ÿå‹•
Set-Service -Name cloudflared -StartupType Automatic

# æª¢æŸ¥ç‹€æ…‹
Get-Service cloudflared
cloudflared tunnel info zhewei-local-gpu
```

---

### éšæ®µ 3ï¼šæ™ºæ…§è·¯ç”±é…ç½®

#### 3.1 ä¿®æ”¹ Brain Server é…ç½®

æ›´æ–° `ai_service.py` çš„ Ollama è·¯ç”±é‚è¼¯ï¼š

```python
# æ™ºæ…§ Ollama è·¯ç”±
def get_ollama_url():
    """æ ¹æ“šæœ¬åœ° GPU å¯ç”¨æ€§é¸æ“‡ Ollama"""
    gpu_url = os.getenv("OLLAMA_GPU_URL", "https://ollama-gpu.zhe-wei.net")
    cpu_url = os.getenv("OLLAMA_BASE_URL", "http://ollama:11434")
    
    try:
        # å˜—è©¦é€£æ¥æœ¬åœ° GPU Ollamaï¼ˆ5 ç§’è¶…æ™‚ï¼‰
        resp = requests.get(f"{gpu_url}/api/tags", timeout=5)
        if resp.status_code == 200:
            return gpu_url
    except:
        pass
    
    # Fallback åˆ°é›²ç«¯ CPU Ollama
    return cpu_url
```

#### 3.2 ç’°å¢ƒè®Šæ•¸è¨­å®š

é›²ç«¯ VPS `.env`ï¼š

```env
# ä¸»è¦ Ollamaï¼ˆé›²ç«¯ CPUï¼‰
OLLAMA_BASE_URL=http://ollama:11434

# å‚™æ´ Ollamaï¼ˆæœ¬åœ° GPUï¼Œé€é Tunnelï¼‰
OLLAMA_GPU_URL=https://ollama-gpu.zhe-wei.net

# æ™ºæ…§è·¯ç”±æ¨¡å¼
AI_COST_MODE=smart_route
OLLAMA_FALLBACK_ENABLED=true
OLLAMA_GPU_TIMEOUT=5
```

---

## ğŸ”„ æ™ºæ…§é™ç´šç­–ç•¥

### å ´æ™¯ 1ï¼šæœ¬åœ°ä¸»æ©Ÿé–‹æ©Ÿï¼ˆæœ€ä½³æ€§èƒ½ï¼‰

```
ç”¨æˆ¶è«‹æ±‚ â†’ Brain Server (é›²ç«¯)
           â†“
    æª¢æ¸¬æœ¬åœ° GPU Ollama
           â†“
    âœ… å¯ç”¨ â†’ ä½¿ç”¨ ollama-gpu.zhe-wei.net (GPU æ¨ç†)
           â†“
    å¤§æ¨¡å‹ä»»å‹™ â†’ qwen2.5-coder:7b, deepseek-r1:14b
    è¦–è¦ºä»»å‹™ â†’ vision-gpu.zhe-wei.net (YOLOv8)
    ç”Ÿåœ–ä»»å‹™ â†’ comfyui.zhe-wei.net (Stable Diffusion)
```

### å ´æ™¯ 2ï¼šæœ¬åœ°ä¸»æ©Ÿé—œæ©Ÿï¼ˆé™ç´šé‹è¡Œï¼‰

```
ç”¨æˆ¶è«‹æ±‚ â†’ Brain Server (é›²ç«¯)
           â†“
    æª¢æ¸¬æœ¬åœ° GPU Ollama
           â†“
    âŒ ä¸å¯ç”¨ â†’ ä½¿ç”¨ ollama:11434 (é›²ç«¯ CPU)
           â†“
    è¼•é‡æ¨¡å‹ â†’ gemma2:2b, qwen2.5:3b
    è¦–è¦ºä»»å‹™ â†’ å›å‚³ã€Œéœ€è¦æœ¬åœ° GPUã€
    ç”Ÿåœ–ä»»å‹™ â†’ å›å‚³ã€Œéœ€è¦æœ¬åœ° GPUã€
```

---

## ğŸ“Š æ€§èƒ½èˆ‡æˆæœ¬å°æ¯”

| é …ç›® | æœ¬åœ°é–‹æ©Ÿ | æœ¬åœ°é—œæ©Ÿ |
|------|----------|----------|
| AI æ¨ç†é€Ÿåº¦ | âš¡ å¿«ï¼ˆGPUï¼‰ | ğŸ¢ æ…¢ï¼ˆCPUï¼‰ |
| å¯ç”¨æ¨¡å‹ | ğŸ¯ å…¨éƒ¨ï¼ˆ7B-14Bï¼‰ | ğŸ“¦ è¼•é‡ï¼ˆ2B-3Bï¼‰ |
| è¦–è¦ºè¾¨è­˜ | âœ… YOLOv8 GPU | âŒ ä¸å¯ç”¨ |
| åœ–ç‰‡ç”Ÿæˆ | âœ… ComfyUI GPU | âŒ ä¸å¯ç”¨ |
| æœˆæˆæœ¬ | $12 + é›»è²» | $12 |
| é©ç”¨å ´æ™¯ | å·¥ä½œæ™‚é–“ | å¤œé–“/å‡æ—¥ |

---

## ğŸ› ï¸ ç¶­è­·èˆ‡ç›£æ§

### è‡ªå‹•å¥åº·æª¢æŸ¥ï¼ˆé›²ç«¯ï¼‰

```bash
# é›²ç«¯ VPS
crontab -e

# åŠ å…¥ä»¥ä¸‹è¡Œ
*/5 * * * * /opt/zhewei/scripts/health_monitor.sh >> /var/log/zhewei_health.log 2>&1
```

### æœ¬åœ°æœå‹™ç›£æ§ï¼ˆWindowsï¼‰

å»ºç«‹ `scripts/check_local_services.ps1`ï¼š

```powershell
# æª¢æŸ¥æœ¬åœ°æœå‹™ç‹€æ…‹
$services = @(
    @{Name="Ollama"; Port=11460},
    @{Name="Vision AI"; Port=8030},
    @{Name="ComfyUI"; Port=9188},
    @{Name="Dify"; Port=8080}
)

foreach ($svc in $services) {
    try {
        $response = Invoke-WebRequest -Uri "http://localhost:$($svc.Port)" -TimeoutSec 2 -ErrorAction Stop
        Write-Host "âœ… $($svc.Name) é‹è¡Œä¸­"
    } catch {
        Write-Host "âŒ $($svc.Name) æœªé‹è¡Œ"
    }
}

# æª¢æŸ¥ Cloudflare Tunnel
$tunnel = Get-Service cloudflared -ErrorAction SilentlyContinue
if ($tunnel.Status -eq "Running") {
    Write-Host "âœ… Cloudflare Tunnel é‹è¡Œä¸­"
} else {
    Write-Host "âŒ Cloudflare Tunnel æœªé‹è¡Œ"
}
```

è¨­å®š Windows å·¥ä½œæ’ç¨‹å™¨æ¯ 10 åˆ†é˜åŸ·è¡Œã€‚

---

## ğŸ§ª æ¸¬è©¦æ··åˆé€£æ¥

### æ¸¬è©¦è…³æœ¬

å»ºç«‹ `scripts/test_hybrid_deployment.py`ï¼š

```python
import requests
import time

def test_hybrid():
    """æ¸¬è©¦æ··åˆéƒ¨ç½²é€£æ¥"""
    
    tests = [
        # é›²ç«¯æœå‹™
        ("Brain Server (é›²ç«¯)", "https://jarvis.zhe-wei.net/health"),
        ("Portal (é›²ç«¯)", "https://zhe-wei.net"),
        ("CMS (é›²ç«¯)", "https://cms.zhe-wei.net/health"),
        
        # æœ¬åœ° GPU æœå‹™ï¼ˆé€é Tunnelï¼‰
        ("Ollama GPU (æœ¬åœ°)", "https://ollama-gpu.zhe-wei.net/api/tags"),
        ("Vision AI (æœ¬åœ°)", "https://vision-gpu.zhe-wei.net/healthz"),
        ("ComfyUI (æœ¬åœ°)", "https://comfyui.zhe-wei.net"),
    ]
    
    print("ğŸ§ª æ¸¬è©¦æ··åˆéƒ¨ç½²é€£æ¥...\n")
    
    for name, url in tests:
        try:
            resp = requests.get(url, timeout=5)
            if resp.status_code == 200:
                print(f"âœ… {name}")
            else:
                print(f"âš ï¸ {name} (HTTP {resp.status_code})")
        except requests.exceptions.Timeout:
            print(f"â±ï¸ {name} (è¶…æ™‚ï¼Œå¯èƒ½æœ¬åœ°é—œæ©Ÿ)")
        except Exception as e:
            print(f"âŒ {name} ({str(e)[:50]})")
    
    print("\næ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    test_hybrid()
```

åŸ·è¡Œæ¸¬è©¦ï¼š

```bash
# é›²ç«¯ VPS
python scripts/test_hybrid_deployment.py

# æœ¬åœ° Windows
python scripts\test_hybrid_deployment.py
```

---

## ğŸ“‹ éƒ¨ç½²æª¢æŸ¥æ¸…å–®

### é›²ç«¯ VPS âœ…
- [ ] VPS å·²å»ºç«‹ä¸¦å®‰è£ Docker
- [ ] å°ˆæ¡ˆå·²ä¸Šå‚³åˆ° `/opt/zhewei`
- [ ] `.env` å·²è¨­å®šï¼ˆCLOUDFLARE_TOKEN, API Keysï¼‰
- [ ] åŸ·è¡Œ `deploy_to_cloud.sh` æˆåŠŸ
- [ ] æ‰€æœ‰å®¹å™¨é‹è¡Œä¸­ï¼ˆ`docker ps`ï¼‰
- [ ] å¤–ç¶²å¯å­˜å– https://jarvis.zhe-wei.net
- [ ] å¥åº·ç›£æ§å·²åŠ å…¥ crontab

### æœ¬åœ°ä¸»æ©Ÿ âœ…
- [ ] Cloudflare Tunnel å·²å®‰è£
- [ ] `config.yml` å·²è¨­å®š 4 å€‹æœå‹™
- [ ] DNS å·²è¨­å®š CNAME è¨˜éŒ„
- [ ] Tunnel å·²å®‰è£ç‚º Windows æœå‹™
- [ ] Ollama é‹è¡Œåœ¨ port 11460
- [ ] Vision AI é‹è¡Œåœ¨ port 8030
- [ ] ComfyUI é‹è¡Œåœ¨ port 9188
- [ ] å¤–ç¶²å¯å­˜å– https://ollama-gpu.zhe-wei.net

### æ™ºæ…§è·¯ç”± âœ…
- [ ] Brain Server å¯åµæ¸¬æœ¬åœ° GPU
- [ ] æœ¬åœ°é–‹æ©Ÿæ™‚ä½¿ç”¨ GPU æ¨¡å‹
- [ ] æœ¬åœ°é—œæ©Ÿæ™‚é™ç´šç‚º CPU æ¨¡å‹
- [ ] æ¸¬è©¦è…³æœ¬å…¨éƒ¨é€šé

---

## ğŸ¯ å®Œæˆå¾Œæ•ˆæœ

### æœ¬åœ°ä¸»æ©Ÿé–‹æ©Ÿæ™‚
- âš¡ **æœ€ä½³æ€§èƒ½**ï¼šGPU åŠ é€Ÿæ¨ç†
- ğŸ¯ **å®Œæ•´åŠŸèƒ½**ï¼šæ‰€æœ‰æœå‹™å¯ç”¨
- ğŸ’° **æˆæœ¬**ï¼š$12/æœˆ + é›»è²»

### æœ¬åœ°ä¸»æ©Ÿé—œæ©Ÿæ™‚
- ğŸ”„ **è‡ªå‹•é™ç´š**ï¼šåˆ‡æ›åˆ°é›²ç«¯ CPU
- âœ… **æ ¸å¿ƒå¯ç”¨**ï¼šå°è©±ã€ç®¡ç†ç³»çµ±æ­£å¸¸
- âš ï¸ **åŠŸèƒ½å—é™**ï¼šè¦–è¦ºè¾¨è­˜ã€ç”Ÿåœ–ä¸å¯ç”¨
- ğŸ’° **æˆæœ¬**ï¼šåƒ… $12/æœˆ

---

## ğŸ†˜ æ•…éšœæ’é™¤

### æœ¬åœ° GPU æœå‹™ç„¡æ³•é€£æ¥

```bash
# æª¢æŸ¥ Tunnel ç‹€æ…‹
Get-Service cloudflared

# é‡å•Ÿ Tunnel
Restart-Service cloudflared

# æª¢æŸ¥ Tunnel æ—¥èªŒ
cloudflared tunnel info zhewei-local-gpu
```

### Brain Server ç„¡æ³•åˆ‡æ›åˆ°æœ¬åœ° GPU

```bash
# æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
docker exec zhewei_brain env | grep OLLAMA

# æª¢æŸ¥æ—¥èªŒ
docker logs zhewei_brain | grep -i ollama

# æ‰‹å‹•æ¸¬è©¦é€£æ¥
docker exec zhewei_brain curl https://ollama-gpu.zhe-wei.net/api/tags
```

---

## ğŸ“š ç›¸é—œæ–‡ä»¶

- é›²ç«¯å®Œæ•´éƒ¨ç½²ï¼š`docs/deployment/CLOUD_24_7_DEPLOYMENT.md`
- å¿«é€Ÿéƒ¨ç½²æŒ‡å—ï¼š`QUICK_CLOUD_DEPLOY.md`
- Docker Composeï¼š`docker-compose.cloud.yml`

---

## âœ¨ ç¸½çµ

æ··åˆéƒ¨ç½²æ–¹æ¡ˆçµåˆäº†é›²ç«¯çš„ç©©å®šæ€§èˆ‡æœ¬åœ°çš„æ€§èƒ½å„ªå‹¢ï¼š

- **é›²ç«¯**ï¼š24/7 æ ¸å¿ƒæœå‹™ï¼Œæˆæœ¬åƒ… $12/æœˆ
- **æœ¬åœ°**ï¼šGPU åŠ é€Ÿï¼Œéœ€è¦æ™‚é–‹æ©Ÿ
- **æ™ºæ…§è·¯ç”±**ï¼šè‡ªå‹•åµæ¸¬ä¸¦åˆ‡æ›æœ€ä½³è³‡æº
- **å½ˆæ€§æ“´å±•**ï¼šéš¨æ™‚å¯å‡ç´šé›²ç«¯ GPU

é€™æ˜¯æœ€ç¶“æ¿Ÿå¯¦æƒ ä¸”æ€§èƒ½æœ€ä½³çš„éƒ¨ç½²æ–¹æ¡ˆï¼
