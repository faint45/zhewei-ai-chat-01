"""
ç¯‰æœªç§‘æŠ€ - è¬èƒ½åŠ©ç†å…±ç”¨é‚è¼¯ï¼ˆDiscord æ©Ÿå™¨äººèˆ‡å¤§è…¦æ©‹æ¥å…±ç”¨ï¼‰
å¤©æ°£ã€æˆæ¬Šã€AI å°è©±ã€Agentã€è»å¸«å”è­°
"""
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

try:
    import requests
except ImportError:
    requests = None

BASE_DIR = Path(__file__).parent.resolve()
try:
    from brain_data_config import DEV_OUTPUT_PATH
    DEV_OUTPUT = DEV_OUTPUT_PATH
except ImportError:
    DEV_OUTPUT = BASE_DIR / "dev_output.py"

STRATEGIST_CONFIG = {
    "active_api": os.environ.get("STRATEGIST_API", "PREMIUM_API"),
    "api_key": os.environ.get("STRATEGIST_API_KEY", ""),
    "endpoint": os.environ.get("STRATEGIST_ENDPOINT", "https://api.openai.com/v1/chat/completions"),
}
# 0=åƒ…æœ¬åœ°å…è²» AI ä¿®æ­£ï¼Œä¸æ±‚åŠ©ä»˜è²»è»å¸«ï¼›1=å¤±æ•—æ™‚å¯å‘¼å«ä»˜è²»è»å¸«
USE_PREMIUM_STRATEGIST = os.environ.get("USE_PREMIUM_STRATEGIST", "0").strip().lower() in ("1", "true", "yes")
OLLAMA_TIMEOUT = 60
OLLAMA_WAIT_SEC = 5
AUTH_EXPIRE_SEC = 600

ASSISTANT_PROMPT = """ç¯‰æœªç§‘æŠ€è¬èƒ½åŠ©ç†ã€‚åªè™•ç†ã€ä¸è§£é‡‹ã€‚
è¦å‰‡ï¼šç›´æ¥çµ¦ä½œæ³•æˆ–ç­”æ¡ˆï¼Œä¸èªªæ˜åŸå› ã€ä¸æ•™å­¸ã€ä¸å»¢è©±ã€‚
åš´ç¦ï¼šè‡ªæˆ‘ä»‹ç´¹ã€LLM æœ¬è³ªåˆ†æã€æ„è­˜è«–è¿°ã€å±€é™æ€§èªªæ˜ã€‚"""

_authorized: dict[str, float] = {}
_premium_authorized: dict[str, float] = {}

ABNORMAL_ERR_KEYWORDS = ("è·¯å¾‘ä¸å­˜åœ¨", "å°ˆæ¡ˆè·¯å¾‘ä¸å­˜åœ¨", "permission denied", "æ¬Šé™ä¸è¶³", "access denied", "no such file", "æ‰¾ä¸åˆ°æŒ‡å®š")
UNCERTAIN_REPLY_KEYWORDS = ("ä¸ç¢ºå®š", "å¯èƒ½", "å»ºè­°æ‰‹å‹•", "ç„¡æ³•è‡ªå‹•", "éœ€äººå·¥", "ä¸ä¸€å®š", "æˆ–è¨±", "maybe", "ä¸å¤ªç¢ºå®š")


def _is_authorized(user_id: str) -> bool:
    now = datetime.now().timestamp()
    if user_id in _authorized and _authorized[user_id] > now:
        return True
    if user_id in _authorized:
        del _authorized[user_id]
    return False


def grant_auth(user_id: str):
    _authorized[user_id] = datetime.now().timestamp() + AUTH_EXPIRE_SEC


def revoke_auth(user_id: str):
    if user_id in _authorized:
        del _authorized[user_id]


def grant_premium_auth(user_id: str):
    _premium_authorized[str(user_id)] = datetime.now().timestamp() + AUTH_EXPIRE_SEC


def _is_premium_authorized(user_id: str) -> bool:
    now = datetime.now().timestamp()
    uid = str(user_id)
    if uid in _premium_authorized and _premium_authorized[uid] > now:
        return True
    if uid in _premium_authorized:
        del _premium_authorized[uid]
    return False


def _is_abnormal_error(err: str) -> bool:
    lower = (err or "").lower()
    return any(k.lower() in lower for k in ABNORMAL_ERR_KEYWORDS)


def _is_uncertain_reply(reply: str) -> bool:
    lower = (reply or "").lower()
    return any(k in lower for k in UNCERTAIN_REPLY_KEYWORDS)


def _can_control(user_id: str) -> bool:
    allowed = os.environ.get("AUTHORIZED_USER_ID", "").strip()
    if not allowed:
        return True
    return str(user_id) == allowed


def get_weather(msg: str = "") -> str:
    """å–å¾—å³æ™‚å¤©æ°£ (Open-Meteo å…è²»)"""
    if not requests:
        return ""
    coords = {"å°åŒ—": (25.033, 121.565), "é«˜é›„": (22.627, 120.301), "å˜‰ç¾©": (23.487, 120.449), "æ°‘é›„": (23.552, 120.432)}
    lat, lon = (23.487, 120.449)
    for k, v in coords.items():
        if k in msg:
            lat, lon = v
            break
    try:
        r = requests.get(
            f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true",
            timeout=5,
        )
        if r.status_code == 200:
            d = r.json().get("current_weather", {})
            temp = d.get("temperature", "?")
            wcode = d.get("weathercode", 0)
            wind = d.get("windspeed", "?")
            wdesc = {0: "æ™´", 1: "å°‘é›²", 2: "å°‘é›²", 3: "å¤šé›²", 45: "éœ§", 48: "éœ§", 51: "æ¯›æ¯›é›¨", 61: "é›¨", 80: "é™£é›¨", 95: "é›·é›¨"}.get(wcode, "â€”")
            return f"[å³æ™‚å¤©æ°£] æº«åº¦ {temp}Â°Cï¼Œ{wdesc}ï¼Œé¢¨é€Ÿ {wind} km/h"
    except Exception:
        pass
    return ""


def get_time() -> str:
    return datetime.now().strftime("%Y-%m-%d %H:%M")


def build_prompt(user_msg: str) -> str:
    """çµ„è£æç¤ºï¼šå«æ™‚é–“ã€å¤©æ°£ã€æ„åœ–åˆ†æµï¼ˆå•ç­”é¡åŠ  CoTï¼‰"""
    now = get_time()
    ctx = f"[ç¾åœ¨] {now}\n\n"
    lower = user_msg.lower()
    if "å¤©æ°£" in user_msg or "weather" in lower or "å¹¾åº¦" in user_msg:
        w = get_weather(user_msg)
        if w:
            ctx += f"{w}\n\n"
    intent = get_intent(user_msg)
    if intent == "question" and len(user_msg) > 30:
        ctx += "è«‹å…ˆç°¡è¦åˆ†æå†çµ¦å‡ºçµè«–ã€‚\n\n"
    return f"{ASSISTANT_PROMPT}\n\n{ctx}ç”¨æˆ¶ï¼š{user_msg}"


def get_intent(content: str) -> str:
    """æ„åœ–åˆ†æµï¼šcode | question | system | generalã€‚
    å•ç­”é¡ï¼ˆç‚ºä»€éº¼ã€æ€éº¼ã€ä»€éº¼æ˜¯ï¼‰å„ªå…ˆæ–¼ codeï¼Œé¿å…ã€Œç‚ºä»€éº¼ Python...ã€è¢«ç•¶ç¨‹å¼ä»»å‹™ã€‚"""
    lower = content.lower().strip()
    if any(k in lower for k in ("é–‹å•Ÿ", "æ‰“é–‹", "æˆæ¬Š", "é—œé–‰", "æª¢æŸ¥", "æª¢æ ¸", "ä¿®å¾©", "é‡å•Ÿ")):
        return "system"
    if any(k in lower for k in ("ç‚ºä»€éº¼", "æ€éº¼", "ä»€éº¼æ˜¯", "è§£é‡‹", "èªªæ˜", "å·®åˆ¥", "æ¯”è¼ƒ", "why", "how", "what")):
        return "question"
    if "å¦‚ä½•" in lower and len(content) < 25 and any(x in content for x in ("å¤©æ°£", "å¹¾åº¦", "ç¾åœ¨")):
        return "general"
    if any(k in lower for k in ("å¯«", "ç¨‹å¼", "ä¿®æ”¹", "æ–°å¢", "å»ºç«‹", "æª”æ¡ˆ", "deploy", "éƒ¨ç½²", "git", "å…ƒä»¶", "py", "jsx", "code")):
        return "code"
    if any(k in lower for k in ("å¦‚ä½•",)):
        return "question"
    return "general"


def is_agent_task(content: str) -> bool:
    """è¾¨è­˜æ˜¯å¦ç‚ºå¯«ç¨‹å¼/éƒ¨ç½²/å‰µæ„ç›¸é—œï¼Œéœ€ç”¨ Agent"""
    lower = content.lower().strip()
    keywords = (
        "å¯«", "ç¨‹å¼", "ç¨‹å¼ç¢¼", "code", "ä¿®æ”¹", "æ–°å¢", "å»ºç«‹", "æª”æ¡ˆ", "file",
        "deploy", "éƒ¨ç½²", "build", "å»ºç½®", "git", "push", "commit",
        "æ”¹", "åŠ ", "å‰µå»º", "åŠ å…¥", "åŠ åˆ°",
        "ä¿®æ­£", "æ›´æ–°", "ç¶²ç«™", "é¦–é ", "é é¢", "å…ƒä»¶", "app.jsx", "src/",
        "component", "jsx", "tsx", "py", "å»ºç«‹å…ƒä»¶", "æ–°å¢é é¢",
        "3d", "ç”Ÿåœ–", "æ–‡å­—ç”Ÿåœ–", "åœ–ç‰‡è½‰", "å½±éŸ³", "å½±ç‰‡", "è²éŸ³", "å…‹éš†",
        "æ’°å¯«", "å®Œæ¡ˆ", "ç‚’ä½œ", "äººæ°£", "è¡ŒéŠ·", "æ–‡æ¡ˆ",
        "é‚Šç·£", "åµæ¸¬", "å½±åƒåˆ†æ", "è¦–è¦º", "ç‰©ä»¶åµæ¸¬", "edge", "detect", "analyze", "vision", "yolo",
        "github", "git hub", "æœå°‹ repo", "å­¸ç¿’è³‡æº", "è‡ªå‹•å­¸ç¿’", "self learn",
        "run_python", "pandas", "numpy è¨ˆç®—", "ç¶²é æœå°‹", "fetch_url", "æŠ“å–ç¶²é ",
        "æŸ¥çŸ¥è­˜åº«", "search_knowledge", "diff", "æ¯”è¼ƒæª”æ¡ˆ",
    )
    return any(k in lower for k in keywords)


def run_system_check() -> str:
    """æª¢æ ¸å¤šå€‹å­ç³»çµ±ç‹€æ…‹"""
    lines = ["ã€ç¯‰æœªç§‘æŠ€å¤§è…¦ - ç³»çµ±æª¢æ ¸ã€‘", ""]
    base_url = os.environ.get("OLLAMA_BASE_URL", "http://127.0.0.1:11434")
    try:
        if requests:
            r = requests.get(f"{base_url.rstrip('/')}/api/tags", timeout=5)
            if r.status_code == 200:
                models = r.json().get("models", []) or []
                names = [m.get("name", "") for m in models[:3] if m.get("name")]
                lines.append(f"âœ… Ollamaï¼šå·²é€£ç·š ({', '.join(names) if names else 'ç„¡æ¨¡å‹'})")
            else:
                lines.append(f"âš ï¸ Ollamaï¼šHTTP {r.status_code}")
        else:
            lines.append("âš ï¸ Ollamaï¼šç„¡æ³•æª¢æŸ¥ (ç¼º requests)")
    except Exception as e:
        lines.append(f"âŒ Ollamaï¼š{str(e)[:80]}")
    try:
        from ai_providers import get_available, ask_sync
        provs = get_available()
        lines.append(f"âœ… AI æä¾›è€…ï¼š{', '.join(provs) if provs else 'ç„¡'}")
        resp, prov = ask_sync("å›è¦†ä¸€å€‹å­—ï¼šå¥½", ensemble=False)
        if resp and "é€£ç·šå¤±æ•—" not in resp:
            lines.append(f"âœ… AI å›æ‡‰ï¼šæ­£å¸¸ ({prov})")
        else:
            lines.append("âš ï¸ AI å›æ‡‰ï¼šé€£ç·šå¤±æ•—")
    except Exception as e:
        lines.append(f"âŒ AI æä¾›è€…ï¼š{str(e)[:60]}")
    try:
        from brain_knowledge import get_stats
        st = get_stats()
        lines.append(f"âœ… çŸ¥è­˜åº«ï¼š{st.get('total', 0)} ç­†")
    except Exception as e:
        lines.append(f"âš ï¸ çŸ¥è­˜åº«ï¼š{str(e)[:50]}")
    try:
        from ai_vision_monitor import health_check
        ok, err = health_check()
        lines.append("âœ… AI è¦–è¦ºè¾¨è­˜ï¼šå¥åº·" if ok else f"âš ï¸ AI è¦–è¦ºè¾¨è­˜ï¼š{err[:100]}...")
    except ImportError:
        lines.append("âš ï¸ AI è¦–è¦ºè¾¨è­˜ï¼šæ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        lines.append(f"âŒ AI è¦–è¦ºè¾¨è­˜ï¼š{str(e)[:60]}")
    try:
        url = (os.environ.get("ZHEWEI_BRAIN_URL") or "http://127.0.0.1:5100").strip().rstrip("/")
        if url and url.lower() not in ("0", "false") and requests:
            r = requests.get(f"{url}/health", timeout=3)
            lines.append("âœ… Brain Bridge APIï¼šå·²é€£ç·š" if r.status_code == 200 else f"âš ï¸ Brain Bridgeï¼šHTTP {r.status_code}")
        else:
            lines.append("â€” Brain Bridgeï¼šæœªå•Ÿç”¨")
    except Exception:
        lines.append("âš ï¸ Brain Bridge APIï¼šé›¢ç·š")
    token = os.environ.get("DISCORD_BOT_TOKEN", "").strip()
    lines.append("âœ… Discord Tokenï¼šå·²è¨­å®š" if token and token != "your-discord-bot-token" and not token.startswith("your-") else "âš ï¸ Discord Tokenï¼šæœªè¨­å®š")
    try:
        from agent_tools import TOOL_MAP
        tools = list(TOOL_MAP.keys())
        lines.append(f"âœ… Agent å·¥å…·ï¼š{len(tools)} å€‹")
    except Exception as e:
        lines.append(f"âš ï¸ Agent å·¥å…·ï¼š{str(e)[:50]}")
    return "\n".join(lines)


def handle_action(user_id: str, content: str) -> str | None:
    """æˆæ¬Šã€é–‹å•ŸæŒ‡ä»¤ã€‚å›å‚³çµæœæˆ– Noneï¼ˆéæŒ‡ä»¤ï¼‰"""
    lower = content.lower().strip()

    if any(k in lower for k in ["å•Ÿç”¨gpt", "æˆæ¬Šé«˜éš", "å•Ÿç”¨é«˜éšè»å¸«", "enable gpt"]):
        if not _can_control(user_id):
            return "âš ï¸ å•Ÿç”¨ GPT é«˜éšè»å¸«åƒ…é™æˆæ¬Šç”¨æˆ¶ã€‚è«‹åœ¨ .env è¨­å®š AUTHORIZED_USER_IDã€‚"
        key = STRATEGIST_CONFIG.get("api_key", "").strip()
        if not key or key.startswith("your-"):
            return "âš ï¸ è«‹å…ˆåœ¨ .env è¨­å®š STRATEGIST_API_KEYï¼ˆOpenAIï¼‰æ–¹èƒ½å•Ÿç”¨ GPT é«˜éšè»å¸«ã€‚"
        grant_premium_auth(user_id)
        return "âœ… å·²æˆæ¬Šå•Ÿç”¨ GPT é«˜éšè»å¸«ã€‚æ¥ä¸‹ä¾† 10 åˆ†é˜å…§ï¼Œä¿®å¾©å¤±æ•—æ™‚æœƒè‡ªå‹•å•Ÿç”¨ GPT å”åŠ©ã€‚"

    if any(k in lower for k in ["é‡æ–°å•Ÿå‹•discordå‚³ä»¤å…µ", "é‡å•Ÿdiscordå‚³ä»¤å…µ", "é‡å•Ÿå‚³ä»¤å…µ", "restart discord bot"]):
        return "**é‡æ–°å•Ÿå‹• Discord å‚³ä»¤å…µ**\n\nè«‹åœ¨æœ¬æ©Ÿå°ˆæ¡ˆç›®éŒ„åŸ·è¡Œï¼š`é‡æ–°å•Ÿå‹•Discordå‚³ä»¤å…µ.bat`\næˆ–ï¼š`python zhewei_guard.py`\nï¼ˆæ˜¯é‡å•Ÿç¯‰æœªç§‘æŠ€ Botï¼Œä¸æ˜¯ Discord æ¡Œé¢ç¨‹å¼ï¼‰"

    check_kw = ("æª¢æ ¸", "æª¢æŸ¥", "æª¢æŸ¥ç³»çµ±", "æª¢æ ¸å¤§è…¦", "æª¢æ ¸ç¯‰æœªç§‘æŠ€", "ç³»çµ±ç‹€æ…‹", "status")
    check_scope = ("ç³»çµ±", "å¤§è…¦", "ç‹€æ…‹", "å…¨éƒ¨", "æ‰€æœ‰", "è¦–è¦º", "aiè¦–è¦º")
    if any(k in content for k in check_kw) and any(x in lower for x in check_scope):
        return run_system_check()

    if "aiè¦–è¦º" in lower or "ä¿®å¾©aiè¦–è¦º" in lower or "aiè¦–è¦ºä¿®æ­£" in lower or "aiè¦–è¦ºç›£çœ‹" in lower:
        if _can_control(user_id) or _is_authorized(user_id):
            try:
                from ai_vision_monitor import health_check, ask_brain as _vision_ask, try_apply_fix
                MAX_FIX = 3
                for attempt in range(MAX_FIX):
                    ok, err = health_check()
                    if ok:
                        return "âœ… AIè¦–è¦ºè¾¨è­˜ç³»çµ± å¥åº·æª¢æŸ¥é€šéã€‚" if attempt == 0 else f"âœ… ä¿®å¾©æˆåŠŸï¼ˆç¬¬ {attempt + 1} æ¬¡æª¢æŸ¥é€šéï¼‰"
                    if _is_abnormal_error(err):
                        return f"ğŸ›‘ ç•°å¸¸çµ‚æ­¢ï¼š{err[:200]}\nï¼ˆè·¯å¾‘/æ¬Šé™ç­‰è«‹æ‰‹å‹•è™•ç†ï¼‰"
                    prompt = f"ã€AIè¦–è¦ºç›£çœ‹ã€‘å¥åº·æª¢æŸ¥å¤±æ•—ã€‚å°ˆæ¡ˆ {os.environ.get('AI_VISION_DIR', 'D:\\\\AI_Vision_Recognition')}ã€‚éŒ¯èª¤ï¼š{err[:500]}ã€‚"
                    if attempt > 0:
                        prompt += " ä¸Šæ¬¡ä¿®æ­£ç„¡æ•ˆï¼Œè«‹æ›å…¶ä»–æ–¹æ³•ã€‚"
                    prompt += " è«‹çµ¦ 1ï½3 æ¢å…·é«”ä¿®æ­£æ­¥é©Ÿï¼Œè‹¥ç¼ºå¥—ä»¶è«‹å¯« pip install å¥—ä»¶åã€‚"
                    reply = _vision_ask(prompt)
                    if not reply:
                        return f"âš ï¸ AIè¦–è¦ºæª¢æŸ¥å¤±æ•—ï¼š{err[:300]}\nï¼ˆå¤§è…¦ç„¡å›è¦†ï¼‰"
                    if _is_uncertain_reply(reply):
                        validated = ask_brain(reply, "", os.environ.get("OLLAMA_MODEL", "qwen2.5:7b"))
                        if validated and len(validated.strip()) > 20:
                            reply = validated.strip()
                    try_apply_fix(reply)
                if _is_premium_authorized(user_id):
                    gpt_reply = call_premium_diagnosis(
                        f"ã€AIè¦–è¦ºã€‘å¥åº·æª¢æŸ¥å¤±æ•—ã€‚éŒ¯èª¤ï¼š{err[:500]}ã€‚è«‹çµ¦ 1ï½3 æ¢å…·é«”ä¿®æ­£æ­¥é©Ÿï¼Œè‹¥ç¼ºå¥—ä»¶è«‹å¯« pip install å¥—ä»¶åã€‚",
                        user_id,
                    )
                    if gpt_reply and len(gpt_reply.strip()) > 20:
                        try_apply_fix(gpt_reply)
                        ok2, _ = health_check()
                        if ok2:
                            return "âœ… GPT é«˜éšè»å¸«å·²ä»‹å…¥ï¼ŒAIè¦–è¦ºè¾¨è­˜ç³»çµ±ä¿®å¾©æˆåŠŸã€‚"
                hint = "\n\nè‹¥éœ€ GPT é«˜éšè»å¸«å”åŠ©ï¼Œè«‹å›è¦†ã€Œå•Ÿç”¨GPTã€å–å¾—æˆæ¬Šå¾Œï¼Œå†é‡æ–°èªªã€Œä¿®å¾©AIè¦–è¦ºã€ã€‚"
                return f"âš ï¸ å·²å˜—è©¦ {MAX_FIX} æ¬¡ä¿®æ­£ä»å¤±æ•—ï¼š{err[:200]}...{hint}"
            except ImportError:
                return "âš ï¸ ai_vision_monitor æ¨¡çµ„æœªæ‰¾åˆ°ã€‚"
            except Exception as e:
                return f"AIè¦–è¦ºç›£çœ‹ç•°å¸¸ï¼š{e}"
        return "âš ï¸ ä¿®å¾©/æª¢æ ¸ AI è¦–è¦ºéœ€å…ˆæˆæ¬Šã€‚è«‹èªªã€Œæˆæ¬Šã€ã€‚"

    if any(k in content for k in ["é—œé–‰æˆæ¬Š", "å–æ¶ˆæˆæ¬Š", "æ’¤éŠ·æˆæ¬Š"]) or "revoke" in lower or "cancel auth" in lower:
        if _can_control(user_id):
            revoke_auth(user_id)
            return "âœ… å·²é—œé–‰æˆæ¬Šã€‚"
        return None
    is_control_cmd = content.strip() in ("æˆæ¬Š", "authorize")
    wants_open = (
        ("google" in lower and any(x in content for x in ["é–‹å•Ÿ", "æ‰“é–‹", "é–‹", "å°è©±"])) or
        ("cursor" in lower and any(x in content for x in ["é–‹å•Ÿ", "æ‰“é–‹", "é–‹", "å°è©±"])) or
        (("gemini" in lower or "ai studio" in lower) and any(x in content for x in ["é–‹å•Ÿ", "æ‰“é–‹", "é–‹", "å°è©±"]))
    )
    if (is_control_cmd or wants_open) and not _can_control(user_id):
        return "âš ï¸ æœ¬æ©Ÿæ“ä½œåƒ…é™æˆæ¬Šç”¨æˆ¶ã€‚è«‹åœ¨ .env è¨­å®š AUTHORIZED_USER_IDã€‚"
    if is_control_cmd:
        grant_auth(user_id)
        return "âœ… å·²æˆæ¬Šã€‚æ¥ä¸‹ä¾† 10 åˆ†é˜å…§å¯åŸ·è¡Œæœ¬æ©ŸæŒ‡ä»¤ã€‚"
    if wants_open and not _is_authorized(user_id):
        return "âš ï¸ è«‹å…ˆèªªã€Œæˆæ¬Šã€ï¼Œæ ¸å‡†å¾Œæ‰èƒ½åŸ·è¡Œæœ¬æ©ŸæŒ‡ä»¤ã€‚"

    if not _is_authorized(user_id):
        return None

    open_kw = any(x in content for x in ["é–‹å•Ÿ", "æ‰“é–‹", "é–‹", "ä»£é–‹"])
    if open_kw and "google" in lower:
        try:
            import webbrowser
            webbrowser.open("https://www.google.com")
            return "å·²é–‹å•Ÿ Google ç€è¦½å™¨ã€‚"
        except Exception as e:
            return f"é–‹å•Ÿå¤±æ•—: {e}"
    if open_kw and "cursor" in lower:
        try:
            subprocess.Popen(["cursor", str(BASE_DIR)], cwd=str(BASE_DIR), stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            return "å·²é–‹å•Ÿ Cursorï¼Œæ­£åœ¨è¼‰å…¥å°ˆæ¡ˆã€‚"
        except FileNotFoundError:
            try:
                os.startfile(str(BASE_DIR))
                return "å·²é–‹å•Ÿå°ˆæ¡ˆè³‡æ–™å¤¾ã€‚"
            except Exception as e:
                return f"é–‹å•Ÿå¤±æ•—: {e}"
        except Exception as e:
            return f"é–‹å•Ÿå¤±æ•—: {e}"
    if open_kw and ("gemini" in lower or "ai studio" in lower):
        try:
            import webbrowser
            webbrowser.open("https://aistudio.google.com/")
            return "å·²é–‹å•Ÿ Google AI Studio (Gemini)ã€‚"
        except Exception as e:
            return f"é–‹å•Ÿå¤±æ•—: {e}"
    return None


def ask_brain(prompt: str, base_url: str = "", model: str = "gemma3:4b") -> str:
    """å‘¼å« AI å¤§è…¦"""
    try:
        from ai_providers import ask_sync
        out, _ = ask_sync(prompt, images=None)
        if out and "é€£ç·šå¤±æ•—" not in out:
            return out.strip()
    except Exception:
        pass
    base_url = base_url or os.environ.get("OLLAMA_BASE_URL", "http://127.0.0.1:11434")
    try:
        r = requests.post(
            f"{base_url.rstrip('/')}/api/generate",
            json={"model": model, "prompt": prompt, "stream": False},
            timeout=OLLAMA_TIMEOUT,
        )
        if r.status_code == 200:
            return r.json().get("response", "").strip() or "ã€å¤§è…¦ç„¡å›è¦†ã€‘"
        return f"ã€éŒ¯èª¤ã€‘HTTP {r.status_code}"
    except Exception as e:
        return f"ã€ç•°å¸¸ã€‘{e}"


def run_agent(user_msg: str, user_id: str = "default") -> str:
    """åŸ·è¡Œ Agent"""
    try:
        from agent import run_agent_sync
        result, _ = run_agent_sync(user_msg, on_step=None, user_id=user_id)
        return result or "ã€Agent ç„¡å›è¦†ã€‘"
    except Exception as e:
        return f"ã€Agent éŒ¯èª¤ã€‘{e}"


def call_local_strategist(demand: str, failed_code: str, error: str) -> str | None:
    """
    æœ¬åœ°è»å¸«ï¼šç”¨å…è²» AIï¼ˆOllama/Groq/Gemini ç­‰ï¼‰ä¾éŒ¯èª¤è¨Šæ¯ä¿®æ­£ä»£ç¢¼ã€‚
    é›¶èŠ±è²»ã€ä¸æ±‚åŠ©å¤–éƒ¨ä»˜è²»è»å¸«ã€‚è‡ªå‹•æ³¨å…¥çŸ¥è­˜åº«ä¸­ç›¸é—œä¿®æ­£ç¶“é©—ã€‚
    """
    ctx = ""
    try:
        from brain_knowledge import search
        q = f"{demand} {error[:100]}"
        ctx = search(q, limit=2)
        if ctx:
            ctx = ctx + "\n\n---\n\n"
    except Exception:
        pass
    prompt = f"""{ctx}ä»»å‹™ï¼š{demand}
å¤±æ•—ä»£ç¢¼ï¼š
```
{failed_code[:2000]}
```
åŸ·è¡ŒéŒ¯èª¤ï¼š
```
{error[:800]}
```
è«‹ç›´æ¥è¼¸å‡ºä¿®æ­£å¾Œçš„å®Œæ•´å¯åŸ·è¡Œ Python ä»£ç¢¼ï¼Œåƒ…ä»£ç¢¼ã€ç„¡è§£é‡‹ã€ç„¡ markdownã€‚"""
    try:
        from ai_providers import ask_sync
        out, _ = ask_sync(prompt, images=None, ensemble=False)
        if out and "é€£ç·šå¤±æ•—" not in out:
            code = out.strip().removeprefix("```python").removeprefix("```").removesuffix("```").strip()
            return code if len(code) > 10 else None
    except Exception:
        pass
    try:
        r = requests.post(
            f"{os.environ.get('OLLAMA_BASE_URL', 'http://127.0.0.1:11434')}/api/generate",
            json={
                "model": os.environ.get("OLLAMA_MODEL", "gemma3:4b"),
                "prompt": f"ä¿®æ­£ä»¥ä¸‹ Python éŒ¯èª¤ï¼Œåªè¼¸å‡ºå®Œæ•´å¯åŸ·è¡Œä»£ç¢¼ï¼š\nä»»å‹™:{demand}\nä»£ç¢¼:\n{failed_code[:1500]}\néŒ¯èª¤:{error[:400]}",
                "stream": False,
            },
            timeout=OLLAMA_TIMEOUT,
        )
        if r.status_code == 200:
            t = r.json().get("response", "").strip().removeprefix("```python").removeprefix("```").removesuffix("```").strip()
            return t if len(t) > 10 else None
    except Exception:
        pass
    return None


def call_premium_diagnosis(prompt: str, user_id: str = "") -> str | None:
    """GPT é«˜éšè¨ºæ–·ï¼šç”¢å‡ºæ–‡å­—ä¿®æ­£æ­¥é©Ÿï¼Œç”¨æ–¼ AI è¦–è¦ºç­‰"""
    if not _is_premium_authorized(user_id):
        return None
    key = STRATEGIST_CONFIG.get("api_key", "").strip()
    if not key or key.startswith("your-"):
        return None
    try:
        r = requests.post(
            STRATEGIST_CONFIG.get("endpoint", "https://api.openai.com/v1/chat/completions"),
            headers={"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
            json={
                "model": "gpt-4o",
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ç¯‰æœªç§‘æŠ€è»å¸«ã€‚æ ¹æ“šéŒ¯èª¤çµ¦å‡º 1ï½3 æ¢å…·é«”ä¿®æ­£æ­¥é©Ÿï¼Œè‹¥ç¼ºå¥—ä»¶è«‹æ˜ç¢ºå¯«å‡º pip install å¥—ä»¶åã€‚åƒ…è¼¸å‡ºæ­¥é©Ÿæ–‡å­—ã€‚"},
                    {"role": "user", "content": prompt},
                ],
            },
            timeout=60,
        )
        if r.status_code != 200:
            return None
        content = r.json().get("choices", [{}])[0].get("message", {}).get("content", "")
        return content.strip() if content else None
    except Exception:
        return None


def call_premium_strategist(demand: str, failed_code: str, error: str, user_id: str = "") -> str | None:
    """ä»˜è²»è»å¸«ï¼šUSE_PREMIUM_STRATEGIST=1 æˆ–ç”¨æˆ¶å·²æˆæ¬Šå•Ÿç”¨GPT"""
    if not USE_PREMIUM_STRATEGIST and not _is_premium_authorized(user_id):
        return None
    key = STRATEGIST_CONFIG.get("api_key", "").strip()
    if not key or key.startswith("your-"):
        return None
    try:
        r = requests.post(
            STRATEGIST_CONFIG.get("endpoint", "https://api.openai.com/v1/chat/completions"),
            headers={"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
            json={
                "model": "gpt-4o",
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ç¯‰æœªç§‘æŠ€è»å¸«ã€‚åªç”¢å‡ºå¯åŸ·è¡Œçš„ Python ä»£ç¢¼ï¼Œç„¡è§£é‡‹ã€‚"},
                    {"role": "user", "content": f"ä»»å‹™ï¼š{demand}\n\nå¤±æ•—ä»£ç¢¼ï¼š\n{failed_code}\n\nstderrï¼š\n{error}\n\nè«‹ç›´æ¥è¼¸å‡ºä¿®æ­£å¾Œçš„å®Œæ•´ Python ä»£ç¢¼ã€‚"},
                ],
            },
            timeout=60,
        )
        if r.status_code != 200:
            return None
        content = r.json().get("choices", [{}])[0].get("message", {}).get("content", "")
        code = content.strip().removeprefix("```python").removeprefix("```").removesuffix("```").strip()
        return code if code else None
    except Exception:
        return None


def call_local_ai_dev(prompt: str) -> str:
    """é–‹ç™¼æ¨¡å¼ï¼šæœ¬åœ° AI ç”¢å‡ºä»£ç¢¼"""
    try:
        from ai_providers import ask_sync
        out, _ = ask_sync(f"ç”¢å‡ºå¯åŸ·è¡Œçš„ Python ä»£ç¢¼å®Œæˆæ­¤ä»»å‹™ï¼Œåƒ…ä»£ç¢¼ç„¡è§£é‡‹ï¼š{prompt}", images=None, ensemble=False)
        if out and "é€£ç·šå¤±æ•—" not in out:
            return out.strip().removeprefix("```python").removeprefix("```").removesuffix("```").strip()
    except Exception:
        pass
    try:
        r = requests.post(
            f"{os.environ.get('OLLAMA_BASE_URL', 'http://127.0.0.1:11434')}/api/generate",
            json={"model": os.environ.get("OLLAMA_MODEL", "gemma3:4b"), "prompt": f"ç”¢å‡º Python ä»£ç¢¼ï¼š{prompt}", "stream": False},
            timeout=OLLAMA_TIMEOUT,
        )
        if r.status_code == 200:
            t = r.json().get("response", "").strip().removeprefix("```python").removeprefix("```").removesuffix("```").strip()
            return t or "# Local AI Offline"
    except Exception:
        pass
    return "# Local AI Offline"


def test_execution(code: str) -> tuple[bool, str]:
    """åŸ·è¡Œè‡ªæª¢"""
    try:
        DEV_OUTPUT.write_text(code, encoding="utf-8")
        res = subprocess.run([sys.executable, str(DEV_OUTPUT)], cwd=str(BASE_DIR), capture_output=True, text=True, timeout=30)
        return (res.returncode == 0, res.stderr or "")
    except subprocess.TimeoutExpired:
        return (False, "åŸ·è¡Œé€¾æ™‚")
    except Exception as e:
        return (False, str(e))


def process_message(content: str, user_id: str, base_url: str = "", model: str = "gemma3:4b") -> tuple[str, str]:
    """
    è™•ç†å–®ä¸€è¨Šæ¯ï¼Œèˆ‡ Discord æ©Ÿå™¨äººé‚è¼¯ä¸€è‡´ã€‚
    å›å‚³ (çµæœ, é¡å‹) é¡å‹: action|agent|brain|dev
    """
    content = (content or "").strip()
    if not content:
        return "è«‹è¼¸å…¥å…§å®¹ã€‚", "brain"

    # ã€é–‹ç™¼ï¼šã€‘M2M è»å¸«å”è­°
    if content.startswith("é–‹ç™¼ï¼š"):
        demand = content.replace("é–‹ç™¼ï¼š", "").strip()
        code = call_local_ai_dev(demand)
        success, error_msg = test_execution(code)
        if success:
            try:
                from brain_self_learner import learn_from_dev_success
                learn_from_dev_success(demand, code)
            except Exception:
                pass
            return "âœ… æœ¬åœ°ç³»çµ±å·²å…¨æ¬ŠåŸ·è¡ŒæˆåŠŸã€‚", "dev"
        # å„ªå…ˆæœ¬åœ°è»å¸«ï¼ˆå…è²»ï¼‰ï¼šç”¨ Ollama/Groq/Gemini ä¾éŒ¯èª¤ä¿®æ­£
        fixed = call_local_strategist(demand, code, error_msg)
        if fixed:
            success2, err2 = test_execution(fixed)
            if success2:
                try:
                    from brain_self_learner import learn_from_dev_success
                    learn_from_dev_success(demand, fixed)
                except Exception:
                    pass
                return "âœ… æœ¬åœ°è»å¸«å·²ä¿®æ­£ï¼ŒåŸ·è¡ŒæˆåŠŸã€‚", "dev"
            # æœ¬åœ°ä¿®æ­£ä»å¤±æ•—ï¼Œå†è©¦ä¸€æ¬¡ï¼ˆå¸¶æ–°éŒ¯èª¤ï¼‰
            fixed2 = call_local_strategist(demand, fixed, err2)
            if fixed2:
                success3, err3 = test_execution(fixed2)
                if success3:
                    try:
                        from brain_self_learner import learn_from_dev_success
                        learn_from_dev_success(demand, fixed2)
                    except Exception:
                        pass
                    return "âœ… æœ¬åœ°è»å¸«å·²ä¿®æ­£ï¼ŒåŸ·è¡ŒæˆåŠŸã€‚", "dev"
                try:
                    from brain_self_learner import learn_from_dev_failure
                    learn_from_dev_failure(demand, err3)
                except Exception:
                    pass
                return f"æœ¬åœ°è»å¸«ä¿®æ­£å¾Œä»å¤±æ•—ï¼š\n{err3[:500]}\n\nè‹¥éœ€ GPT é«˜éšè»å¸«ï¼Œè«‹å›è¦†ã€Œå•Ÿç”¨GPTã€å–å¾—æˆæ¬Šå¾Œå†è©¦ã€‚", "dev"
        fixed = call_premium_strategist(demand, code, error_msg, user_id)
        if fixed:
            success2, err2 = test_execution(fixed)
            if success2:
                try:
                    from brain_self_learner import learn_from_dev_success
                    learn_from_dev_success(demand, fixed)
                except Exception:
                    pass
                return "ğŸ”® ä»˜è²»è»å¸«å·²é‡æ§‹ï¼ŒåŸ·è¡ŒæˆåŠŸã€‚", "dev"
            try:
                from brain_self_learner import learn_from_dev_failure
                learn_from_dev_failure(demand, err2)
            except Exception:
                pass
            return f"ä»˜è²»è»å¸«é‡æ§‹å¾Œä»å¤±æ•—ï¼š\n{err2[:500]}", "dev"
        try:
            from brain_self_learner import learn_from_dev_failure
            learn_from_dev_failure(demand, error_msg)
        except Exception:
            pass
        return f"æœ¬åœ°è»å¸«ç„¡æ³•ä¿®æ­£ï¼ˆå¯ç”¨ Groq/Gemini æå‡èƒ½åŠ›ï¼‰\n{error_msg[:500]}\n\nè‹¥éœ€ GPT é«˜éšè»å¸«ï¼Œè«‹å›è¦†ã€Œå•Ÿç”¨GPTã€å–å¾—æˆæ¬Šå¾Œå†è©¦ã€‚", "dev"

    # æˆæ¬Šã€é–‹å•ŸæŒ‡ä»¤
    action_result = handle_action(user_id, content)
    if action_result is not None:
        return action_result, "action"

    # Agent æ¨¡å¼ï¼ˆå¯«ç¨‹å¼/éƒ¨ç½²ï¼‰
    if _can_control(user_id) and is_agent_task(content):
        result = run_agent(content, user_id)
        return result, "agent"

    # ä¸€èˆ¬ AI å°è©±
    prompt = build_prompt(content)
    result = ask_brain(prompt, base_url, model)
    return result, "brain"
