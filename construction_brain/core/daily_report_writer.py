# -*- coding: utf-8 -*-
"""
ç‡Ÿå»ºè‡ªå‹•åŒ–å¤§è…¦ â€” æ–½å·¥æ—¥èªŒå¼•æ“Ž
å°‡äº‹ä»¶æŠ½å–çµæžœçµ„è£ç‚ºå®Œæ•´æ–½å·¥æ—¥å ±

è¤‡ç”¨ï¼š
  - construction_mgmt/database.py: create_daily_log, get_daily_log
  - construction_brain/core/extract_work_events.py: extract_events
"""
import json
import logging
import os
import time
from datetime import date, datetime
from pathlib import Path
from typing import Optional

log = logging.getLogger("construction_brain.daily_report")

DATA_DIR = Path(os.environ.get("CB_DATA_DIR", str(Path(__file__).resolve().parent.parent / "data")))
REPORTS_DIR = DATA_DIR / "reports"
REPORTS_DIR.mkdir(parents=True, exist_ok=True)

OLLAMA_BASE = os.environ.get("OLLAMA_BASE_URL", "http://localhost:11460").rstrip("/")
OLLAMA_MODEL = os.environ.get("CB_LLM_MODEL", "qwen3:32b")


def _call_llm(prompt: str, system: str = "") -> str:
    import urllib.request
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "system": system,
        "stream": False,
        "options": {"temperature": 0.2, "num_predict": 4000},
    }
    try:
        req = urllib.request.Request(
            f"{OLLAMA_BASE}/api/generate",
            data=json.dumps(payload).encode("utf-8"),
            headers={"Content-Type": "application/json"},
            method="POST",
        )
        with urllib.request.urlopen(req, timeout=120) as resp:
            return json.loads(resp.read().decode("utf-8")).get("response", "")
    except Exception as e:
        log.error(f"LLM å‘¼å«å¤±æ•—: {e}")
        return ""


class DailyReportWriter:
    """
    æ–½å·¥æ—¥å ±æ’°å¯«å¼•æ“Ž

    æµç¨‹ï¼š
    1. æ”¶é›†ç•¶æ—¥æ‰€æœ‰ IngestResultï¼ˆèªžéŸ³+ç…§ç‰‡+æ–‡å­—ï¼‰
    2. åˆä½µäº‹ä»¶åˆ°çµ±ä¸€æ—¥èªŒçµæ§‹
    3. LLM ç”Ÿæˆæ­£å¼æ—¥å ±æ–‡å­—
    4. è¼¸å‡º JSON + å¯åˆ—å°æ–‡å­—å ±å‘Š
    """

    def __init__(self, project_id: str = "", project_name: str = ""):
        self.project_id = project_id
        self.project_name = project_name
        self._events: list = []

    def add_events(self, events: dict):
        """åŠ å…¥äº‹ä»¶æŠ½å–çµæžœ"""
        self._events.append(events)

    def add_from_ingest(self, ingest_result):
        """å¾ž IngestResult åŠ å…¥äº‹ä»¶"""
        if hasattr(ingest_result, "events") and ingest_result.events:
            self._events.append(ingest_result.events)

    def merge_daily_log(self) -> dict:
        """åˆä½µå¤šå€‹äº‹ä»¶çµæžœåˆ°å–®ä¸€æ—¥èªŒçµæ§‹"""
        today = date.today().isoformat()
        merged = {
            "log_date": today,
            "weather_am": "", "weather_pm": "",
            "temperature_high": None, "temperature_low": None,
            "day_status": "working",
            "work_description": "",
            "safety_notes": "", "quality_notes": "", "notes": "",
            "workers": [], "equipment": [], "materials": [], "work_items": [],
        }
        all_safety = []
        all_quality = []
        all_events = []
        descriptions = []

        for evt in self._events:
            dl = evt.get("daily_log", {})
            # å–ç¬¬ä¸€å€‹éžç©ºçš„å¤©æ°£/ç‹€æ…‹
            for key in ("weather_am", "weather_pm", "day_status"):
                if dl.get(key) and not merged[key]:
                    merged[key] = dl[key]
            for key in ("temperature_high", "temperature_low"):
                if dl.get(key) is not None and merged[key] is None:
                    merged[key] = dl[key]
            # åˆä½µé™£åˆ—
            merged["workers"].extend(dl.get("workers", []))
            merged["equipment"].extend(dl.get("equipment", []))
            merged["materials"].extend(dl.get("materials", []))
            merged["work_items"].extend(dl.get("work_items", []))
            # æ–‡å­—
            desc = dl.get("work_description", "")
            if desc:
                descriptions.append(desc)
            for key in ("safety_notes", "quality_notes", "notes"):
                val = dl.get(key, "")
                if val:
                    merged[key] = (merged[key] + "ï¼›" + val).lstrip("ï¼›")
            # ç¨ç«‹å€å¡Š
            all_safety.extend(evt.get("safety_alerts", []))
            all_quality.extend(evt.get("quality_checks", []))
            all_events.extend(evt.get("events", []))

        merged["work_description"] = "\n".join(descriptions)
        # åŽ»é‡äººåŠ›ï¼ˆåŒå·¥ç¨®åˆä½µäººæ•¸ï¼‰
        merged["workers"] = self._dedup_workers(merged["workers"])

        return {
            "daily_log": merged,
            "safety_alerts": all_safety,
            "quality_checks": all_quality,
            "events": all_events,
        }

    def generate_report(self) -> dict:
        """
        ç”Ÿæˆå®Œæ•´æ—¥å ±

        Returns:
            {
                "merged": {...},         # çµæ§‹åŒ–è³‡æ–™
                "report_text": "...",    # æ­£å¼æ—¥å ±æ–‡å­—
                "safety_summary": "...", # å·¥å®‰æ‘˜è¦
                "elapsed_ms": 0.0,
            }
        """
        t0 = time.perf_counter()
        merged = self.merge_daily_log()
        dl = merged["daily_log"]
        safety = merged["safety_alerts"]

        # LLM ç”Ÿæˆæ­£å¼æ—¥å ±
        system = f"""ä½ æ˜¯ç‡Ÿå»ºå·¥ç¨‹æ—¥å ±æ’°å¯«åŠ©ç†ã€‚å·¥ç¨‹åç¨±ï¼š{self.project_name}ã€‚
è«‹æ ¹æ“šçµæ§‹åŒ–è³‡æ–™æ’°å¯«æ­£å¼æ–½å·¥æ—¥å ±ï¼Œæ ¼å¼ç¬¦åˆå°ç£å…¬å…±å·¥ç¨‹å“è³ªç®¡ç†è¦ç¯„ã€‚
èªžæ°£æ­£å¼ã€ç°¡æ½”ã€å°ˆæ¥­ã€‚åŒ…å«ï¼šæ–½å·¥æ¦‚è¦ã€äººåŠ›æ©Ÿå…·ã€ææ–™é€²å ´ã€æ–½å·¥é€²åº¦ã€å“è³ªç®¡ç†ã€å®‰å…¨è¡›ç”Ÿã€‚"""

        prompt = f"""çµæ§‹åŒ–è³‡æ–™ï¼š
```json
{json.dumps(dl, ensure_ascii=False, indent=2)}
```

å·¥å®‰è­¦å ±ï¼š
{json.dumps(safety, ensure_ascii=False) if safety else "ç„¡"}

è«‹æ’°å¯«æ­£å¼æ–½å·¥æ—¥å ±ï¼ˆç´”æ–‡å­—ï¼Œå«å„åˆ†æ®µæ¨™é¡Œï¼‰ã€‚"""

        report_text = _call_llm(prompt, system)

        # å·¥å®‰æ‘˜è¦
        safety_summary = ""
        if safety:
            high = [s for s in safety if s.get("severity") == "high"]
            medium = [s for s in safety if s.get("severity") == "medium"]
            if high:
                safety_summary += f"ðŸ”´ é«˜é¢¨éšª {len(high)} é …ï¼š" + "ï¼›".join(s.get("risk", "") for s in high) + "\n"
            if medium:
                safety_summary += f"ðŸŸ¡ ä¸­é¢¨éšª {len(medium)} é …ï¼š" + "ï¼›".join(s.get("risk", "") for s in medium)

        elapsed = round((time.perf_counter() - t0) * 1000, 1)
        result = {
            "merged": merged,
            "report_text": report_text,
            "safety_summary": safety_summary.strip(),
            "elapsed_ms": elapsed,
        }

        # å„²å­˜
        report_path = REPORTS_DIR / f"daily_{dl.get('log_date', date.today().isoformat())}_{self.project_id}.json"
        try:
            report_path.write_text(json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
            log.info(f"æ—¥å ±å·²å„²å­˜: {report_path}")
        except Exception as e:
            log.error(f"æ—¥å ±å„²å­˜å¤±æ•—: {e}")

        return result

    @staticmethod
    def _dedup_workers(workers: list) -> list:
        """åŽ»é‡äººåŠ›ï¼šåŒå·¥ç¨®åˆä½µäººæ•¸"""
        by_trade = {}
        for w in workers:
            trade = w.get("trade", "")
            if not trade:
                continue
            if trade in by_trade:
                by_trade[trade]["count"] += w.get("count", 0)
            else:
                by_trade[trade] = {**w}
        return list(by_trade.values())

    def save_to_db(self, merged: dict = None) -> Optional[int]:
        """å°‡æ—¥èªŒå¯«å…¥ construction_mgmt è³‡æ–™åº«"""
        if merged is None:
            merged = self.merge_daily_log()
        try:
            import sys
            sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
            from construction_mgmt.database import create_daily_log
            project_id = int(self.project_id) if self.project_id.isdigit() else 1
            log_id = create_daily_log(project_id, merged["daily_log"])
            log.info(f"æ—¥èªŒå·²å¯«å…¥ DB: project={project_id}, log_id={log_id}")
            return log_id
        except Exception as e:
            log.error(f"DB å¯«å…¥å¤±æ•—: {e}")
            return None
