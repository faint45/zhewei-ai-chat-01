# -*- coding: utf-8 -*-
"""
ç¯‰æœªç§‘æŠ€ â€” è‡ªå‹•å‚™ä»½è…³æœ¬
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
å‚™ä»½é …ç›®ï¼š
  1. PostgreSQLï¼ˆpg_dump via docker execï¼‰
  2. brain_workspace é—œéµè³‡æ–™ï¼ˆauth, licenses, usage, kbï¼‰
  3. .env è¨­å®šæª”
  4. æ”¯ä»˜è¨˜éŒ„

å‚™ä»½ç›®éŒ„ï¼šD:\\zhewei_backups\\YYYY-MM-DD_HHMMSS\\
ä¿ç•™ç­–ç•¥ï¼šä¿ç•™æœ€è¿‘ 30 å¤©

åŸ·è¡Œï¼š
  python scripts/backup_all.py                    # æ‰‹å‹•
  schtasks æ’ç¨‹æ¯å¤©å‡Œæ™¨ 3:00 è‡ªå‹•åŸ·è¡Œ             # è‡ªå‹•

Windows Task Scheduler è¨­å®šï¼ˆä»¥ç®¡ç†å“¡åŸ·è¡Œï¼‰ï¼š
  schtasks /create /tn "ZheWei-Daily-Backup" /tr "D:\\zhe-wei-tech\\.venv312\\Scripts\\python.exe D:\\zhe-wei-tech\\scripts\\backup_all.py" /sc daily /st 03:00 /ru SYSTEM /f
"""
import datetime
import os
import shutil
import subprocess
import sys
from pathlib import Path

if sys.platform == "win32":
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")

# â”€â”€ è¨­å®š â”€â”€
PROJECT_ROOT = Path(__file__).resolve().parent.parent
BACKUP_ROOT = Path(os.environ.get("ZHEWEI_BACKUP_DIR", str(PROJECT_ROOT / "backups")))
RETENTION_DAYS = int(os.environ.get("BACKUP_RETENTION_DAYS", "30"))

# PG å®¹å™¨åç¨±ï¼ˆå˜—è©¦å¤šå€‹ï¼‰
PG_CONTAINERS = ["docker-db_postgres-1", "zhewei_postgres", "postgres"]
PG_DATABASE = os.environ.get("PG_DATABASE", "jarvis")
PG_USER = os.environ.get("PG_USER", "postgres")

# è¦å‚™ä»½çš„ç›®éŒ„/æª”æ¡ˆ
BACKUP_ITEMS = [
    ("brain_workspace/auth",       "auth"),
    ("brain_workspace/licenses",   "licenses"),
    ("brain_workspace/usage",      "usage"),
    ("brain_workspace/kb_snapshots", "kb_snapshots"),
    (".env",                       ".env"),
    ("brain_workspace/orders",     "orders"),
]

PASSED = 0
FAILED = 0


def _step(name, fn):
    global PASSED, FAILED
    try:
        fn()
        PASSED += 1
        print(f"  âœ… {name}")
    except Exception as e:
        FAILED += 1
        print(f"  âŒ {name} â€” {e}")


def backup_postgres(backup_dir: Path):
    """é€é docker exec åŸ·è¡Œ pg_dumpã€‚"""
    dump_file = backup_dir / "postgres_jarvis.sql.gz"

    for container in PG_CONTAINERS:
        # æª¢æŸ¥å®¹å™¨æ˜¯å¦å­˜åœ¨
        check = subprocess.run(
            ["docker", "inspect", container],
            capture_output=True, text=True
        )
        if check.returncode != 0:
            continue

        # åŸ·è¡Œ pg_dump | gzip
        cmd = [
            "docker", "exec", container,
            "pg_dump", "-U", PG_USER, "-d", PG_DATABASE,
            "--no-owner", "--no-privileges", "--clean", "--if-exists"
        ]
        with open(dump_file.with_suffix(""), "wb") as f:
            result = subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE, timeout=120)

        if result.returncode == 0:
            # å£“ç¸®
            import gzip
            sql_file = dump_file.with_suffix("")
            with open(sql_file, "rb") as f_in:
                with gzip.open(str(dump_file), "wb") as f_out:
                    shutil.copyfileobj(f_in, f_out)
            sql_file.unlink()
            size_mb = dump_file.stat().st_size / 1024 / 1024
            print(f"    ğŸ“¦ {dump_file.name} ({size_mb:.1f} MB) from {container}")
            return
        else:
            stderr = result.stderr.decode("utf-8", errors="replace")
            if "does not exist" in stderr:
                print(f"    âš ï¸  Database '{PG_DATABASE}' not found in {container}")
                continue
            raise RuntimeError(f"pg_dump failed: {stderr[:200]}")

    raise RuntimeError(f"No PG container found: tried {PG_CONTAINERS}")


def backup_files(backup_dir: Path):
    """å‚™ä»½é—œéµæª”æ¡ˆå’Œç›®éŒ„ã€‚"""
    for src_rel, dst_name in BACKUP_ITEMS:
        src = PROJECT_ROOT / src_rel
        dst = backup_dir / dst_name

        if not src.exists():
            print(f"    â­ï¸  {src_rel} (ä¸å­˜åœ¨ï¼Œè·³é)")
            continue

        if src.is_dir():
            shutil.copytree(str(src), str(dst), dirs_exist_ok=True)
            count = sum(1 for _ in dst.rglob("*") if _.is_file())
            print(f"    ğŸ“ {dst_name}/ ({count} files)")
        else:
            dst.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(str(src), str(dst))
            print(f"    ğŸ“„ {dst_name}")


def cleanup_old_backups():
    """åˆªé™¤è¶…éä¿ç•™æœŸé™çš„å‚™ä»½ã€‚"""
    if not BACKUP_ROOT.exists():
        return
    cutoff = datetime.datetime.now() - datetime.timedelta(days=RETENTION_DAYS)
    removed = 0
    for d in sorted(BACKUP_ROOT.iterdir()):
        if not d.is_dir():
            continue
        try:
            # ç›®éŒ„åæ ¼å¼ï¼š2026-02-27_230000
            dir_date = datetime.datetime.strptime(d.name[:10], "%Y-%m-%d")
            if dir_date < cutoff:
                shutil.rmtree(str(d))
                removed += 1
        except (ValueError, IndexError):
            continue
    if removed:
        print(f"    ğŸ—‘ï¸  æ¸…ç† {removed} å€‹éæœŸå‚™ä»½ï¼ˆ> {RETENTION_DAYS} å¤©ï¼‰")
    else:
        print(f"    âœ… ç„¡éæœŸå‚™ä»½éœ€æ¸…ç†")


def send_notification(backup_dir: Path, success: bool):
    """é€é Ntfy ç™¼é€å‚™ä»½çµæœé€šçŸ¥ã€‚"""
    try:
        ntfy_url = os.environ.get("NTFY_URL", "http://localhost:2586")
        topic = os.environ.get("NTFY_TOPIC", "zhewei-alerts")
        import urllib.request
        status_text = "OK" if success else "PARTIAL_FAIL"
        size = sum(f.stat().st_size for f in backup_dir.rglob("*") if f.is_file()) / 1024 / 1024
        msg = f"Backup {status_text}\nDir: {backup_dir.name}\nSize: {size:.1f} MB\nResult: {PASSED} ok, {FAILED} fail"
        req = urllib.request.Request(
            f"{ntfy_url}/{topic}",
            data=msg.encode("utf-8"),
            method="POST",
        )
        req.add_header("Title", f"ZheWei Backup {status_text}")
        req.add_header("Priority", "3" if success else "4")
        req.add_header("Tags", "floppy_disk" if success else "warning")
        urllib.request.urlopen(req, timeout=5)
        print(f"  ğŸ“¨ é€šçŸ¥å·²ç™¼é€åˆ° Ntfy")
    except Exception as e:
        print(f"  âš ï¸  Ntfy é€šçŸ¥å¤±æ•—: {e}")


def main():
    ts = datetime.datetime.now().strftime("%Y-%m-%d_%H%M%S")
    backup_dir = BACKUP_ROOT / ts
    backup_dir.mkdir(parents=True, exist_ok=True)

    print("=" * 55)
    print(f"ç¯‰æœªç§‘æŠ€å‚™ä»½ â€” {ts}")
    print(f"ç›®æ¨™: {backup_dir}")
    print("=" * 55)

    print("\nğŸ“¦ PostgreSQL å‚™ä»½")
    _step("pg_dump", lambda: backup_postgres(backup_dir))

    print("\nğŸ“ æª”æ¡ˆå‚™ä»½")
    _step("é—œéµæª”æ¡ˆ", lambda: backup_files(backup_dir))

    print("\nğŸ—‘ï¸  æ¸…ç†éæœŸå‚™ä»½")
    _step("æ¸…ç†", cleanup_old_backups)

    total_size = sum(f.stat().st_size for f in backup_dir.rglob("*") if f.is_file()) / 1024 / 1024
    success = FAILED == 0

    print(f"\n{'=' * 55}")
    print(f"çµæœ: {PASSED} æˆåŠŸ, {FAILED} å¤±æ•— | ç¸½å¤§å°: {total_size:.1f} MB")
    print(f"{'=' * 55}")

    send_notification(backup_dir, success)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
