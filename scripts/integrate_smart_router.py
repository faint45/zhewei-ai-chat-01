#!/usr/bin/env python3
"""
ç¯‰æœªç§‘æŠ€ â€” æ™ºæ…§è·¯ç”±æ•´åˆè…³æœ¬
å°‡ SmartOllamaRouter æ•´åˆåˆ°ç¾æœ‰çš„ AI æœå‹™ä¸­
"""

import os
import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT))

def integrate_to_ai_service():
    """æ•´åˆæ™ºæ…§è·¯ç”±åˆ° ai_service.py"""
    
    ai_service_path = ROOT / "ai_service.py"
    
    if not ai_service_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ° {ai_service_path}")
        return False
    
    print(f"ğŸ“ è®€å– {ai_service_path}")
    content = ai_service_path.read_text(encoding="utf-8")
    
    # æª¢æŸ¥æ˜¯å¦å·²æ•´åˆ
    if "smart_ollama_router" in content:
        print("âœ… æ™ºæ…§è·¯ç”±å·²æ•´åˆåˆ° ai_service.py")
        return True
    
    # åœ¨ OllamaService çš„ __init__ æ–¹æ³•ä¸­æ•´åˆæ™ºæ…§è·¯ç”±
    integration_code = '''
    def __init__(self, model_name: str | None = None):
        # ä½¿ç”¨æ™ºæ…§è·¯ç”±é¸æ“‡æœ€ä½³ Ollama URL
        try:
            from ai_modules.smart_ollama_router import get_ollama_url
            base = get_ollama_url(prefer_gpu=True)
        except ImportError:
            # Fallback åˆ°ç’°å¢ƒè®Šæ•¸
            base = (os.environ.get("OLLAMA_BASE_URL") or "http://localhost:11434").rstrip("/")
        
        self.base_url = f"{base}/api/chat"
        self.model_name = model_name or OLLAMA_MODEL
        self.timeout = OLLAMA_TIMEOUT
'''
    
    # æ›¿æ›åŸæœ‰çš„ __init__ æ–¹æ³•
    old_init = '''    def __init__(self, model_name: str | None = None):
        base = (os.environ.get("OLLAMA_BASE_URL") or "http://localhost:11434").rstrip("/")
        self.base_url = f"{base}/api/chat"
        self.model_name = model_name or OLLAMA_MODEL
        self.timeout = OLLAMA_TIMEOUT'''
    
    if old_init in content:
        content = content.replace(old_init, integration_code)
        ai_service_path.write_text(content, encoding="utf-8")
        print("âœ… å·²æ•´åˆæ™ºæ…§è·¯ç”±åˆ° ai_service.py")
        return True
    else:
        print("âš ï¸ ç„¡æ³•æ‰¾åˆ° OllamaService.__init__ æ–¹æ³•ï¼Œè«‹æ‰‹å‹•æ•´åˆ")
        return False

def add_router_api_to_brain_server():
    """åœ¨ brain_server.py ä¸­æ·»åŠ è·¯ç”±å™¨ç‹€æ…‹ API"""
    
    brain_server_path = ROOT / "brain_server.py"
    
    if not brain_server_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ° {brain_server_path}")
        return False
    
    print(f"ğŸ“ è®€å– {brain_server_path}")
    content = brain_server_path.read_text(encoding="utf-8")
    
    # æª¢æŸ¥æ˜¯å¦å·²æ·»åŠ 
    if "/api/ollama/router/status" in content:
        print("âœ… è·¯ç”±å™¨ API å·²æ·»åŠ åˆ° brain_server.py")
        return True
    
    # æ·»åŠ è·¯ç”±å™¨ç‹€æ…‹ API
    router_api = '''
# ============================================
# Ollama æ™ºæ…§è·¯ç”± API
# ============================================

@app.get("/api/ollama/router/status")
async def get_ollama_router_status():
    """å–å¾— Ollama æ™ºæ…§è·¯ç”±å™¨ç‹€æ…‹"""
    try:
        from ai_modules.smart_ollama_router import get_router_status
        status = get_router_status()
        return {"success": True, "data": status}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/ollama/router/refresh")
async def refresh_ollama_router():
    """å¼·åˆ¶åˆ·æ–°è·¯ç”±å™¨å¿«å–"""
    try:
        from ai_modules.smart_ollama_router import get_router
        router = get_router()
        router.force_refresh()
        status = router.get_status()
        return {"success": True, "message": "è·¯ç”±å™¨å·²åˆ·æ–°", "data": status}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/ollama/models/recommended")
async def get_recommended_ollama_model(task_type: str = "general"):
    """å–å¾—æ¨è–¦çš„ Ollama æ¨¡å‹"""
    try:
        from ai_modules.smart_ollama_router import get_recommended_model
        model = get_recommended_model(task_type)
        return {"success": True, "model": model, "task_type": task_type}
    except Exception as e:
        return {"success": False, "error": str(e)}
'''
    
    # åœ¨æª”æ¡ˆæœ«å°¾æ·»åŠ ï¼ˆåœ¨ if __name__ == "__main__" ä¹‹å‰ï¼‰
    if 'if __name__ == "__main__":' in content:
        parts = content.split('if __name__ == "__main__":')
        content = parts[0] + router_api + '\n\nif __name__ == "__main__":' + parts[1]
        brain_server_path.write_text(content, encoding="utf-8")
        print("âœ… å·²æ·»åŠ è·¯ç”±å™¨ API åˆ° brain_server.py")
        return True
    else:
        print("âš ï¸ ç„¡æ³•æ‰¾åˆ°åˆé©çš„æ’å…¥é»ï¼Œè«‹æ‰‹å‹•æ·»åŠ  API")
        return False

def create_test_script():
    """å»ºç«‹æ¸¬è©¦è…³æœ¬"""
    
    test_script = ROOT / "scripts" / "test_smart_router.py"
    
    test_code = '''#!/usr/bin/env python3
"""æ¸¬è©¦æ™ºæ…§ Ollama è·¯ç”±å™¨"""

import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT))

from ai_modules.smart_ollama_router import get_router

def main():
    print("=== æ¸¬è©¦æ™ºæ…§ Ollama è·¯ç”±å™¨ ===\\n")
    
    router = get_router()
    
    # å–å¾—ç‹€æ…‹
    status = router.get_status()
    
    print(f"ğŸ¯ ç•¶å‰æ¨¡å¼: {status['current_mode']}")
    print(f"\\nğŸ“¡ GPU Ollama:")
    print(f"   URL: {status['gpu']['url']}")
    print(f"   å¯ç”¨: {'âœ…' if status['gpu']['available'] else 'âŒ'}")
    if status['gpu']['models']:
        print(f"   æ¨¡å‹: {', '.join(status['gpu']['models'][:5])}")
    print(f"   è«‹æ±‚æ¬¡æ•¸: {status['gpu']['requests']}")
    
    print(f"\\nâ˜ï¸  CPU Ollama:")
    print(f"   URL: {status['cpu']['url']}")
    if status['cpu']['models']:
        print(f"   æ¨¡å‹: {', '.join(status['cpu']['models'][:5])}")
    print(f"   è«‹æ±‚æ¬¡æ•¸: {status['cpu']['requests']}")
    
    # æ¨è–¦æ¨¡å‹
    print(f"\\nğŸ’¡ æ¨è–¦æ¨¡å‹:")
    print(f"   é€šç”¨ä»»å‹™: {router.get_recommended_model('general')}")
    print(f"   ä»£ç¢¼ä»»å‹™: {router.get_recommended_model('code')}")
    print(f"   è¼•é‡ä»»å‹™: {router.get_recommended_model('lightweight')}")
    
    # æœ€ä½³ URL
    best_url = router.get_best_ollama_url()
    print(f"\\nğŸš€ æœ€ä½³ Ollama URL: {best_url}")
    
    print("\\nâœ… æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main()
'''
    
    test_script.write_text(test_code, encoding="utf-8")
    print(f"âœ… å·²å»ºç«‹æ¸¬è©¦è…³æœ¬: {test_script}")

def main():
    print("=" * 60)
    print("ğŸ”§ ç¯‰æœªç§‘æŠ€ â€” æ™ºæ…§è·¯ç”±æ•´åˆ")
    print("=" * 60)
    print()
    
    # 1. æ•´åˆåˆ° ai_service.py
    print("æ­¥é©Ÿ 1: æ•´åˆåˆ° ai_service.py")
    integrate_to_ai_service()
    print()
    
    # 2. æ·»åŠ  API åˆ° brain_server.py
    print("æ­¥é©Ÿ 2: æ·»åŠ  API åˆ° brain_server.py")
    add_router_api_to_brain_server()
    print()
    
    # 3. å»ºç«‹æ¸¬è©¦è…³æœ¬
    print("æ­¥é©Ÿ 3: å»ºç«‹æ¸¬è©¦è…³æœ¬")
    create_test_script()
    print()
    
    print("=" * 60)
    print("âœ… æ•´åˆå®Œæˆï¼")
    print("=" * 60)
    print()
    print("å¾ŒçºŒæ­¥é©Ÿ:")
    print("1. è¤‡è£½ env.hybrid.example ç‚º .env")
    print("2. å¡«å…¥ CLOUDFLARE_TOKEN å’Œ API Keys")
    print("3. åŸ·è¡Œæ¸¬è©¦: python scripts/test_smart_router.py")
    print("4. é‡å•Ÿ Brain Server")
    print()

if __name__ == "__main__":
    main()
