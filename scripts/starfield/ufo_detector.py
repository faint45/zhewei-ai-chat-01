#!/usr/bin/env python3
"""
UFO åµæ¸¬å¼•æ“ â€” Tapo C230 å¤œç©ºä¸æ˜é£›è¡Œç‰©åµæ¸¬
æ ¸å¿ƒæ¼”ç®—æ³•ï¼š
  1. èƒŒæ™¯å»ºæ¨¡ï¼ˆæ˜Ÿç©ºéœæ…‹èƒŒæ™¯ï¼‰â€” ç´¯ç©å¹³å‡ or MOG2
  2. å‰æ™¯åµæ¸¬ï¼ˆç§»å‹•ç‰©é«”æå–ï¼‰â€” èƒŒæ™¯å·®åˆ† + å½¢æ…‹å­¸
  3. æ˜Ÿé»æ’é™¤ â€” éœæ…‹äº®é»éæ¿¾ï¼ˆæ˜Ÿæ˜Ÿä¸å‹•ï¼‰
  4. è»Œè·¡è¿½è¹¤ â€” å¤šå¹€é—œè¯ + å¡çˆ¾æ›¼æ¿¾æ³¢é æ¸¬
  5. ç‰©é«”åˆ†é¡ â€” ä¾äº®åº¦/é€Ÿåº¦/è»Œè·¡å½¢ç‹€/é–ƒçˆæ¨¡å¼åˆ†é¡
  6. äº‹ä»¶è¨˜éŒ„ â€” è‡ªå‹•æˆªåœ– + JSON äº‹ä»¶æ—¥èªŒ
"""

import os
os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp|stimeout;5000000"

import cv2
import numpy as np
import json
import time
import uuid
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Tuple


# ---------------------------------------------------------------------------
# è³‡æ–™çµæ§‹
# ---------------------------------------------------------------------------

@dataclass
class Detection:
    """å–®å¹€åµæ¸¬çµæœ"""
    x: int
    y: int
    w: int
    h: int
    cx: float          # ä¸­å¿ƒ x
    cy: float          # ä¸­å¿ƒ y
    area: int
    brightness: float  # å¹³å‡äº®åº¦
    max_brightness: float
    frame_id: int
    timestamp: float


@dataclass
class Track:
    """è¿½è¹¤è»Œè·¡"""
    track_id: str = ""
    detections: List[Detection] = field(default_factory=list)
    predicted_x: float = 0.0
    predicted_y: float = 0.0
    velocity_x: float = 0.0
    velocity_y: float = 0.0
    speed_px_per_sec: float = 0.0
    age: int = 0             # å­˜æ´»å¹€æ•¸
    missed: int = 0          # é€£çºŒæœªåŒ¹é…å¹€æ•¸
    classification: str = "unknown"
    confidence: float = 0.0
    color: Tuple[int, int, int] = (0, 255, 0)
    first_seen: float = 0.0
    last_seen: float = 0.0
    is_flashing: bool = False
    flash_frequency: float = 0.0

    def __post_init__(self):
        if not self.track_id:
            self.track_id = uuid.uuid4().hex[:8]


@dataclass
class UFOEvent:
    """UFO äº‹ä»¶"""
    event_id: str
    track_id: str
    classification: str
    confidence: float
    start_time: str
    end_time: str
    duration_sec: float
    avg_speed: float
    max_speed: float
    trajectory_points: int
    trajectory_length_px: float
    avg_brightness: float
    is_flashing: bool
    flash_frequency: float
    bbox_first: dict
    bbox_last: dict
    screenshot_path: str = ""
    trail_image_path: str = ""


# ---------------------------------------------------------------------------
# ç‰©é«”åˆ†é¡å™¨
# ---------------------------------------------------------------------------

class SkyObjectClassifier:
    """
    å¤œç©ºç‰©é«”åˆ†é¡å™¨
    ä¾æ“šï¼šé€Ÿåº¦ã€äº®åº¦ã€è»Œè·¡å½¢ç‹€ã€é–ƒçˆæ¨¡å¼ã€æŒçºŒæ™‚é–“
    """

    # åˆ†é¡è¦å‰‡ï¼ˆå¯èª¿æ•´ï¼‰
    RULES = {
        "airplane": {
            "speed_range": (5, 80),       # px/secï¼ˆä¸­ç­‰é€Ÿåº¦ï¼‰
            "duration_min": 3.0,           # è‡³å°‘ 3 ç§’
            "flashing": True,              # é£›æ©Ÿæœ‰é–ƒçˆç‡ˆ
            "trajectory": "linear",        # ç›´ç·šè»Œè·¡
            "brightness_range": (30, 200),
        },
        "satellite": {
            "speed_range": (2, 40),        # px/secï¼ˆç©©å®šæ…¢é€Ÿï¼‰
            "duration_min": 5.0,           # è¡›æ˜Ÿéå¢ƒè¼ƒä¹…
            "flashing": False,             # è¡›æ˜Ÿä¸é–ƒçˆï¼ˆç©©å®šåå°„ï¼‰
            "trajectory": "linear",        # ç›´ç·š
            "brightness_range": (15, 120), # è¼ƒæš—
        },
        "meteor": {
            "speed_range": (80, 9999),     # px/secï¼ˆæ¥µå¿«ï¼‰
            "duration_min": 0.0,
            "duration_max": 3.0,           # æµæ˜Ÿå¾ˆçŸ­æš«
            "flashing": False,
            "trajectory": "linear",
            "brightness_range": (50, 255), # å¾ˆäº®
        },
        "drone": {
            "speed_range": (1, 60),
            "duration_min": 2.0,
            "flashing": True,              # ç„¡äººæ©Ÿæœ‰ç‡ˆ
            "trajectory": "erratic",       # è»Œè·¡ä¸è¦å‰‡
            "brightness_range": (20, 180),
        },
        "ufo": {
            "speed_range": (0, 9999),      # ä»»ä½•é€Ÿåº¦
            "duration_min": 0.5,
            "flashing": None,              # ä¸ç¢ºå®š
            "trajectory": "any",           # ä»»ä½•è»Œè·¡
            "brightness_range": (10, 255),
        },
    }

    @staticmethod
    def analyze_trajectory(points: List[Tuple[float, float]]) -> dict:
        """åˆ†æè»Œè·¡ç‰¹å¾µ"""
        if len(points) < 3:
            return {"type": "unknown", "linearity": 0, "curvature": 0}

        pts = np.array(points, dtype=np.float64)

        # ç·šæ€§åº¦ï¼šç”¨æœ€å°äºŒä¹˜æ³•æ“¬åˆç›´ç·šï¼Œè¨ˆç®— RÂ²
        if len(pts) >= 2:
            # ç”¨ x,y åˆ†åˆ¥å° index åšç·šæ€§å›æ­¸
            t = np.arange(len(pts), dtype=np.float64)
            if np.std(pts[:, 0]) > 1e-6:
                corr_x = np.corrcoef(t, pts[:, 0])[0, 1] if len(t) > 1 else 0
            else:
                corr_x = 1.0
            if np.std(pts[:, 1]) > 1e-6:
                corr_y = np.corrcoef(t, pts[:, 1])[0, 1] if len(t) > 1 else 0
            else:
                corr_y = 1.0
            linearity = (abs(corr_x) + abs(corr_y)) / 2.0
        else:
            linearity = 0

        # æ›²ç‡ï¼šç›¸é„°å‘é‡çš„è§’åº¦è®ŠåŒ–
        angles = []
        for i in range(1, len(pts) - 1):
            v1 = pts[i] - pts[i - 1]
            v2 = pts[i + 1] - pts[i]
            norm1 = np.linalg.norm(v1)
            norm2 = np.linalg.norm(v2)
            if norm1 > 0.5 and norm2 > 0.5:
                cos_a = np.clip(np.dot(v1, v2) / (norm1 * norm2), -1, 1)
                angles.append(np.degrees(np.arccos(cos_a)))

        avg_curvature = np.mean(angles) if angles else 0
        max_curvature = np.max(angles) if angles else 0

        if linearity > 0.85 and avg_curvature < 15:
            traj_type = "linear"
        elif avg_curvature > 30 or max_curvature > 60:
            traj_type = "erratic"
        else:
            traj_type = "curved"

        return {
            "type": traj_type,
            "linearity": round(linearity, 3),
            "curvature_avg": round(avg_curvature, 1),
            "curvature_max": round(max_curvature, 1),
        }

    @staticmethod
    def detect_flashing(brightness_history: List[float], fps: float = 15) -> dict:
        """åµæ¸¬é–ƒçˆæ¨¡å¼"""
        if len(brightness_history) < 6:
            return {"is_flashing": False, "frequency": 0, "amplitude": 0}

        arr = np.array(brightness_history, dtype=np.float64)
        mean_b = np.mean(arr)
        std_b = np.std(arr)

        if mean_b < 1:
            return {"is_flashing": False, "frequency": 0, "amplitude": 0}

        # è®Šç•°ä¿‚æ•¸ > 0.2 è¦–ç‚ºé–ƒçˆ
        cv = std_b / mean_b if mean_b > 0 else 0
        is_flashing = cv > 0.2

        # ä¼°ç®—é »ç‡ï¼šè¨ˆç®—éé›¶é»
        centered = arr - mean_b
        zero_crossings = np.sum(np.diff(np.sign(centered)) != 0)
        duration = len(arr) / fps if fps > 0 else 1
        frequency = zero_crossings / (2 * duration) if duration > 0 else 0

        return {
            "is_flashing": is_flashing,
            "frequency": round(frequency, 2),
            "amplitude": round(std_b, 1),
            "cv": round(cv, 3),
        }

    def classify(self, track: Track, fps: float = 15) -> Tuple[str, float]:
        """åˆ†é¡è¿½è¹¤ç‰©é«”"""
        if len(track.detections) < 2:
            return "unknown", 0.0

        points = [(d.cx, d.cy) for d in track.detections]
        brightness_hist = [d.brightness for d in track.detections]
        duration = track.last_seen - track.first_seen

        traj = self.analyze_trajectory(points)
        flash = self.detect_flashing(brightness_hist, fps)

        speed = track.speed_px_per_sec
        avg_bright = np.mean(brightness_hist)

        scores = {}
        for name, rule in self.RULES.items():
            if name == "ufo":
                continue  # UFO æ˜¯ fallback
            score = 0
            total = 0

            # é€Ÿåº¦
            total += 30
            s_min, s_max = rule["speed_range"]
            if s_min <= speed <= s_max:
                score += 30
            elif speed < s_min * 0.5 or speed > s_max * 2:
                score += 0
            else:
                score += 10

            # æŒçºŒæ™‚é–“
            total += 20
            if duration >= rule.get("duration_min", 0):
                if "duration_max" not in rule or duration <= rule["duration_max"]:
                    score += 20
                else:
                    score += 5
            else:
                score += 5

            # é–ƒçˆ
            total += 25
            if rule["flashing"] is not None:
                if flash["is_flashing"] == rule["flashing"]:
                    score += 25
                else:
                    score += 5
            else:
                score += 15  # ä¸ç¢ºå®š

            # è»Œè·¡
            total += 15
            if rule["trajectory"] == "any" or traj["type"] == rule["trajectory"]:
                score += 15
            elif traj["type"] == "unknown":
                score += 8
            else:
                score += 3

            # äº®åº¦
            total += 10
            b_min, b_max = rule["brightness_range"]
            if b_min <= avg_bright <= b_max:
                score += 10
            else:
                score += 3

            scores[name] = score / total if total > 0 else 0

        if scores:
            best = max(scores, key=scores.get)
            confidence = scores[best]
            if confidence >= 0.55:
                return best, round(confidence, 3)

        return "ufo", round(1.0 - max(scores.values(), default=0), 3)


# ---------------------------------------------------------------------------
# è¿½è¹¤å™¨
# ---------------------------------------------------------------------------

class MultiTracker:
    """å¤šç‰©é«”è¿½è¹¤å™¨ï¼ˆç°¡åŒ–ç‰ˆ SORTï¼‰"""

    def __init__(self, max_missed: int = 15, min_hits: int = 3,
                 max_distance: float = 80.0):
        self.tracks: List[Track] = []
        self.max_missed = max_missed
        self.min_hits = min_hits
        self.max_distance = max_distance
        self.next_color_idx = 0
        self.colors = [
            (0, 255, 0), (255, 255, 0), (0, 255, 255), (255, 0, 255),
            (255, 128, 0), (128, 255, 0), (0, 128, 255), (255, 0, 128),
        ]

    def _get_color(self):
        c = self.colors[self.next_color_idx % len(self.colors)]
        self.next_color_idx += 1
        return c

    def update(self, detections: List[Detection]) -> List[Track]:
        """ç”¨æ–°åµæ¸¬çµæœæ›´æ–°è¿½è¹¤å™¨"""
        now = time.time()

        # é æ¸¬ç¾æœ‰è»Œè·¡çš„ä¸‹ä¸€å€‹ä½ç½®
        for t in self.tracks:
            if len(t.detections) >= 2:
                t.predicted_x = t.detections[-1].cx + t.velocity_x
                t.predicted_y = t.detections[-1].cy + t.velocity_y
            elif t.detections:
                t.predicted_x = t.detections[-1].cx
                t.predicted_y = t.detections[-1].cy

        # åŒˆç‰™åˆ©åŒ¹é…ï¼ˆç°¡åŒ–ç‰ˆï¼šè²ªå¿ƒæœ€è¿‘é„°ï¼‰
        used_det = set()
        used_trk = set()

        if self.tracks and detections:
            # è¨ˆç®—è·é›¢çŸ©é™£
            costs = np.zeros((len(self.tracks), len(detections)))
            for i, t in enumerate(self.tracks):
                for j, d in enumerate(detections):
                    costs[i, j] = np.sqrt(
                        (t.predicted_x - d.cx) ** 2 +
                        (t.predicted_y - d.cy) ** 2
                    )

            # è²ªå¿ƒåŒ¹é…
            while True:
                min_val = costs.min() if costs.size > 0 else self.max_distance + 1
                if min_val > self.max_distance:
                    break
                i, j = np.unravel_index(costs.argmin(), costs.shape)
                if i in used_trk or j in used_det:
                    costs[i, j] = 99999
                    continue

                # åŒ¹é…æˆåŠŸ
                self.tracks[i].detections.append(detections[j])
                self.tracks[i].missed = 0
                self.tracks[i].age += 1
                self.tracks[i].last_seen = now

                # æ›´æ–°é€Ÿåº¦
                if len(self.tracks[i].detections) >= 2:
                    d_prev = self.tracks[i].detections[-2]
                    d_curr = self.tracks[i].detections[-1]
                    dt = d_curr.timestamp - d_prev.timestamp
                    if dt > 0:
                        self.tracks[i].velocity_x = (d_curr.cx - d_prev.cx) / dt * 0.033
                        self.tracks[i].velocity_y = (d_curr.cy - d_prev.cy) / dt * 0.033
                        speed = np.sqrt(
                            (d_curr.cx - d_prev.cx) ** 2 +
                            (d_curr.cy - d_prev.cy) ** 2
                        ) / dt
                        # æŒ‡æ•¸ç§»å‹•å¹³å‡
                        self.tracks[i].speed_px_per_sec = (
                            0.7 * self.tracks[i].speed_px_per_sec + 0.3 * speed
                        )

                used_trk.add(i)
                used_det.add(j)
                costs[i, :] = 99999
                costs[:, j] = 99999

        # æœªåŒ¹é…çš„åµæ¸¬ â†’ æ–°è»Œè·¡
        for j, d in enumerate(detections):
            if j not in used_det:
                t = Track(color=self._get_color(), first_seen=now, last_seen=now)
                t.detections.append(d)
                t.predicted_x = d.cx
                t.predicted_y = d.cy
                self.tracks.append(t)

        # æœªåŒ¹é…çš„è»Œè·¡ â†’ å¢åŠ  missed
        for i, t in enumerate(self.tracks):
            if i not in used_trk:
                t.missed += 1

        # ç§»é™¤éæœŸè»Œè·¡
        self.tracks = [t for t in self.tracks if t.missed <= self.max_missed]

        # å›å‚³å·²ç¢ºèªçš„è»Œè·¡ï¼ˆè‡³å°‘ min_hits æ¬¡åµæ¸¬ï¼‰
        return [t for t in self.tracks if t.age >= self.min_hits]


# ---------------------------------------------------------------------------
# UFO åµæ¸¬å¼•æ“
# ---------------------------------------------------------------------------

class UFODetector:
    """
    UFO åµæ¸¬å¼•æ“

    æµç¨‹ï¼š
    1. èƒŒæ™¯å»ºæ¨¡ï¼ˆMOG2 æˆ–ç´¯ç©å¹³å‡ï¼‰
    2. å‰æ™¯æå– + å½¢æ…‹å­¸æ¸…ç†
    3. æ˜Ÿé»é®ç½©ï¼ˆéœæ…‹äº®é»æ’é™¤ï¼‰
    4. è¼ªå»“åµæ¸¬ + éæ¿¾
    5. å¤šç‰©é«”è¿½è¹¤
    6. åˆ†é¡ + äº‹ä»¶è¨˜éŒ„
    """

    def __init__(self, sensitivity: float = 0.5,
                 min_area: int = 8, max_area: int = 5000,
                 star_mask_frames: int = 60,
                 output_dir: str = "ufo_events"):
        self.sensitivity = sensitivity
        self.min_area = min_area
        self.max_area = max_area
        self.star_mask_frames = star_mask_frames
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / "screenshots").mkdir(exist_ok=True)
        (self.output_dir / "trails").mkdir(exist_ok=True)

        # èƒŒæ™¯æ¨¡å‹
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=300,
            varThreshold=int(16 + (1 - sensitivity) * 30),
            detectShadows=False
        )

        # æ˜Ÿé»é®ç½©
        self.star_mask = None
        self.star_accumulator = None
        self.star_frame_count = 0

        # è¿½è¹¤å™¨
        self.tracker = MultiTracker(max_missed=15, min_hits=3, max_distance=80)
        self.classifier = SkyObjectClassifier()

        # ç‹€æ…‹
        self.frame_id = 0
        self.events: List[UFOEvent] = []
        self.active_events = {}  # track_id â†’ event_id
        self.fps_estimate = 15.0
        self.running = False

        # åµæ¸¬åƒæ•¸
        thresh_base = 20 + int((1 - sensitivity) * 40)
        self.fg_threshold = thresh_base

    def build_star_mask(self, gray: np.ndarray):
        """ç´¯ç©å»ºç«‹æ˜Ÿé»é®ç½© â€” éœæ…‹äº®é»ï¼ˆæ˜Ÿæ˜Ÿï¼‰æœƒåœ¨ç´¯ç©å½±åƒä¸­ä¿æŒé«˜äº®åº¦"""
        if self.star_accumulator is None:
            self.star_accumulator = gray.astype(np.float64)
        else:
            self.star_accumulator = (
                self.star_accumulator * self.star_frame_count + gray.astype(np.float64)
            ) / (self.star_frame_count + 1)
        self.star_frame_count += 1

        if self.star_frame_count >= self.star_mask_frames:
            avg = self.star_accumulator.astype(np.uint8)
            # éœæ…‹äº®é» = æ˜Ÿæ˜Ÿ
            _, self.star_mask = cv2.threshold(avg, 30, 255, cv2.THRESH_BINARY)
            # è†¨è„¹ä¸€é»ç¢ºä¿å®Œå…¨é®è“‹
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            self.star_mask = cv2.dilate(self.star_mask, kernel, iterations=1)

    def detect_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Detection], List[Track]]:
        """
        è™•ç†å–®å¹€ï¼Œå›å‚³ (æ¨™è¨»å½±åƒ, åµæ¸¬åˆ—è¡¨, ç¢ºèªè»Œè·¡åˆ—è¡¨)
        """
        now = time.time()
        self.frame_id += 1
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # 1. å»ºç«‹/æ›´æ–°æ˜Ÿé»é®ç½©
        if self.star_mask is None:
            self.build_star_mask(gray)

        # 2. èƒŒæ™¯å·®åˆ†
        fg_mask = self.bg_subtractor.apply(gray, learningRate=0.002)

        # 3. é–¾å€¼åŒ–
        _, fg_mask = cv2.threshold(fg_mask, self.fg_threshold, 255, cv2.THRESH_BINARY)

        # 4. æ’é™¤æ˜Ÿé»
        if self.star_mask is not None:
            fg_mask = cv2.bitwise_and(fg_mask, cv2.bitwise_not(self.star_mask))

        # 5. å½¢æ…‹å­¸æ¸…ç†
        kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel_open)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel_close)

        # 6. è¼ªå»“åµæ¸¬
        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        detections = []
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < self.min_area or area > self.max_area:
                continue
            x, y, w, h = cv2.boundingRect(cnt)
            cx = x + w / 2.0
            cy = y + h / 2.0

            # è¨ˆç®—äº®åº¦
            roi = gray[y:y+h, x:x+w]
            avg_b = float(np.mean(roi)) if roi.size > 0 else 0
            max_b = float(np.max(roi)) if roi.size > 0 else 0

            detections.append(Detection(
                x=x, y=y, w=w, h=h, cx=cx, cy=cy,
                area=area, brightness=avg_b, max_brightness=max_b,
                frame_id=self.frame_id, timestamp=now
            ))

        # 7. è¿½è¹¤
        confirmed = self.tracker.update(detections)

        # 8. åˆ†é¡ç¢ºèªçš„è»Œè·¡
        for track in confirmed:
            cls, conf = self.classifier.classify(track, self.fps_estimate)
            track.classification = cls
            track.confidence = conf

            # é–ƒçˆåµæ¸¬
            b_hist = [d.brightness for d in track.detections]
            flash = self.classifier.detect_flashing(b_hist, self.fps_estimate)
            track.is_flashing = flash["is_flashing"]
            track.flash_frequency = flash["frequency"]

        # 9. äº‹ä»¶ç®¡ç†
        self._manage_events(confirmed, frame)

        # 10. ç¹ªè£½æ¨™è¨»
        annotated = self._draw_annotations(frame.copy(), detections, confirmed, fg_mask)

        return annotated, detections, confirmed

    def _manage_events(self, confirmed: List[Track], frame: np.ndarray):
        """ç®¡ç†äº‹ä»¶ï¼šæ–°äº‹ä»¶å»ºç«‹ã€çµæŸäº‹ä»¶è¨˜éŒ„"""
        now = time.time()
        active_ids = {t.track_id for t in confirmed}

        # æ–°è»Œè·¡ â†’ æ–°äº‹ä»¶
        for track in confirmed:
            if track.track_id not in self.active_events:
                event_id = f"UFO-{datetime.now().strftime('%Y%m%d-%H%M%S')}-{track.track_id}"
                self.active_events[track.track_id] = event_id

                # è‡ªå‹•æˆªåœ–
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                ss_path = str(self.output_dir / "screenshots" / f"{event_id}.png")
                cv2.imwrite(ss_path, frame)

        # çµæŸçš„è»Œè·¡ â†’ å®Œæˆäº‹ä»¶
        ended = [tid for tid in self.active_events if tid not in active_ids]
        for tid in ended:
            # æ‰¾åˆ°å°æ‡‰çš„ trackï¼ˆå¯èƒ½å·²å¾ tracker ç§»é™¤ï¼‰
            track = None
            for t in self.tracker.tracks:
                if t.track_id == tid:
                    track = t
                    break

            if track and len(track.detections) >= 3:
                event = self._build_event(track, frame)
                if event:
                    self.events.append(event)
                    self._save_event(event)

            del self.active_events[tid]

    def _build_event(self, track: Track, frame: np.ndarray) -> Optional[UFOEvent]:
        """å¾è»Œè·¡å»ºç«‹äº‹ä»¶"""
        if len(track.detections) < 3:
            return None

        event_id = self.active_events.get(track.track_id,
                    f"UFO-{datetime.now().strftime('%Y%m%d-%H%M%S')}-{track.track_id}")

        points = [(d.cx, d.cy) for d in track.detections]
        speeds = []
        for i in range(1, len(track.detections)):
            d0 = track.detections[i - 1]
            d1 = track.detections[i]
            dt = d1.timestamp - d0.timestamp
            if dt > 0:
                dist = np.sqrt((d1.cx - d0.cx)**2 + (d1.cy - d0.cy)**2)
                speeds.append(dist / dt)

        # è»Œè·¡é•·åº¦
        traj_len = sum(
            np.sqrt((points[i][0] - points[i-1][0])**2 + (points[i][1] - points[i-1][1])**2)
            for i in range(1, len(points))
        )

        # ç¹ªè£½è»Œè·¡åœ–
        trail_path = str(self.output_dir / "trails" / f"{event_id}_trail.png")
        self._draw_trail_image(track, frame.shape[:2], trail_path)

        d_first = track.detections[0]
        d_last = track.detections[-1]

        return UFOEvent(
            event_id=event_id,
            track_id=track.track_id,
            classification=track.classification,
            confidence=track.confidence,
            start_time=datetime.fromtimestamp(track.first_seen).isoformat(),
            end_time=datetime.fromtimestamp(track.last_seen).isoformat(),
            duration_sec=round(track.last_seen - track.first_seen, 2),
            avg_speed=round(np.mean(speeds), 1) if speeds else 0,
            max_speed=round(np.max(speeds), 1) if speeds else 0,
            trajectory_points=len(points),
            trajectory_length_px=round(traj_len, 1),
            avg_brightness=round(np.mean([d.brightness for d in track.detections]), 1),
            is_flashing=track.is_flashing,
            flash_frequency=track.flash_frequency,
            bbox_first={"x": d_first.x, "y": d_first.y, "w": d_first.w, "h": d_first.h},
            bbox_last={"x": d_last.x, "y": d_last.y, "w": d_last.w, "h": d_last.h},
            screenshot_path=str(self.output_dir / "screenshots" / f"{event_id}.png"),
            trail_image_path=trail_path,
        )

    def _draw_trail_image(self, track: Track, frame_shape: tuple, output_path: str):
        """ç¹ªè£½è»Œè·¡åœ–"""
        h, w = frame_shape
        canvas = np.zeros((h, w, 3), dtype=np.uint8)
        points = [(int(d.cx), int(d.cy)) for d in track.detections]

        # æ¼¸è®Šè»Œè·¡
        for i in range(1, len(points)):
            alpha = i / len(points)
            color = (
                int(track.color[0] * alpha),
                int(track.color[1] * alpha),
                int(track.color[2] * alpha),
            )
            thickness = max(1, int(3 * alpha))
            cv2.line(canvas, points[i-1], points[i], color, thickness, cv2.LINE_AA)

        # èµ·é»å’Œçµ‚é»
        if points:
            cv2.circle(canvas, points[0], 6, (0, 255, 0), -1)   # ç¶ è‰²èµ·é»
            cv2.circle(canvas, points[-1], 6, (0, 0, 255), -1)  # ç´…è‰²çµ‚é»

        # æ¨™è¨»
        label = f"{track.classification} ({track.confidence:.0%})"
        cv2.putText(canvas, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
                    0.8, (255, 255, 255), 2, cv2.LINE_AA)
        speed_text = f"Speed: {track.speed_px_per_sec:.1f} px/s"
        cv2.putText(canvas, speed_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX,
                    0.6, (200, 200, 200), 1, cv2.LINE_AA)

        cv2.imwrite(output_path, canvas)

    def _draw_annotations(self, frame: np.ndarray, detections: List[Detection],
                          confirmed: List[Track], fg_mask: np.ndarray) -> np.ndarray:
        """åœ¨å½±åƒä¸Šç¹ªè£½åµæ¸¬æ¨™è¨»"""
        h, w = frame.shape[:2]

        # ç¹ªè£½æ‰€æœ‰åŸå§‹åµæ¸¬ï¼ˆå°ç°æ¡†ï¼‰
        for d in detections:
            cv2.rectangle(frame, (d.x, d.y), (d.x + d.w, d.y + d.h),
                          (80, 80, 80), 1)

        # ç¹ªè£½ç¢ºèªè»Œè·¡
        for track in confirmed:
            if not track.detections:
                continue
            d = track.detections[-1]
            color = track.color

            # åˆ†é¡é¡è‰²
            cls_colors = {
                "airplane": (255, 200, 0),    # é’è‰²
                "satellite": (200, 200, 200),  # ç°ç™½
                "meteor": (0, 100, 255),       # æ©˜è‰²
                "drone": (255, 0, 255),        # ç´«è‰²
                "ufo": (0, 0, 255),            # ç´…è‰²ï¼
                "unknown": (128, 128, 128),
            }
            color = cls_colors.get(track.classification, track.color)

            # æ¡†
            pad = 4
            cv2.rectangle(frame, (d.x - pad, d.y - pad),
                          (d.x + d.w + pad, d.y + d.h + pad), color, 2)

            # æ¨™ç±¤
            label = f"{track.classification} {track.confidence:.0%}"
            (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(frame, (d.x - pad, d.y - pad - th - 6),
                          (d.x - pad + tw + 4, d.y - pad), color, -1)
            cv2.putText(frame, label, (d.x - pad + 2, d.y - pad - 4),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

            # è»Œè·¡ç·š
            pts = [(int(det.cx), int(det.cy)) for det in track.detections[-60:]]
            for i in range(1, len(pts)):
                alpha = i / len(pts)
                line_color = tuple(int(c * alpha) for c in color)
                cv2.line(frame, pts[i-1], pts[i], line_color, 2, cv2.LINE_AA)

            # é€Ÿåº¦
            spd_text = f"{track.speed_px_per_sec:.0f}px/s"
            cv2.putText(frame, spd_text, (d.x, d.y + d.h + 15),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1, cv2.LINE_AA)

            # é–ƒçˆæ¨™è¨˜
            if track.is_flashing:
                cv2.putText(frame, "FLASH", (d.x, d.y + d.h + 28),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 255), 1)

        # HUD è³‡è¨Š
        hud_y = 25
        cv2.putText(frame, f"UFO Detector | Frame: {self.frame_id}",
                    (10, hud_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)
        hud_y += 20
        cv2.putText(frame, f"Detections: {len(detections)} | Tracks: {len(confirmed)} | Events: {len(self.events)}",
                    (10, hud_y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 200, 0), 1, cv2.LINE_AA)
        hud_y += 20
        star_status = "Ready" if self.star_mask is not None else f"Building ({self.star_frame_count}/{self.star_mask_frames})"
        cv2.putText(frame, f"Star Mask: {star_status}",
                    (10, hud_y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 180, 0), 1, cv2.LINE_AA)

        # å°å‹å‰æ™¯é®ç½©é è¦½ï¼ˆå³ä¸‹è§’ï¼‰
        mask_small = cv2.resize(fg_mask, (w // 5, h // 5))
        mask_color = cv2.cvtColor(mask_small, cv2.COLOR_GRAY2BGR)
        frame[h - h//5 - 5:h - 5, w - w//5 - 5:w - 5] = mask_color

        return frame

    def _save_event(self, event: UFOEvent):
        """å„²å­˜äº‹ä»¶åˆ° JSON"""
        event_path = self.output_dir / f"{event.event_id}.json"
        with open(event_path, "w", encoding="utf-8") as f:
            json.dump(asdict(event), f, ensure_ascii=False, indent=2)
        print(f"ğŸ“¡ äº‹ä»¶è¨˜éŒ„ï¼š{event.event_id} [{event.classification}] "
              f"ä¿¡å¿ƒåº¦={event.confidence:.0%} æŒçºŒ={event.duration_sec}s "
              f"é€Ÿåº¦={event.avg_speed:.0f}px/s")

    def get_stats(self) -> dict:
        """å–å¾—çµ±è¨ˆè³‡è¨Š"""
        cls_count = {}
        for e in self.events:
            cls_count[e.classification] = cls_count.get(e.classification, 0) + 1
        return {
            "total_frames": self.frame_id,
            "total_events": len(self.events),
            "active_tracks": len(self.tracker.tracks),
            "confirmed_tracks": len([t for t in self.tracker.tracks if t.age >= self.tracker.min_hits]),
            "star_mask_ready": self.star_mask is not None,
            "classification_counts": cls_count,
        }


# ---------------------------------------------------------------------------
# CLI å³æ™‚åµæ¸¬
# ---------------------------------------------------------------------------

def run_live_detection(rtsp_url: str, sensitivity: float = 0.5,
                       width: int = 640, height: int = 480,
                       output_dir: str = "ufo_events"):
    """å³æ™‚ RTSP åµæ¸¬æ¨¡å¼"""
    detector = UFODetector(sensitivity=sensitivity, output_dir=output_dir)

    cap = cv2.VideoCapture(rtsp_url)
    if not cap.isOpened():
        print("éŒ¯èª¤ï¼šç„¡æ³•é–‹å•Ÿ RTSP ä¸²æµ")
        return
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    win_name = "UFO Detector | Q=quit S=snapshot"
    cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(win_name, width, height)

    print(f"ğŸ›¸ UFO åµæ¸¬å•Ÿå‹• â€” éˆæ•åº¦: {sensitivity}")
    print(f"   å‰ {detector.star_mask_frames} å¹€å»ºç«‹æ˜Ÿé»é®ç½©...")
    print(f"   æŒ‰ Q é€€å‡ºï¼ŒS æˆªåœ–")

    fps_timer = time.time()
    fps_count = 0

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                cap.release()
                cap = cv2.VideoCapture(rtsp_url)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                continue

            frame = cv2.resize(frame, (width, height))
            annotated, dets, tracks = detector.detect_frame(frame)

            # FPS è¨ˆç®—
            fps_count += 1
            elapsed = time.time() - fps_timer
            if elapsed >= 1.0:
                detector.fps_estimate = fps_count / elapsed
                fps_count = 0
                fps_timer = time.time()

            cv2.imshow(win_name, annotated)
            key = cv2.waitKey(1) & 0xFF
            if key == ord("q"):
                break
            elif key == ord("s"):
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                cv2.imwrite(f"ufo_snapshot_{ts}.png", annotated)
                print(f"ğŸ“¸ æˆªåœ–å·²å„²å­˜")

    except KeyboardInterrupt:
        pass
    finally:
        cap.release()
        cv2.destroyAllWindows()
        stats = detector.get_stats()
        print(f"\n=== åµæ¸¬çµæŸ ===")
        print(f"ç¸½å¹€æ•¸ï¼š{stats['total_frames']}")
        print(f"äº‹ä»¶æ•¸ï¼š{stats['total_events']}")
        print(f"åˆ†é¡çµ±è¨ˆï¼š{stats['classification_counts']}")


def main():
    import argparse
    parser = argparse.ArgumentParser(description="Tapo C230 UFO åµæ¸¬å¼•æ“")
    parser.add_argument("-u", "--url", help="RTSP URLï¼ˆæˆ–å¾ .env è®€å– TAPO_RTSP_URLï¼‰")
    parser.add_argument("-s", "--sensitivity", type=float, default=0.5,
                        help="åµæ¸¬éˆæ•åº¦ 0.0~1.0ï¼ˆé è¨­ 0.5ï¼‰")
    parser.add_argument("-W", "--width", type=int, default=640, help="ç•«é¢å¯¬åº¦")
    parser.add_argument("-H", "--height", type=int, default=480, help="ç•«é¢é«˜åº¦")
    parser.add_argument("-o", "--output", default="ufo_events", help="äº‹ä»¶è¼¸å‡ºç›®éŒ„")
    args = parser.parse_args()

    rtsp_url = args.url
    if not rtsp_url:
        try:
            from dotenv import load_dotenv
            load_dotenv(Path(__file__).resolve().parent / ".env")
        except ImportError:
            pass
        rtsp_url = os.environ.get("TAPO_RTSP_URL")

    if not rtsp_url:
        print("éŒ¯èª¤ï¼šè«‹æä¾› RTSP URLï¼ˆ-u åƒæ•¸æˆ– .env ä¸­çš„ TAPO_RTSP_URLï¼‰")
        return

    run_live_detection(rtsp_url, args.sensitivity, args.width, args.height, args.output)


if __name__ == "__main__":
    main()
