# -*- coding: utf-8 -*-
"""
Conversational Remote - å°è©±å¼é™æ§ç³»çµ±
èªéŸ³è¼¸å…¥ â†’ AI ç†è§£ â†’ åŸ·è¡Œ â†’ èªéŸ³/æ–‡å­—å›è¦†
ç„¡éœ€çœ‹è¢å¹•ï¼ŒåƒèŠå¤©ä¸€æ¨£æ§åˆ¶é›»è…¦
"""
import asyncio
import json
import time
from datetime import datetime
from typing import Optional, Callable
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent))

from smart_remote_agent import SmartRemoteAgent, call_host_api, get_screenshot


class ConversationalRemote:
    """å°è©±å¼é™æ§ç³»çµ±ã€‚"""

    def __init__(self, llm_provider: str = "gemini"):
        self.agent = SmartRemoteAgent(llm_provider=llm_provider)
        self.conversation_history = []
        self.execution_history = []
        self.context = {}

    def _call_llm(self, prompt: str, system_prompt: str = None) -> str:
        """å‘¼å« LLMã€‚"""
        try:
            from ai_service import AIServiceFactory
            service = AIServiceFactory.get_service(self.llm_provider)
            return service.chat(prompt, system_prompt=system_prompt)
        except Exception as e:
            return f"LLM éŒ¯èª¤: {e}"

    def _summarize_result(self, result: dict) -> str:
        """å°‡åŸ·è¡Œçµæœæ‘˜è¦ç‚ºè‡ªç„¶èªè¨€ã€‚"""
        if result.get("success"):
            steps = result.get("steps_executed", 0)
            duration = result.get("duration_seconds", 0)
            return f"âœ… å·²å®Œæˆ {steps} å€‹æ­¥é©Ÿï¼Œè€—æ™‚ {duration} ç§’ã€‚"
        error = result.get("error", "æœªçŸ¥éŒ¯èª¤")
        return f"âŒ åŸ·è¡Œå¤±æ•—ï¼š{error}"

    def _parse_conversational(self, message: str) -> dict:
        """è§£æå°è©±å¼æŒ‡ä»¤ã€‚"""
        system_prompt = """
ä½ æ˜¯å°è©±å¼é™æ§åŠ©æ‰‹ã€‚ç”¨æˆ¶æœƒç”¨è‡ªç„¶å°è©±èªªæƒ³è¦åšä»€éº¼ï¼Œä½ éœ€è¦ç†è§£ä¸¦è¦åŠƒå‹•ä½œã€‚

å¸¸è¦‹æ„åœ–:
- execute_action: åŸ·è¡Œå…·é«”å‹•ä½œï¼ˆé–‹è»Ÿé«”ã€æœå°‹ã€åŸ·è¡Œå‘½ä»¤ï¼‰
- ask_question: å•å•é¡Œï¼ˆä¸åŸ·è¡Œï¼‰
- check_status: æª¢æŸ¥ç‹€æ…‹
- multi_step: å¤šæ­¥é©Ÿè¤‡åˆä»»å‹™

å›å‚³ JSON:
{
  "intent": "ç”¨æˆ¶æ„åœ–æ‘˜è¦",
  "type": "execute_action|ask_question|check_status|multi_step",
  "action": "å…·é«”å‹•ä½œæè¿°",
  "params": {"command": "...", "app": "...", "path": "...", "search": "..."},
  "response_type": "explanation|confirmation|result",
  "needs_confirmation": æ˜¯å¦éœ€è¦ç¢ºèª,
  "confidence": 0.0-1.0
}
"""
        response = self._call_llm(message, system_prompt)
        try:
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0]
            return json.loads(response)
        except:
            return {"intent": message, "type": "execute_action", "action": message, "confidence": 0.5}

    def chat(self, message: str, execute: bool = True) -> dict:
        """
        å°è©±å¼é™æ§ä¸»å…¥å£ã€‚
        
        Args:
            message: ç”¨æˆ¶çš„è‡ªç„¶èªè¨€è¨Šæ¯
            execute: æ˜¯å¦åŸ·è¡Œå‹•ä½œ
        
        Returns:
            {"response": "å›è¦†æ–‡å­—", "executed": bool, "result": dict}
        """
        timestamp = datetime.now().isoformat()
        self.conversation_history.append({"role": "user", "message": message, "timestamp": timestamp})

        parsed = self._parse_conversational(message)
        result = {
            "timestamp": timestamp,
            "user_message": message,
            "parsed": parsed,
            "executed": False,
            "response": "",
            "result": None
        }

        if parsed.get("needs_confirmation") and execute:
            confirm_prompt = f"ç”¨æˆ¶èªªï¼šã€Œ{message}ã€ï¼Œä½ æƒ³è¦ï¼š\n\n{parsed.get('intent')}\n\nç¢ºèªåŸ·è¡Œå—ï¼Ÿè«‹å›è¦†ã€Œæ˜¯ã€ç¹¼çºŒï¼Œæˆ–ã€Œå¦ã€å–æ¶ˆã€‚"
            result["response"] = confirm_prompt
            result["needs_confirmation"] = True
            self.conversation_history.append({"role": "assistant", "message": confirm_prompt, "timestamp": datetime.now().isoformat()})
            return result

        if parsed.get("type") == "ask_question":
            answer = self.agent.ask(message)
            result["response"] = answer
            self.conversation_history.append({"role": "assistant", "message": answer, "timestamp": datetime.now().isoformat()})
            return result

        if parsed.get("type") == "check_status":
            status = self.get_system_status()
            result["response"] = status["summary"]
            result["result"] = status
            self.conversation_history.append({"role": "assistant", "message": status["summary"], "timestamp": datetime.now().isoformat()})
            return result

        if execute:
            action = parsed.get("action", message)
            exec_result = self.agent.run(action, execute=True)
            result["executed"] = True
            result["result"] = exec_result
            result["response"] = self._summarize_result(exec_result)
            self.execution_history.append(exec_result)
            self.conversation_history.append({"role": "assistant", "message": result["response"], "timestamp": datetime.now().isoformat()})
        else:
            plan = self.agent._parse_instruction(message)
            result["response"] = f"æˆ‘æ‰“ç®—ï¼š\n1. {plan.get('intent', message)}\n\néœ€è¦æˆ‘åŸ·è¡Œå—ï¼Ÿ"
            self.conversation_history.append({"role": "assistant", "message": result["response"], "timestamp": datetime.now().isoformat()})

        return result

    def get_system_status(self) -> dict:
        """å–å¾—ç³»çµ±ç‹€æ…‹æ‘˜è¦ã€‚"""
        sysinfo = call_host_api("/sysinfo")
        windows = call_host_api("/windows")
        screenshot = get_screenshot("base64")

        win_count = len(windows.get("windows", [])) if windows.get("ok") else 0
        cpu = sysinfo.get("cpu_percent", "?")

        summary = f"""ğŸ“Š ç³»çµ±ç‹€æ…‹ï¼š
- CPUï¼š{cpu}%
- è¨˜æ†¶é«”ï¼š{sysinfo.get('memory_percent', '?')}%
- é–‹å•Ÿè¦–çª—ï¼š{win_count} å€‹
- æˆªåœ–ï¼š{'âœ…' if screenshot.get('ok') else 'âŒ'}"""

        return {
            "ok": True,
            "summary": summary,
            "details": {
                "sysinfo": sysinfo,
                "windows": windows,
                "screenshot": screenshot.get("ok")
            }
        }

    def get_conversation_history(self, limit: int = 20) -> list:
        """å–å¾—å°è©±æ­·å²ã€‚"""
        return self.conversation_history[-limit:]

    def clear_history(self):
        """æ¸…é™¤å°è©±æ­·å²ã€‚"""
        self.conversation_history = []
        self.execution_history = []


def conversational_chat(message: str, execute: bool = True, provider: str = "gemini") -> dict:
    """ä¾¿æ·å‡½æ•¸ï¼šå°è©±å¼é™æ§ã€‚"""
    remote = ConversationalRemote(llm_provider=provider)
    return remote.chat(message, execute=execute)


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        message = " ".join(sys.argv[1:])
        result = conversational_chat(message, execute=True)
        print(f"\nğŸ‘¤ ä½ èªªï¼š{message}")
        print(f"\nğŸ¤– å›è¦†ï¼š{result['response']}")
        if result.get('executed'):
            print(f"\nâœ… å·²åŸ·è¡Œ {result.get('result', {}).get('steps_executed', 0)} æ­¥é©Ÿ")
    else:
        print("å°è©±å¼é™æ§ç³»çµ±")
        print("=" * 40)
        print("ç”¨æ³•: python conversational_remote.py <æŒ‡ä»¤>")
        print("ç¯„ä¾‹: python conversational_remote.py é–‹å•Ÿè¨˜äº‹æœ¬")
        print("ç¯„ä¾‹: python conversational_remote.py æª¢æŸ¥ç³»çµ±ç‹€æ…‹")
        print("ç¯„ä¾‹: python conversational_remote.py æœå°‹ D:\\ çš„ Python æª”æ¡ˆ")
        print()
        print("äº’å‹•æ¨¡å¼ï¼š")
        print("=" * 40)
        remote = ConversationalRemote()
        while True:
            try:
                msg = input("\nğŸ‘¤ ä½ èªªï¼š")
                if msg.lower() in ['exit', 'quit', 'é€€å‡º']:
                    break
                result = remote.chat(msg)
                print(f"\nğŸ¤– å›è¦†ï¼š{result['response']}")
            except KeyboardInterrupt:
                break
        print("\nå†è¦‹ï¼")
